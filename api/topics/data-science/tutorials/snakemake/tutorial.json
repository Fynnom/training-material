{"layout":"tutorial_hands_on","title":"Make & Snakemake","level":"Intermediate","zenodo_link":"https://zenodo.org/record/5562251","requirements":[{"type":"internal","topic_name":"data-science","tutorials":["cli-basics","cli-advanced"]}],"follow_up_training":[],"questions":["What is Make & Snakemake","What is a Makefile/Snakefile","How do these improve pipelines over simple scripts?","Why is Snakemake better for scientific research and how can I use it","How do I use conda envs with Snakemake?"],"objectives":["Write a snakefile that does a simple QC and Mapping workflow"],"time_estimation":"3H","key_points":["Make and Snakemake are ways to write pipelines in a declarative format","Instead of writing individual actions you wish to take, you describe how to produce each file you need, and the system executes those steps only if they're needed","If you're doing scientific research you should use Snakemake","Snakemake can significantly speed up your command line pipelines by providing automatic detection of inputs, and not re-creating them if they don't need","Snakemake also provides very easy access to paralellisation without complexity.","But it is more complex than using Galaxy"],"subtopic":"sciwms","contributors":[{"name":"Helena Rasche","orcid":"0000-0001-9760-8992","maintainer_contact":"gitter","matrix":"hexylena:matrix.org","joined":"2017-09","elixir_node":"nl","affiliations":["gallantries","by-covid","erasmusmc","elixir-europe","elixir-converge"],"former_affiliations":["deNBI","avans-atgm","uni-freiburg"],"contact_for_training":false,"location":{"country":"NL","lat":51.91,"lon":4.46},"id":"hexylena","url":"https://training.galaxyproject.org/training-material/api/contributors/hexylena.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/"},{"name":"Bazante Sanders","joined":"2020-12","affiliations":["avans-atgm"],"id":"bazante1","url":"https://training.galaxyproject.org/training-material/api/contributors/bazante1.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/bazante1/"},{"name":"Donny Vrins","joined":"2021-10","linkedin":"Donny Vrins","email":"D.vrins@live.nl","former_affiliations":["avans-atgm"],"id":"dirowa","url":"https://training.galaxyproject.org/training-material/api/contributors/dirowa.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/dirowa/"},{"name":"Avans Hogeschool","joined":"2020-11","url":"https://training.galaxyproject.org/training-material/api/organisations/avans-atgm.json","avatar":"/training-material/shared/images/logo-avans.png","members":["bazante1"],"former_members":["dirowa","hexylena"],"id":"avans-atgm","page":"https://training.galaxyproject.org/training-material/hall-of-fame/avans-atgm/"}],"abbreviations":{"SciWMS":"Scientific Workflow Management System","DAG":"Directed Acyclic Graph"},"js_requirements":{"mathjax":null,"mermaid":false},"short_id":"T00105","url":"/topics/data-science/tutorials/snakemake/tutorial.html","topic_name":"data-science","tutorial_name":"snakemake","dir":"topics/data-science/tutorials/snakemake","symlink":null,"id":"data-science/snakemake","ref_tutorials":["<p>Here you will learn to write both Make and Snakemake workflows. We teach two workflow engines because Snakemake uses a lot of the concepts of Make, and these concepts are somewhat complex and a very different way of thinking than you might be used to with workflow design.</p>\n\n<p>This tutorial is aimed at students and Galaxy community members who might want to convert Snakemake workflows into Galaxy workflows, but need to understand how Snakemake workflows work.</p>\n\n<blockquote class=\"agenda\">\n  <agenda-title></agenda-title>\n\n  <p>In this tutorial, we will cover:</p>\n\n<ol id=\"markdown-toc\">\n  <li><a href=\"#bash\" id=\"markdown-toc-bash\">Bash</a></li>\n  <li><a href=\"#make\" id=\"markdown-toc-make\">Make</a>    <ol>\n      <li><a href=\"#line-by-line-comparison\" id=\"markdown-toc-line-by-line-comparison\">Line-By-Line Comparison</a></li>\n      <li><a href=\"#why-make\" id=\"markdown-toc-why-make\">Why Make?</a></li>\n      <li><a href=\"#backwards\" id=\"markdown-toc-backwards\">Backwards</a></li>\n    </ol>\n  </li>\n  <li><a href=\"#snakemake\" id=\"markdown-toc-snakemake\">Snakemake</a>    <ol>\n      <li><a href=\"#line-by-line-comparison-1\" id=\"markdown-toc-line-by-line-comparison-1\">Line-By-Line Comparison</a></li>\n      <li><a href=\"#best-practices\" id=\"markdown-toc-best-practices\">Best Practices</a></li>\n      <li><a href=\"#final-pipeline\" id=\"markdown-toc-final-pipeline\">Final Pipeline</a></li>\n      <li><a href=\"#why-snakemake\" id=\"markdown-toc-why-snakemake\">Why Snakemake</a></li>\n      <li><a href=\"#the-case-of-the-missing-fastqc\" id=\"markdown-toc-the-case-of-the-missing-fastqc\">The Case of the Missing FastQC</a></li>\n    </ol>\n  </li>\n  <li><a href=\"#conclusion\" id=\"markdown-toc-conclusion\">Conclusion</a></li>\n</ol>\n\n</blockquote>\n\n<p>We’re going to go through this tutorial as “the evolution of a pipeline” from a simple bash script that we might run as individual commands on the command line, all the way up to a Snakemake workflow. This should give you some perspective of why the systems exist, and what benefits each system brings.</p>\n\n<h1 id=\"bash\">Bash</h1>\n\n<p>We’ve set up a simple bash pipeline. It downloads some read files from a website, decompresses them, builds an index for a <code class=\"language-plaintext highlighter-rouge\">genome.fa</code> we already have, and then does the alignment against that genome.</p>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\"># Downloading our datasets</span>\nwget https://zenodo.org/record/5562251/files/GCA_000017985.1_ASM1798v1_genomic.fna.gz\nwget https://zenodo.org/record/5562251/files/SRR2584866_1.fq.gz\nwget https://zenodo.org/record/5562251/files/SRR2584866_2.fq.gz\nwget https://zenodo.org/record/5562251/files/SRR2589044_1.fq.gz\nwget https://zenodo.org/record/5562251/files/SRR2589044_2.fq.gz\n\n<span class=\"c\"># Generate FastQC Report</span>\nfastqc <span class=\"k\">*</span>.fq\n\n<span class=\"c\"># Run Trimmomatic to trim the bad reads out.</span>\ntrimmomatic PE SRR2589044_1.fq.gz SRR2589044_2.fq.gz <span class=\"se\">\\</span>\n               SRR2589044_1.trim.fq SRR2589044_1un.trim.fq <span class=\"se\">\\</span>\n               SRR2589044_2.trim.fq SRR2589044_2un.trim.fq <span class=\"se\">\\</span>\n               SLIDINGWINDOW:4:20 MINLEN:25 ILLUMINACLIP:NexteraPE-PE.fa:2:40:15\n\ntrimmomatic PE SRR2584866_1.fq.gz SRR2589044_2.fq.gz <span class=\"se\">\\</span>\n               SRR2584866_1.trim.fq SRR2589044_1un.trim.fq <span class=\"se\">\\</span>\n               SRR2584866_2.trim.fq SRR2589044_2un.trim.fq <span class=\"se\">\\</span>\n               SLIDINGWINDOW:4:20 MINLEN:25 ILLUMINACLIP:NexteraPE-PE.fa:2:40:15\n\n<span class=\"c\"># Generate Updated FastQC Report</span>\nfastqc <span class=\"k\">*</span>.trim.fq\n\n<span class=\"c\"># Generate the genome index</span>\nbwa index GCA_000017985.1_ASM1798v1_genomic.fna\n\n<span class=\"c\"># Align reads to the genome</span>\nbwa mem GCA_000017985.1_ASM1798v1_genomic.fna SRR2589044_1.trim.fq SRR2589044_2.trim.fq | samtools <span class=\"nb\">sort</span> <span class=\"nt\">-O</span> bam <span class=\"nt\">-o</span> SRR2589044.bam\nbwa mem GCA_000017985.1_ASM1798v1_genomic.fna SRR2584866_1.trim.fq SRR2584866_2.trim.fq | samtools <span class=\"nb\">sort</span> <span class=\"nt\">-O</span> bam <span class=\"nt\">-o</span> SRR2584866.bam\n</code></pre></div></div>\n\n<p>This is a fine start to our analysis pipeline, and might simply be summarising\nthe commands we executed interactively at the command line.</p>\n\n<h1 id=\"make\">Make</h1>\n\n<p>Make is a build automation tool that has been around since 1976. It lets you describe build processes, writing down the individual processes which will occur, and then providing you a single entrypoint to run your workflow, a lot like how Scientific Workflow Management System (SciWMS) work! But importantly it is declarative, rather than imperative which is a big change if you’re familiar with programming languages like bash or python.</p>\n\n<p>Instead of defining step by step all of the steps that should be executed like the bash example above,\nyou instead write more general rules on how to produce individual files. We’ll look at them one-by-one.</p>\n\n<p>In bash scripts you write something like:</p>\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">command input</code> and it implicitly creates the output file automatically, often by adding a suffix (e.g. <code class=\"language-plaintext highlighter-rouge\">bwa index genome.fa</code> produces an index you refer to with <code class=\"language-plaintext highlighter-rouge\">genome</code>)</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">command input &gt; output</code> redirecting output of the command to a file</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">command input -O output</code> where we explicitly state where the output is</li>\n</ul>\n\n<p>In Make you’ll need to do that, but you’ll also need to declare the inputs and outputs of every step!</p>\n\n<pre class=\"highlight\"><code><span class=\"nb\">output</span>: <span class=\"kt\">input</span>\n\t<span class=\"s2\">command [and here the correct variant from above]</span>\n</code></pre>\n\n<p>This may seem tedious, to annotate the inputs and outputs of each step, but because Make knows what input files need to exist before it can execute this step, and it knows precisely which output files you will generate. It needs this information so that when you have multiple rules, it can decide which dependencies need to be executed.</p>\n\n<h2 id=\"line-by-line-comparison\">Line-By-Line Comparison</h2>\n\n<h3 id=\"downloading-data\">Downloading Data</h3>\n\n<blockquote class=\"code-in\">\n  <code-in-title>Bash</code-in-title>\n  <pre class=\"highlight\"><code><span class=\"s2\">wget https://.../GCA_000017985.1_ASM1798v1_genomic.fna.gz\nwget https://.../SRR2584866_1.fq.gz</span>\n</code></pre>\n  <p>With bash we download each read file one by one</p>\n</blockquote>\n<blockquote class=\"code-out\">\n  <code-out-title>Make</code-out-title>\n  <pre class=\"highlight\"><code><span class=\"nb\">%.gz</span>:\n\t<span class=\"s2\">wget https://.../$@ -O $@</span>\n</code></pre>\n  <p>But with Make we write is a generic rule which can be used any time you need to download a file for this project. <code class=\"language-plaintext highlighter-rouge\">$@</code> is used as the name of the output file and in the templated source url we will download from. If you ran <code class=\"language-plaintext highlighter-rouge\">make SRR2584866_1.fq.gz</code> it would template out the <code class=\"language-plaintext highlighter-rouge\">wget</code> command and run it. <strong>Speed bonus</strong>: It can parallelise these download jobs for us!</p>\n</blockquote>\n\n<h3 id=\"fastqc\">FastQC</h3>\n\n<blockquote class=\"code-in\">\n  <code-in-title>Bash</code-in-title>\n  <pre class=\"highlight\"><code><span class=\"s2\">fastqc *.fq</span></code></pre>\n  <p>Generate ALL of the FastQC reports</p>\n</blockquote>\n<blockquote class=\"code-out\">\n  <code-out-title>Make</code-out-title>\n  <pre class=\"highlight\"><code><span class=\"nb\">%.fastqc.html</span>: <span class=\"kt\">%.fq</span>\n\t<span class=\"s2\">fastqc $&lt;</span>\n</code></pre>\n  <p>Here is a rule to generate a single FastQC report from a single FastQ file</p>\n</blockquote>\n\n<h3 id=\"trimming-data\">Trimming Data</h3>\n\n<blockquote class=\"code-in\">\n  <code-in-title>Bash</code-in-title>\n  <pre class=\"highlight\"><code><span class=\"s2\">trimmomatic PE</span> <span class=\"kt\">SRR2589044_1.fq.gz SRR2589044_2.fq.gz</span> \\\n               <span class=\"nb\">SRR2589044_1.trim.fq SRR2589044_1un.trim.fq \\\n               SRR2589044_2.trim.fq SRR2589044_2un.trim.fq</span> \\\n               <span class=\"s2\">SLIDINGWINDOW:4:20 MINLEN:25 ILLUMINACLIP:NexteraPE-PE.fa:2:40:15</span>\n\n<span class=\"s2\">trimmomatic PE</span> <span class=\"kt\">SRR2584866_1.fq.gz SRR2584866_2.fq.gz</span> \\\n               <span class=\"nb\">SRR2584866_1.trim.fq SRR2584866_1un.trim.fq \\\n               SRR2584866_2.trim.fq SRR2584866_2un.trim.fq</span> \\\n               <span class=\"s2\">SLIDINGWINDOW:4:20 MINLEN:25 ILLUMINACLIP:NexteraPE-PE.fa:2:40:15</span>\n</code></pre>\n  <p>Run these two individual trimmomatic commands with these hardcoded filenames. If you need to run a new file make sure to carefully change all of the uses of it!</p>\n</blockquote>\n<blockquote class=\"code-out\">\n  <code-out-title>Make</code-out-title>\n  <pre class=\"highlight\"><code><span class=\"nb\">%_1.trim.fq %_2.trim.fq %_1un.trim.fq %_2un.trim.fq</span>: <span class=\"kt\">%_1.fq.gz %_2.fq.gz</span>\n\t<span class=\"s2\">trimmomatic PE $^ \\\n\t\t$(shell basename $(word 1,$^) .fq).trim.fq \\\n\t\t$(shell basename $(word 1,$^) .fq)un.trim.fq \\\n\t\t$(shell basename $(word 2,$^) .fq).trim.fq \\\n\t\t$(shell basename $(word 2,$^) .fq)un.trim.fq \\\n\t\tSLIDINGWINDOW:4:20 MINLEN:25 ILLUMINACLIP:NexteraPE-PE.fa:2:40:15</span>\n</code></pre>\n\n  <p>A more generic rule to generate the trimmed fastq files from whichever pair of sequence identifiers were provided. By using <code class=\"language-plaintext highlighter-rouge\">%</code> we also get some safety in this function that we didn’t have in the bash version! We know for sure those are identical values, and no one accidentally made a small typo in any one of the <strong>6</strong> times the same identifier was repeated. <u>But it comes at the cost</u> of using some complex Make statements like <code class=\"language-plaintext highlighter-rouge\">$(shell)</code> which lets us execute arbitrary shell commands inside our pipeline.</p>\n\n  <p>You’ll notice that what we’re really doing is extracting the inputs and outputs from the command and making them much more uniform</p>\n</blockquote>\n\n<p>So when we translated from Bash to Make, every time</p>\n\n<ul>\n  <li>we annotated inputs</li>\n  <li>we annotated outputs</li>\n  <li>we made the command a ‘template’</li>\n</ul>\n\n<blockquote class=\"comment\">\n  <comment-title>DO NOT REMEMBER THIS</comment-title>\n  <p>There is a lot of Make specific things going on in the above examples. You do not need to know it! We just wanted to provide working, correct examples. This tutorial is focused on Snakemake, so read these for context and understanding of why we use Snakemake, not reading them to learn Makefiles.</p>\n</blockquote>\n\n<h2 id=\"why-make\">Why Make?</h2>\n\n<p>So now comes the question, why Make? Why would you want to write the rules in this declarative way, rather than the imperative way that is so much easier and requires so much less work? <em>Speed!</em> Why would you want to write these generic rules that require learning a lot of Make’s syntax? <em>Reusability</em>.</p>\n\n<dl>\n  <dt>Speed</dt>\n  <dd>Every time you want to run your declarative pipeline, you either need to run it from start to finish every time (re-downloading sequence data, re-building genome indicies, re-mapping reads) or to write a lot of bash code to check if those files exist and only downloading/indexing/alinging as-needed.</dd>\n  <dt>Reusability</dt>\n  <dd>That pipeline can only download those specific files, unless you write additional code to template out the name of the reads and genome you want to align. By writing more generic rules, as soon as someone gives you new datasets, you can immediately start processing those with your re-usable pipeline.</dd>\n</dl>\n\n<p>However with <code class=\"language-plaintext highlighter-rouge\">make</code>, you’ve written generic rules which can be used to download any fastq files. And best of all, make can check if the files already exist, and if they do, it skips the step and goes on to the next step, rather than re-creating the file. Make does this by checking the</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Aspect</th>\n      <th>Bash</th>\n      <th>Make</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Language style</td>\n      <td>Individual steps performed line-by-line</td>\n      <td>Generic rules are written which say how to do the operation, but not on which data</td>\n    </tr>\n    <tr>\n      <td>Partial re-run</td>\n      <td>You must run the entire script every time (or write extra code)</td>\n      <td>Files are only created when you ask for them</td>\n    </tr>\n    <tr>\n      <td>How it is invoked</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">bash script.sh</code></td>\n      <td><code class=\"language-plaintext highlighter-rouge\">make</code></td>\n    </tr>\n    <tr>\n      <td>Running with different data?</td>\n      <td>Edit the script to replace the identifiers, or support templated identifiers.</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">make read1111.sam read2222.sam read3333.same read4444.sam</code></td>\n    </tr>\n    <tr>\n      <td>Paralellisation?</td>\n      <td>None by default, you must edit the script to add it.</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">make -j 8</code> runs each build step on one thread, with 8 threads available, until all tasks are finished.</td>\n    </tr>\n    <tr>\n      <td>Filename</td>\n      <td>Anything ending in <code class=\"language-plaintext highlighter-rouge\">.sh</code></td>\n      <td><code class=\"language-plaintext highlighter-rouge\">Makefile</code> is the default name, and you should name your makefile this, unless you want people to have to type <code class=\"language-plaintext highlighter-rouge\">make -f other-file.mk</code></td>\n    </tr>\n    <tr>\n      <td>Dependencies</td>\n      <td>Up to you to manage</td>\n      <td>Up to you to manage</td>\n    </tr>\n    <tr>\n      <td>Multiple output files per step</td>\n      <td>n/a</td>\n      <td><a href=\"https://www.gnu.org/software/automake/manual/html_node/Multiple-Outputs.html\">Very tricky to get completely right</a>, Makefiles really expect one rule produces one output file (and can only check e.g. update times of a single file.)</td>\n    </tr>\n    <tr>\n      <td>Cluster/HPC Friendliness</td>\n      <td>Everything is manual</td>\n      <td>Everything is manual</td>\n    </tr>\n  </tbody>\n</table>\n\n<h2 id=\"backwards\">Backwards</h2>\n\n<p>A full makefile example</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>all: SRR2589044.bam\n\n# Here we've hardcoded the genome name because it's less likely to change for a\n# single pipeline than the individual data files are.\n%.bam: %_1.trim.fq %_1.trim.fq GCA_000017985.1_ASM1798v1_genomic.fna.gz.bwt\n\tbwa mem GCA_000017985.1_ASM1798v1_genomic.fna $(word 1,$^) $(word 2,$^) | \\\n\t\tsamtools sort -O bam -o $@\n\n# This indexing step however will work for any possible\n%.fna.gz.bwt: %.fna.gz\n\tbwa index $&lt;\n\n# This handles ALL fastqc reporting, so we don't have to do it in two sections,\n# but, unless we ask for these reports they won't be generated.\n%.fastqc.html: %.fq\n\tfastqc $&lt;\n\n# This rule violates some Makefile internal expectations by having multiple\n# outputs which is not handled well by all implementations\n%_1.trim.fq %_2.trim.fq %_1un.trim.fq %_2un.trim.fq: %_1.fq.gz %_2.fq.gz\n\ttrimmomatic PE $^ \\\n\t\t$(shell basename $(word 1,$^) .fq).trim.fq \\\n\t\t$(shell basename $(word 1,$^) .fq)un.trim.fq \\\n\t\t$(shell basename $(word 2,$^) .fq).trim.fq \\\n\t\t$(shell basename $(word 2,$^) .fq)un.trim.fq \\\n\t\tSLIDINGWINDOW:4:20 MINLEN:25 ILLUMINACLIP:NexteraPE-PE.fa:2:40:15\n\n# And here's finally our download step\n%:\n\thttps://zenodo.org/record/5562251/files/$(shell basename $@) \\\n\t\t-O $@\n</code></pre></div></div>\n\n<p>You’ll notice a couple things about this above example:</p>\n\n<ol>\n  <li>There is a new rule called <code class=\"language-plaintext highlighter-rouge\">all</code>. In a makefile, by default, the very first rule is executed when you run <code class=\"language-plaintext highlighter-rouge\">make</code>. If you want to execute other rules you can, but it defaults to the first one. By convention, many people name it <code class=\"language-plaintext highlighter-rouge\">all</code>.</li>\n  <li>Inside there we’ve also written a file we’d like created, <code class=\"language-plaintext highlighter-rouge\">SRR2589044.bam</code>, which doesn’t exist yet. Make sees this as a dependency to finishing the (empty) all rule, and then goes on to figure out how to create it.</li>\n  <li>It is written backwards, we’ve started with what we want to output, and for each line, we figured out what we needed for that, and wrote a rule on how to create it. This is relatively common in makefiles.</li>\n</ol>\n\n<p>You’ll also notice some weird additional things we’ve had to do like <code class=\"language-plaintext highlighter-rouge\">$(word 2,$^)</code> to get the second input file to that rule, this is really kind of ugly and hard to understand and is a great motivation for learning Snakemake which helps address these issues.</p>\n\n<p>Make will read the above makefile like so:</p>\n\n<ol>\n  <li>You’re running <code class=\"language-plaintext highlighter-rouge\">make</code> so I will find the first task and run it</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">all</code> is the first task and it depends on this BAM file</li>\n  <li>The BAM file needs me to run bwa-mem and bwa-index, in two separate steps\n    <ol>\n      <li>For bwa index I need to index the genome</li>\n      <li>And I need to download it first!</li>\n    </ol>\n  </li>\n  <li>Also I need the trimmed fastq files, both forward and reverse files.</li>\n  <li>And I need to have the untrimmed files to trim them</li>\n  <li>And I need to download those first!</li>\n</ol>\n\n<p>Notice that Make isn’t running every task, it’s reading the one task you asked for, and seeing what’s required for that based on your annotations of inputs and outputs.</p>\n\n<blockquote class=\"question\">\n  <question-title>Check your understanding</question-title>\n\n  <ol>\n    <li>If a file is not part of the final output, or not the requested task, will it be created?</li>\n    <li>Do you spot any omissions in the above pipeline?</li>\n  </ol>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n    <ol>\n      <li>No, Make only runs the tasks for files it needs, it won’t run any of the other tasks. This is part of what makes <code class=\"language-plaintext highlighter-rouge\">make</code> fast and easily parallelisable.</li>\n      <li>Yes! FastQC is missing, it won’t be created unless we ask for it.</li>\n    </ol>\n  </blockquote>\n</blockquote>\n\n<p>Reading the above you should be able to imagine a tree of tasks that Make is creating internally:</p>\n\n<p>TODO</p>\n\n<p>This is called a Directed Acyclic Graph (DAG), it is a graph of nodes (tasks that need to be executed), with connections between nodes that have a direction (this task depends on outputs of that task), and there are no cycles (no outputs depend on inputs.) These are very common in <abbr title=\"Scientific Workflow Management System\">SciWMS</abbr>s because they make computation faster. Instead of executing step-by-step, we can build this graph of what work needs to be done, and then starting with the leaves of the graph (the end nodes without other dependencies) we can start executing and removing them.</p>\n\n<p>This also how we can really easily parallelise workflows: because we know the dependencies of each step, we know which can be executed right now, and we can execute them in parallel because we know for sure they do not depend on each other.</p>\n\n<h1 id=\"snakemake\">Snakemake</h1>\n\n<blockquote class=\"quote\" cite=\"https://snakemake.readthedocs.io/en/stable/index.html\">\n  <p>The Snakemake workflow management system is a tool to create reproducible and scalable data analyses. Workflows are described via a human readable, Python based language. They can be seamlessly scaled to server, cluster, grid and cloud environments, without the need to modify the workflow definition. Finally, Snakemake workflows can entail a description of required software, which will be automatically deployed to any execution environment.</p>\n</blockquote>\n\n<p>Snakemake addresses a lot of the issues with make for use in scientific contexts: clearer pipelines and dependencies. We did not talk about it in the previous section, but where did <code class=\"language-plaintext highlighter-rouge\">bowtie2</code> and <code class=\"language-plaintext highlighter-rouge\">bowtie2-build</code> come from? How did those get installed? What versions are they? None of that information is included in the Makefile</p>\n\n<p>Snakemake rules are a bit more complex, in Snakemake you will write rules that follow this form:</p>\n\n<pre class=\"highlight\"><code>rule my-rule-name\n\t<span class=\"kt\">input:\n\t\t\"something\",\n\t\t\"something-else\"</span>\n\t<span class=\"nb\">output:\n\t\t\"output-1\",\n\t\t\"output-2\"</span>\n\t<span class=\"s2\">shell:\n\t\t\"cat {input} &gt; {output}\"</span>\n</code></pre>\n\n<h2 id=\"line-by-line-comparison-1\">Line-By-Line Comparison</h2>\n\n<h3 id=\"downloading-data-1\">Downloading Data</h3>\n\n<blockquote class=\"code-in\">\n  <code-in-title>Make</code-in-title>\n  <pre class=\"highlight\"><code><span class=\"nb\">%.fq.gz</span>:\n\t<span class=\"s2\">wget https://zenodo.org/record/5562251/files/$@</span>\n</code></pre>\n\n  <p>Generic download rule, the <code>$@</code> and <code>%</code> used are a bit opaque, you need to know what they mean to understand how the rule works.</p>\n</blockquote>\n<blockquote class=\"code-out\">\n  <code-out-title>Snakemake</code-out-title>\n  <pre class=\"highlight\"><code>rule download:\n\t<span class=\"nb\">output:\n\t\t\"{sample}.fq.gz\"</span>\n\t<span class=\"s2\">shell:\n\t\t\"wget https://zenodo.org/record/5562251/files/{wildcards.sample}.fq.gz -O {output}\"</span>\n</code></pre>\n\n  <p>This is much more explicit, the outputs are listed and <code class=\"language-plaintext highlighter-rouge\">{sample}</code> is used as the variable to be templated out, a lot like you might recognise from Python’s <code class=\"language-plaintext highlighter-rouge\">format</code> function or <code class=\"language-plaintext highlighter-rouge\">f\"\"</code> strings. The rule also has a name which serves as really nice documentation for what that step does, you don’t have to read the command to figure it out.</p>\n</blockquote>\n\n<h3 id=\"fastqc-1\">FastQC</h3>\n\n<blockquote class=\"code-in\">\n  <code-in-title>Make</code-in-title>\n  <pre class=\"highlight\"><code><span class=\"nb\">%.fastqc.html</span>: <span class=\"kt\">%.fq</span>\n\t<span class=\"s2\">fastqc $&lt;</span>\n</code></pre>\n\n  <p>Here is a rule to generate a single FastQC report from a single FastQ file</p>\n</blockquote>\n<blockquote class=\"code-out\">\n  <code-out-title>Snakemake</code-out-title>\n  <pre class=\"highlight\"><code>rule fastqc:\n\t<span class=\"kt\">input:\n\t\t\"{sample}.fq.gz\"</span>\n\t<span class=\"nb\">output:\n\t\t\"{sample}_fastqc.html\"</span>\n\t<span class=\"s2\">shell:\n\t\t\"fastqc {input} --outdir fastqc/\"</span>\n</code></pre>\n\n  <p>Essentially the same, but now we’ve also added a Conda environment in which our job will run. This makes dependency management a lot simpler.</p>\n</blockquote>\n\n<h3 id=\"trimming-data-1\">Trimming Data</h3>\n\n<blockquote class=\"code-in\">\n  <code-in-title>Make</code-in-title>\n  <pre class=\"highlight\"><code><span class=\"nb\">%_1.trim.fq %_2.trim.fq %_1un.trim.fq %_2un.trim.fq</span>: <span class=\"kt\">%_1.fq.gz %_2.fq.gz</span>\n\t<span class=\"s2\">trimmomatic PE $^ \\\n\t\t$(shell basename $(word 1,$^) .fq).trim.fq \\\n\t\t$(shell basename $(word 1,$^) .fq)un.trim.fq \\\n\t\t$(shell basename $(word 2,$^) .fq).trim.fq \\\n\t\t$(shell basename $(word 2,$^) .fq)un.trim.fq \\\n\t\tSLIDINGWINDOW:4:20 MINLEN:25 ILLUMINACLIP:NexteraPE-PE.fa:2:40:15</span>\n</code></pre>\n\n  <p>Here we take our very complicated and hard to understand Make rule (shell? basename? word?) with ugly and potentially quite broken multiple output syntax</p>\n\n</blockquote>\n<blockquote class=\"code-out\">\n  <code-out-title>Snakemake</code-out-title>\n  <pre class=\"highlight\"><code>rule trimmomatic:\n\t<span class=\"kt\">input:\n\t\tr1=\"{sample}_1.fq.gz\",\n\t\tr2=\"{sample}_2.fq.gz\"</span>\n\t<span class=\"nb\">output:\n\t\to1=\"{sample}_1.trim.fq\",\n\t\to2=\"{sample}_2.trim.fq\",\n\t\to1un=\"{sample}_1un.trim.fq\",\n\t\to2un=\"{sample}_2un.trim.fq\"</span>\n\t<span class=\"s2\">shell:\n\t\t\"trimmomatic PE \"\n\t\t\"{input.r1} {input.r2} \"\n\t\t\"{output.o1} {output.o1un} \"\n\t\t\"{output.o2} {output.o2un} \"\n\t\t\"SLIDINGWINDOW:4:20 MINLEN:25 \"\n\t\t\"ILLUMINACLIP:NexteraPE-PE.fa:2:40:15\"</span>\n</code></pre>\n\n  <p>And turn it into a much more readable and clear Snakemake step! Now instead of using more opaque terms like <code class=\"language-plaintext highlighter-rouge\">$(word 1,$^)</code> we can just declare “our output should have this name and use {sample} as part of the name” and Snakemake takes care of the rest. Then in our commandline we can clearly reference exactly what we want.</p>\n\n  <p>Note: We also use <code class=\"language-plaintext highlighter-rouge\">fq.gz</code> as our input file because trimmomatic we know can accept gzipped fastq files, but we output plain fastq files because re-compressing those is another step and it’s not necessary right now for our small datasets. In a real world situation you might also choose not to compress intermediate datasets because you want better performance and you know you’ll throw away the intermediates and keep the source and final datasets.</p>\n</blockquote>\n\n<p>Now that you have seen a few rules, let’s write the rest.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Save this Snakefile to the filesystem</hands-on-title>\n  <p>From here on you are going to finish writing this Snakefile on your own! We’ll give you the bits you have seen up until now, and future tasks will require you to add your own rules and get to actually test out the pipeline!</p>\n\n  <pre><code class=\"language-Snakemake\">rule download:\n\toutput:\n\t\t\"{sample}.fq.gz\"\n\tshell:\n\t\t\"wget https://zenodo.org/record/5562251/files/{wildcards.sample}.fq.gz -O {output}\"\n\nrule download_genome:\n\toutput:\n\t\t\"GCA_000017985.1_ASM1798v1_genomic.fna.gz\"\n\tshell:\n\t\t\"wget https://zenodo.org/record/5562251/files/GCA_000017985.1_ASM1798v1_genomic.fna.gz -O {output}\"\n\nrule fastqc:\n\tinput:\n\t\t\"{sample}.fq.gz\"\n\toutput:\n\t\t\"{sample}_fastqc.html\"\n\tshell:\n\t\t\"fastqc {input} --outdir fastqc/\"\n\nrule trimmomatic:\n\tinput:\n\t\tr1=\"{sample}_1.fq.gz\",\n\t\tr2=\"{sample}_2.fq.gz\"\n\toutput:\n\t\to1=\"{sample}_1.trim.fq\",\n\t\to2=\"{sample}_2.trim.fq\",\n\t\to1un=\"{sample}_1un.trim.fq\",\n\t\to2un=\"{sample}_2un.trim.fq\"\n\tshell:\n\t\t\"trimmomatic PE \"\n\t\t\"{input.r1} {input.r2} \"\n\t\t\"{output.o1} {output.o1un} \"\n\t\t\"{output.o2} {output.o2un} \"\n\t\t\"SLIDINGWINDOW:4:20 MINLEN:25 \"\n\t\t\"ILLUMINACLIP:NexteraPE-PE.fa:2:40:15\"\n</code></pre>\n</blockquote>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Install Snakemake</hands-on-title>\n  <p>We’re about to start doing things really with snakemake, so, it’s time to install it.</p>\n  <ol>\n    <li><a href=\"https://docs.conda.io/en/latest/miniconda.html\">Install Miniconda</a></li>\n    <li>\n      <p>Create an environment for Snakemake:</p>\n\n      <div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>conda create <span class=\"nt\">-n</span> snakemake\n</code></pre></div>      </div>\n    </li>\n    <li>\n      <p>Activate it</p>\n\n      <div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>conda activate snakemake\n</code></pre></div>      </div>\n    </li>\n    <li>\n      <p>And install snakemake in this environment</p>\n\n      <div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>conda <span class=\"nb\">install </span><span class=\"nv\">snakemake</span><span class=\"o\">=</span>6.10.0\n</code></pre></div>      </div>\n    </li>\n  </ol>\n\n</blockquote>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Try running snakemake!</hands-on-title>\n\n  <ol>\n    <li>\n      <p>Try running snakemake</p>\n\n      <blockquote class=\"code-in\">\n        <code-in-title>CLI</code-in-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>snakemake -c1\n</code></pre></div>        </div>\n      </blockquote>\n\n      <blockquote class=\"tip\">\n        <tip-title>\"specify the maximum number of jobs\"</tip-title>\n        <p>If you see an error like this it might be due to an outdated version of snakemake</p>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Error: you need to specify the maximum number of jobs to be queued or executed at the same time with --jobs.\n</code></pre></div>        </div>\n      </blockquote>\n\n      <blockquote class=\"code-out\">\n        <code-out-title></code-out-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Building DAG of jobs...\nWorkflowError:\nTarget rules may not contain wildcards. Please specify concrete files or a rule without wildcards at the command line, or have a rule without wildcards at the very top of your workflow (e.g. the typical \"rule all\" which just collects all results you want to generate in the end).\n</code></pre></div>        </div>\n      </blockquote>\n\n      <p>Wait, that didn’t work! This is the <code class=\"language-plaintext highlighter-rouge\">all</code> rule we also saw in the makefile. But we can use Snakemake to build individual rule outputs, so let’s try that now.</p>\n    </li>\n    <li>\n      <p>Run snakemake to download <code class=\"language-plaintext highlighter-rouge\">SRR2584866_1.fq.gz</code> and <code class=\"language-plaintext highlighter-rouge\">SRR2584866_2.fq.gz</code></p>\n\n      <blockquote class=\"code-in\">\n        <code-in-title>CLI</code-in-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>snakemake -c1 SRR2584866_1.fq.gz SRR2584866_2.fq.gz\n</code></pre></div>        </div>\n      </blockquote>\n\n      <blockquote class=\"code-out code-max-300\">\n        <code-out-title></code-out-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Building DAG of jobs...\nUsing shell: /usr/bin/bash\nProvided cores: 1 (use --cores to define parallelism)\nRules claiming more threads will be scaled down.\nConda environments: ignored\nJob stats:\njob         count    min threads    max threads\n--------  -------  -------------  -------------\ndownload        2              1              1\ntotal           2              1              1\n\nSelect jobs to execute...\n\n[Fri Oct  8 16:06:32 2021]\nrule download:\n    output: SRR2584866_2.fq.gz\n    jobid: 1\n    wildcards: sample=SRR2584866_2\n    resources: tmpdir=/tmp\n\n--2021-10-08 16:06:32--  https://zenodo.org/record/5562251/SRR2584866_2.fq.gz\nResolving localhost (localhost)... 127.0.0.1\nConnecting to localhost (localhost)|127.0.0.1|:8000... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 6319969 (6,0M) [application/gzip]\nSaving to: ‘SRR2584866_2.fq.gz’\n\n2021-10-08 16:06:32 (538 MB/s) - ‘SRR2584866_2.fq.gz’ saved [6319969/6319969]\n\n[Fri Oct  8 16:06:32 2021]\nFinished job 1.\n1 of 2 steps (50%) done\nSelect jobs to execute...\n\n[Fri Oct  8 16:06:32 2021]\nrule download:\n    output: SRR2584866_1.fq.gz\n    jobid: 0\n    wildcards: sample=SRR2584866_1\n    resources: tmpdir=/tmp\n\n--2021-10-08 16:06:32--  https://zenodo.org/record/5562251/SRR2584866_1.fq.gz\nResolving localhost (localhost)... 127.0.0.1\nConnecting to localhost (localhost)|127.0.0.1|:8000... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 6586718 (6,3M) [application/gzip]\nSaving to: ‘SRR2584866_1.fq.gz’\n\n2021-10-08 16:06:32 (537 MB/s) - ‘SRR2584866_1.fq.gz’ saved [6586718/6586718]\n\n[Fri Oct  8 16:06:32 2021]\nFinished job 0.\n2 of 2 steps (100%) done\nComplete log: /tmp/snake.q5mqtdhfg6/.snakemake/log/2021-10-08T160632.213680.snakemake.log\n</code></pre></div>        </div>\n      </blockquote>\n    </li>\n    <li>\n      <p>Check that it worked. Do you see files in your directory?</p>\n    </li>\n  </ol>\n</blockquote>\n\n<p>Now that we’ve got our pipeline started, let’s do some more with it!</p>\n\n<blockquote class=\"question\">\n  <question-title></question-title>\n\n  <p>How would you write the following task in Snakemake?</p>\n\n  <p>The command is</p>\n  <pre class=\"highlight\"><code><span class=\"s2\">bwa index</span> <span class=\"kt\">GCA_000017985.1_ASM1798v1_genomic.fna</span></code></pre>\n  <p>and it creates <code class=\"language-plaintext highlighter-rouge\">GCA_000017985.1_ASM1798v1_genomic.fna.gz.bwt</code></p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <pre class=\"highlight\"><code>rule indexgenome:\n\t<span class=\"kt\">input:\n\t\t\"GCA_000017985.1_ASM1798v1_genomic.fna.gz\"</span>\n\t<span class=\"nb\">output:\n\t\t\"GCA_000017985.1_ASM1798v1_genomic.fna.gz.bwt\"</span>\n\t<span class=\"s2\">shell:\n\t\t\"bwa index {input}\"</span>\n</code></pre>\n  </blockquote>\n</blockquote>\n\n<blockquote class=\"question\">\n  <question-title></question-title>\n\n  <p>The command is <code class=\"language-plaintext highlighter-rouge\">bwa mem GCA_000017985.1_ASM1798v1_genomic.fna SRR2584866_1.trim.fq SRR2584866_2.trim.fq | samtools sort -O bam -o SRR2584866.bam</code></p>\n\n  <ol>\n    <li>What are the inputs?</li>\n    <li>What are the outputs?</li>\n    <li>How would you write the following task in Snakemake?</li>\n  </ol>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <ol>\n      <li>\n        <p><code class=\"language-plaintext highlighter-rouge\">GCA_000017985.1_ASM1798v1_genomic.fna.gz.bwt</code>, the index file (but beware it does not get passed in as-is, the indexing tool expects just the <code class=\"language-plaintext highlighter-rouge\">GCA_000017985.1_ASM1798v1_genomic.fna</code> portion.)</p>\n\n        <p>Also we have our two sequence files <code class=\"language-plaintext highlighter-rouge\">SRR2584866_1.trim.fq SRR2584866_2.trim.fq</code></p>\n      </li>\n      <li>\n        <p>Our output is <code class=\"language-plaintext highlighter-rouge\">SRR2584866.bam</code></p>\n      </li>\n      <li>\n        <p>There are a couple of options we have here, we can supply both the <code class=\"language-plaintext highlighter-rouge\">.fna</code> and the <code class=\"language-plaintext highlighter-rouge\">.fna.gz.bwt</code> file as inputs (not strictly true, we don’t need the fasta file) and then just use the <code class=\"language-plaintext highlighter-rouge\">fna</code> file in the command line, or we can pass in just the <code class=\"language-plaintext highlighter-rouge\">.fna.gz.bwt</code> file and try and calculate the <code class=\"language-plaintext highlighter-rouge\">.fna</code> version that is expected as the index name. We will show the second option as it is more complicated.</p>\n      </li>\n    </ol>\n    <pre class=\"highlight\"><code>rule align:\n\t<span class=\"kt\">input:\n\t\tr1=\"{sample}_1.trim.fq\",\n\t\tr2=\"{sample}_1.trim.fq\",\n\t\tindex=\"{genome}.fna.gz.bwt\"</span>\n\t<span class=\"nb\">output:\n\t\t\"{genome}/{sample}.bam\"</span>\n\t<span class=\"s2\">shell:\n\t\t\"bwa mem {wildcards.genome}.fna {input.r1} {input.r2} | \"\n\t\t\"samtools sort -O bam -o {output}\"</span>\n</code></pre>\n\n    <p>Here we used a number of features to accomplish what we need, and we’ll now go through them. First is <a href=\"https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html#wildcards\">Wildcards</a> which can be used to take a portion of the output name or a portion of the input name and to re-use that in the command line. Here we declared that the first part of the index name up to <code class=\"language-plaintext highlighter-rouge\">.fna.gz.bwt</code> was going to be the <code class=\"language-plaintext highlighter-rouge\">genome</code> wildcard.</p>\n\n    <p>Importantly, we also used this in our output. What would have happened if we didn’t? It would be unresolvable! We would run <code class=\"language-plaintext highlighter-rouge\">snakemake ... output.bam</code> and it would say “I don’t know what value genome should be set to”, so we need to have that value somewhere in our output filename in order to be able to figure that out.</p>\n\n    <p>That isn’t the only way to solve that problem, we could also hardcode this or write it in a <a href=\"https://snakemake.readthedocs.io/en/stable/snakefiles/configuration.html\">config file</a> that is used by snakemake.</p>\n  </blockquote>\n</blockquote>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Add the above outputs to your Pipeline</hands-on-title>\n  <p>If you haven’t already, add the above outputs to your Snakemake pipeline. You should now have a few rules:</p>\n\n  <ul>\n    <li>download</li>\n    <li>fastqc</li>\n    <li>trimmomatic</li>\n    <li>indexgenome</li>\n    <li>align</li>\n  </ul>\n</blockquote>\n\n<h2 id=\"best-practices\">Best Practices</h2>\n\n<p>But this was our very first attempt at a workflow, so what might a best practice workflow look like?</p>\n\n<h3 id=\"conda-for-reproducibility\">Conda for reproducibility</h3>\n\n<p>If you’re not already using conda, you should be! Much scientific software you might be interested in using is already in there, probably mostly provided by the <a href=\"https://anaconda.org/bioconda/repo\">BioConda</a> repository. Writing an environment file can be pretty simple, you just need a file like this, which we customarily put in a folder named <code class=\"language-plaintext highlighter-rouge\">envs/</code></p>\n\n<blockquote class=\"code-in\">\n  <code-in-title>`envs/bwa.yaml`</code-in-title>\n  <div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">channels</span><span class=\"pi\">:</span>\n  <span class=\"pi\">-</span> <span class=\"s\">conda-forge</span>\n  <span class=\"pi\">-</span> <span class=\"s\">bioconda</span>\n  <span class=\"pi\">-</span> <span class=\"s\">defaults</span>\n<span class=\"na\">dependencies</span><span class=\"pi\">:</span>\n  <span class=\"pi\">-</span> <span class=\"s\">bwa=0.7.17</span>\n  <span class=\"pi\">-</span> <span class=\"s\">samtools=1.13</span>\n</code></pre></div>  </div>\n</blockquote>\n\n<p>In the above code sample you can see <code class=\"language-plaintext highlighter-rouge\">bwa=0.7.17</code>, that’s the version of the <code class=\"language-plaintext highlighter-rouge\">bwa</code> mapper we want to use which was found on <a href=\"https://anaconda.org/bioconda/bwa\">the conda repository page</a>. You’ll notice that after it is <code class=\"language-plaintext highlighter-rouge\">=h5bf99c6_8</code>, this is a specific revision of the package that has been ‘pinned’ (i.e. we want to ensure conda installs specifically the version we know works.) That step is not necessary, but if you really care about reproducibility it can be good in a pipeline</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Add conda</hands-on-title>\n  <p>Now you should add Conda environments where appropriate. But where is appropriate? Unix built in tools (wget, curl, gzip, cat, head, tail) generally do not need to be in conda, because they’re very standard across all unix environments.</p>\n\n  <p>Bioinformatics tools on the other hand, these need conda envs.</p>\n\n  <p>Try and add these yourself, and check your work below.</p>\n\n  <p>Please use the following versions:</p>\n\n  <table>\n    <thead>\n      <tr>\n        <th>Package</th>\n        <th>Version</th>\n      </tr>\n    </thead>\n    <tbody>\n      <tr>\n        <td>fastqc</td>\n        <td>0.11.9</td>\n      </tr>\n      <tr>\n        <td>trimmomatic</td>\n        <td>0.39</td>\n      </tr>\n      <tr>\n        <td>bwa</td>\n        <td>0.7.17</td>\n      </tr>\n      <tr>\n        <td>samtools</td>\n        <td>1.13</td>\n      </tr>\n    </tbody>\n  </table>\n\n  <p><em>Hints</em></p>\n  <ol>\n    <li>see above for what a conda environment looks like.</li>\n    <li>You’ll need to install both <code class=\"language-plaintext highlighter-rouge\">bwa</code> and <code class=\"language-plaintext highlighter-rouge\">samtools</code> into the environment for the alignment step.</li>\n    <li>Create the <code class=\"language-plaintext highlighter-rouge\">envs/</code> directory if it does not exist.</li>\n  </ol>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <p><code class=\"language-plaintext highlighter-rouge\">envs/bwa.yaml</code> should look like this:</p>\n\n    <div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">channels</span><span class=\"pi\">:</span>\n  <span class=\"pi\">-</span> <span class=\"s\">conda-forge</span>\n  <span class=\"pi\">-</span> <span class=\"s\">bioconda</span>\n  <span class=\"pi\">-</span> <span class=\"s\">defaults</span>\n<span class=\"na\">dependencies</span><span class=\"pi\">:</span>\n  <span class=\"pi\">-</span> <span class=\"s\">bwa=0.7.17</span>\n  <span class=\"pi\">-</span> <span class=\"s\">samtools=1.13</span>\n</code></pre></div>    </div>\n\n    <p>And here is the <code class=\"language-plaintext highlighter-rouge\">envs/fastqc.yaml</code>:</p>\n\n    <div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">channels</span><span class=\"pi\">:</span>\n  <span class=\"pi\">-</span> <span class=\"s\">conda-forge</span>\n  <span class=\"pi\">-</span> <span class=\"s\">bioconda</span>\n  <span class=\"pi\">-</span> <span class=\"s\">defaults</span>\n<span class=\"na\">dependencies</span><span class=\"pi\">:</span>\n  <span class=\"pi\">-</span> <span class=\"s\">fastqc=0.11.9</span>\n</code></pre></div>    </div>\n\n    <p>And here is the <code class=\"language-plaintext highlighter-rouge\">envs/trimmomatic.yaml</code>:</p>\n\n    <div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">channels</span><span class=\"pi\">:</span>\n  <span class=\"pi\">-</span> <span class=\"s\">conda-forge</span>\n  <span class=\"pi\">-</span> <span class=\"s\">bioconda</span>\n  <span class=\"pi\">-</span> <span class=\"s\">defaults</span>\n<span class=\"na\">dependencies</span><span class=\"pi\">:</span>\n  <span class=\"pi\">-</span> <span class=\"s\">trimmomatic=0.39</span>\n</code></pre></div>    </div>\n\n    <blockquote class=\"comment\">\n      <comment-title>How to read diffs</comment-title>\n      <p>This is a ‘diff’, it shows you the difference between two versions of a text file. Everything added is highlighed in light blue. Anything deleted is shown in black with a strikethrough. Importantly it shows you the context, the bits that are not highlighted, and this helps you know where the changes should go.\nThe first line shows the original file, and the second line shows the new file. If the names are different, it means the file has been renamed.</p>\n\n      <p>The <code class=\"language-plaintext highlighter-rouge\">@@ ... @@</code> line shows the position in the file and how that changes, and often it will also show you the name of the function or in the case of Snakemake, the name of the rule that change appears in.</p>\n    </blockquote>\n\n    <div class=\"language-diff highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"gd\">--- a/Snakefile\n</span><span class=\"gi\">+++ b/Snakefile\n</span><span class=\"p\">@@ -9,6 +9,8 @@</span> rule fastqc:\n \t\t\"{sample}.fq.gz\"\n \toutput:\n \t\t\"{sample}_fastqc.html\"\n<span class=\"gi\">+\tconda:\n+\t\t\"envs/fastqc.yaml\"\n</span> \tshell:\n \t\t\"fastqc {input} --outdir fastqc/\"\n<span class=\"err\">\n</span><span class=\"p\">@@ -21,6 +23,8 @@</span> rule trimmomatic:\n \t\to2=\"{sample}_2.trim.fq\",\n \t\to1un=\"{sample}_1un.trim.fq\",\n \t\to2un=\"{sample}_2un.trim.fq\"\n<span class=\"gi\">+\tconda:\n+\t\t\"envs/trimmomatic.yaml\"\n</span> \tshell:\n \t\t\"trimmomatic PE \"\n \t\t\"{input.r1} {input.r2} \"\n<span class=\"p\">@@ -34,6 +38,8 @@</span> rule indexgenome:\n \t\t\"GCA_000017985.1_ASM1798v1_genomic.fna.gz\"\n \toutput:\n \t\t\"GCA_000017985.1_ASM1798v1_genomic.fna.gz.bwt\"\n<span class=\"gi\">+\tconda:\n+\t\t\"envs/bwa.yaml\"\n</span> \tshell:\n \t\t\"bwa index {input}\"\n<span class=\"err\">\n</span><span class=\"p\">@@ -44,6 +50,8 @@</span> rule align:\n \t\tindex=\"{genome}.fna.gz.bwt\"\n \toutput:\n \t\t\"{genome}/{sample}.bam\"\n<span class=\"gi\">+\tconda:\n+\t\t\"envs/bwa.yaml\"\n</span> \tshell:\n \t\t\"bwa mem {wildcards.genome}.fna {input.r1} {input.r2} | \"\n \t\t\"samtools sort -O bam -o {output}\"\n</code></pre></div>    </div>\n\n    <p>Here in the last two steps we used a single environment, this is a technical decision we made. We could have used a single environment for every step, but with conda the more packages you add, the more complicated it is for Conda to find a version of all of those packages that work together OK. So by isolating packages to single environments, you speed up the installation process. But in two out of four steps above, we have used a shared environment. This is because <code class=\"language-plaintext highlighter-rouge\">bwa</code> was required in both, and one just needs the additional <code class=\"language-plaintext highlighter-rouge\">samtools</code> package. For this there is no real technical reason, just a feeling of “it’s probably ok and won’t be too difficult to resolve”.</p>\n  </blockquote>\n</blockquote>\n\n<h3 id=\"log-files\">Log Files</h3>\n\n<p>Saving log files is key to making sure that you have a complete log of the execution of sotware. If you don’t save the log files, and you’re running a pipeline with 100 samples, it can be very easy to get confused about what went wrong and where. Unfortunately this is not a completely automatic process, and you’ll need to manually configure it:</p>\n\n<blockquote class=\"code-in\">\n  <code-in-title>`Snakefile`</code-in-title>\n  <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>rule indexgenome:\n\tinput:\n\t\t\"{sample}.fna.gz\"\n\toutput:\n\t\t\"{sample}.fna.gz.bwt\"\n\tconda:\n\t\t\"envs/bwa.yaml\"\n\tlog:\n\t\tout=\"logs/bwa.index.{sample}.out\",\n\t\terr=\"logs/bwa.index.{sample}.err\"\n\tshell:\n\t\t\"bwa index {input} &gt;{log.out} 2&gt;{log.err}\"\n</code></pre></div>  </div>\n</blockquote>\n\n<p>In the above rule we setup an <code class=\"language-plaintext highlighter-rouge\">out</code> and <code class=\"language-plaintext highlighter-rouge\">err</code> log file because every program that executes on Linux has two output streams known as <code class=\"language-plaintext highlighter-rouge\">stderr</code> and <code class=\"language-plaintext highlighter-rouge\">stdout</code>. By default these are just printed to your screen, and can be mixed together which is unhelpful when your program writes a lot of logging messages and you have to dig through it to find the one error message. So we setup the <code class=\"language-plaintext highlighter-rouge\">out</code> and <code class=\"language-plaintext highlighter-rouge\">err</code> files in a <code class=\"language-plaintext highlighter-rouge\">logs/</code> directory with the name of the tool that will be executed as well.</p>\n\n<p>Additionally we need to change the <code class=\"language-plaintext highlighter-rouge\">shell</code> step to redirect <code class=\"language-plaintext highlighter-rouge\">stdout</code> and <code class=\"language-plaintext highlighter-rouge\">stderr</code> to the appropriate files. Please see <a href=\"https://wiki.bash-hackers.org/howto/redirection_tutorial\">this bash tutorial</a> for more information on how redirecting outputs works.</p>\n\n<p>But <strong>don’t just copy/paste</strong> the above example because:</p>\n\n<ul>\n  <li>Some tools produce output on stdout, e.g. <code class=\"language-plaintext highlighter-rouge\">bwa mem .. | samtools</code>, there <code class=\"language-plaintext highlighter-rouge\">bwa mem</code> is writing to <code class=\"language-plaintext highlighter-rouge\">stdout</code> which is getting piped to <code class=\"language-plaintext highlighter-rouge\">samtools</code>, so, you should not redirect its output into the logging file or your pipeline will break. There you would only want to redirect <code class=\"language-plaintext highlighter-rouge\">2&gt;{log.err}</code>.</li>\n  <li>Sometimes you have multiple commands in a pipeline, these all should go to different log files or you will have more trouble figuring out where your error came from.</li>\n</ul>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Add log files to every step</hands-on-title>\n\n  <p>Try and add log files everywhere (err and out where appropriate) to all of your rules. And use them in the <code class=\"language-plaintext highlighter-rouge\">shell</code> sections as well. Also put your logs under the <code class=\"language-plaintext highlighter-rouge\">logs/</code> folder!</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <p>This is again a diff, things in blue were added to the file named at the top, things with black highlight were deleted. Think “track changes” mode in Google Docs or Word, except harder to read.</p>\n\n    <div class=\"language-diff highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"gd\">--- a/Snakefile\n</span><span class=\"gi\">+++ b/Snakefile\n</span><span class=\"p\">@@ -1,14 +1,20 @@</span>\n rule download:\n \toutput:\n \t\t\"{sample}.fq.gz\"\n<span class=\"gi\">+\tlog:\n+\t\tout=\"logs/download.{sample}.out\",\n+\t\terr=\"logs/download.{sample}.err\"\n</span> \tshell:\n<span class=\"gd\">-\t\t\"wget https://zenodo.org/record/5562251/files/{wildcards.sample}.fq.gz -O {output}\"\n</span><span class=\"gi\">+\t\t\"wget https://zenodo.org/record/5562251/files/{wildcards.sample}.fq.gz -O {output} &gt;{log.out} 2&gt;{log.err}\"\n</span><span class=\"err\">\n</span> rule download_genome:\n \toutput:\n \t\t\"GCA_000017985.1_ASM1798v1_genomic.fna.gz\"\n<span class=\"gi\">+\tlog:\n+\t\tout=\"logs/download.out\",\n+\t\terr=\"logs/download.err\"\n</span> \tshell:\n<span class=\"gd\">-\t\t\"wget https://zenodo.org/record/5562251/files/GCA_000017985.1_ASM1798v1_genomic.fna.gz -O {output}\"\n</span><span class=\"gi\">+\t\t\"wget https://zenodo.org/record/5562251/files/GCA_000017985.1_ASM1798v1_genomic.fna.gz -O {output} &gt;{log.out} 2&gt;{log.err}\"\n</span><span class=\"err\">\n</span> rule fastqc:\n \tinput:\n<span class=\"p\">@@ -17,8 +23,11 @@</span> rule fastqc:\n \t\t\"{sample}_fastqc.html\"\n \tconda:\n \t\t\"envs/fastqc.yaml\"\n<span class=\"gi\">+\tlog:\n+\t\tout=\"logs/fastqc.{sample}.out\",\n+\t\terr=\"logs/fastqc.{sample}.err\"\n</span> \tshell:\n<span class=\"gd\">-\t\t\"fastqc {input} --outdir fastqc/\"\n</span><span class=\"gi\">+\t\t\"fastqc {input} --outdir fastqc/ &gt;{log.out} 2&gt;{log.err}\"\n</span><span class=\"err\">\n</span> rule trimmomatic:\n \tinput:\n<span class=\"p\">@@ -31,13 +40,16 @@</span> rule trimmomatic:\n \t\to2un=\"{sample}_2un.trim.fq\"\n \tconda:\n \t\t\"envs/trimmomatic.yaml\"\n<span class=\"gi\">+\tlog:\n+\t\tout=\"logs/trimmomatic.{sample}.out\",\n+\t\terr=\"logs/trimmomatic.{sample}.err\"\n</span> \tshell:\n \t\t\"trimmomatic PE \"\n \t\t\"{input.r1} {input.r2} \"\n \t\t\"{output.o1} {output.o1un} \"\n \t\t\"{output.o2} {output.o2un} \"\n \t\t\"SLIDINGWINDOW:4:20 MINLEN:25 \"\n<span class=\"gd\">-\t\t\"ILLUMINACLIP:NexteraPE-PE.fa:2:40:15\"\n</span><span class=\"gi\">+\t\t\"ILLUMINACLIP:NexteraPE-PE.fa:2:40:15 &gt;{log.out} 2&gt;{log.err}\"\n</span><span class=\"err\">\n</span> rule indexgenome:\n \tinput:\n<span class=\"p\">@@ -46,8 +58,11 @@</span> rule indexgenome:\n \t\t\"GCA_000017985.1_ASM1798v1_genomic.fna.gz.bwt\"\n \tconda:\n \t\t\"envs/bwa.yaml\"\n<span class=\"gi\">+\tlog:\n+\t\tout=\"logs/bwa.index.out\",\n+\t\terr=\"logs/bwa.index.err\"\n</span> \tshell:\n<span class=\"gd\">-\t\t\"bwa index {input}\"\n</span><span class=\"gi\">+\t\t\"bwa index {input} &gt;{log.out} 2&gt;{log.err}\"\n</span><span class=\"err\">\n</span> rule align:\n \tinput:\n<span class=\"p\">@@ -58,6 +73,10 @@</span> rule align:\n \t\t\"{genome}/{sample}.bam\"\n \tconda:\n \t\t\"envs/bwa.yaml\"\n<span class=\"gi\">+\tlog:\n+\t\tbwaerr=\"logs/bwa.{genome}.{sample}.err\",\n+\t\tout=\"logs/samtools.{genome}.{sample}.out\",\n+\t\terr=\"logs/samtools.{genome}.{sample}.err\"\n</span> \tshell:\n<span class=\"gd\">-\t\t\"bwa mem {wildcards.genome}.fna {input.r1} {input.r2} | \"\n-\t\t\"samtools sort -O bam -o {output}\"\n</span><span class=\"gi\">+\t\t\"bwa mem {wildcards.genome}.fna {input.r1} {input.r2} 2&gt;{log.bwaerr} | \"\n+\t\t\"samtools sort -O bam -o {output} &gt;{log.out} 2&gt;{log.err}\"\n</span></code></pre></div>    </div>\n\n    <p>The last one is the most complicated. Here we have <code class=\"language-plaintext highlighter-rouge\">bwa mem</code> which writes to <code class=\"language-plaintext highlighter-rouge\">stdout</code>. We know that because a <code class=\"language-plaintext highlighter-rouge\">|</code> character comes next which indicates we’re piping the output from one program to another, so there we want to store the error. However <code class=\"language-plaintext highlighter-rouge\">samtools</code> has a <code class=\"language-plaintext highlighter-rouge\">-o {output}</code> so we can infer from this that it writes to that output file by name. Anything it writes on <code class=\"language-plaintext highlighter-rouge\">stdout</code> or <code class=\"language-plaintext highlighter-rouge\">stderr</code> migth be important.</p>\n  </blockquote>\n</blockquote>\n\n<h3 id=\"use-folders\">Use Folders</h3>\n\n<p>You’ve seen a couple examples above but it’s best to use folders to help keep your data organised. Separate individual pipeline steps into different folders so you can more easily keep track of e.g. whether you’re working with trimmed or untrimmed data.</p>\n\n<blockquote class=\"question\">\n  <question-title></question-title>\n  <p>What sort of folders would you establish for the example pipeline in this tutorial?</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <p>One possible solution you could consider is:</p>\n\n    <table>\n      <thead>\n        <tr>\n          <th>Folder</th>\n          <th>Purpose</th>\n        </tr>\n      </thead>\n      <tbody>\n        <tr>\n          <td>envs</td>\n          <td>Conda environment files</td>\n        </tr>\n        <tr>\n          <td>reads</td>\n          <td>Your sequencing data</td>\n        </tr>\n        <tr>\n          <td>trim</td>\n          <td>Your sequences after they have been trimmed and cleaned</td>\n        </tr>\n        <tr>\n          <td>fastqc</td>\n          <td>The FastQC reports</td>\n        </tr>\n        <tr>\n          <td>alignments</td>\n          <td>All of your final output alignments</td>\n        </tr>\n        <tr>\n          <td>reference</td>\n          <td>Any reference data, indicies, etc.</td>\n        </tr>\n      </tbody>\n    </table>\n  </blockquote>\n</blockquote>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Do it!</hands-on-title>\n  <p>Update your pipeline to have all of datasets stored nicely in folders.</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <div class=\"language-diff highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"gh\">diff --git a/Snakefile b/Snakefile\nindex 59b983c..31ebdff 100644\n</span><span class=\"gd\">--- a/Snakefile\n</span><span class=\"gi\">+++ b/Snakefile\n</span><span class=\"p\">@@ -1,6 +1,6 @@</span>\n rule download:\n \toutput:\n<span class=\"gd\">-\t\t\"{sample}.fq.gz\"\n</span><span class=\"gi\">+\t\t\"reads/{sample}.fq.gz\"\n</span> \tlog:\n \t\tout=\"logs/download.{sample}.out\",\n \t\terr=\"logs/download.{sample}.err\"\n<span class=\"p\">@@ -9,7 +9,7 @@</span> rule download:\n<span class=\"err\">\n</span> rule download_genome:\n \toutput:\n<span class=\"gd\">-\t\t\"GCA_000017985.1_ASM1798v1_genomic.fa.gz\"\n</span><span class=\"gi\">+\t\t\"reference/GCA_000017985.1_ASM1798v1_genomic.fa.gz\"\n</span> \tlog:\n \t\tout=\"logs/download.{sample}.out\",\n \t\terr=\"logs/download.{sample}.err\"\n<span class=\"p\">@@ -18,9 +18,9 @@</span> rule download_genome:\n<span class=\"err\">\n</span> rule fastqc:\n \tinput:\n<span class=\"gd\">-\t\t\"{sample}.fq\"\n</span><span class=\"gi\">+\t\t\"reads/{sample}.fq.gz\"\n</span> \toutput:\n<span class=\"gd\">-\t\t\"{sample}_fastqc.html\"\n</span><span class=\"gi\">+\t\t\"fastqc/{sample}_fastqc.html\"\n</span> \tconda:\n \t\t\"envs/fastqc.yaml\"\n \tlog:\n<span class=\"p\">@@ -31,13 +31,13 @@</span> rule fastqc:\n<span class=\"err\">\n</span> rule trimmomatic:\n \tinput:\n<span class=\"gd\">-\t\tr1=\"{sample}_1.fq\",\n-\t\tr2=\"{sample}_2.fq\"\n</span><span class=\"gi\">+\t\tr1=\"reads/{sample}_1.fq\",\n+\t\tr2=\"reads/{sample}_2.fq\"\n</span> \toutput:\n<span class=\"gd\">-\t\to1=\"{sample}_1.trim.fq\",\n-\t\to2=\"{sample}_2.trim.fq\",\n-\t\to1un=\"{sample}_1un.trim.fq\",\n-\t\to2un=\"{sample}_2un.trim.fq\"\n</span><span class=\"gi\">+\t\to1=\"trim/{sample}_1.trim.fq\",\n+\t\to2=\"trim/{sample}_2.trim.fq\",\n+\t\to1un=\"trim/{sample}_1un.trim.fq\",\n+\t\to2un=\"trim/{sample}_2un.trim.fq\"\n</span> \tconda:\n \t\t\"envs/trimmomatic.yaml\"\n \tlog:\n<span class=\"p\">@@ -53,9 +53,9 @@</span> rule trimmomatic:\n<span class=\"err\">\n</span> rule indexgenome:\n \tinput:\n<span class=\"gd\">-\t\t\"GCA_000017985.1_ASM1798v1_genomic.fna\"\n</span><span class=\"gi\">+\t\t\"reference/GCA_000017985.1_ASM1798v1_genomic.fa\"\n</span> \toutput:\n<span class=\"gd\">-\t\t\"GCA_000017985.1_ASM1798v1_genomic.fna.bwt\"\n</span><span class=\"gi\">+\t\t\"reference/GCA_000017985.1_ASM1798v1_genomic.fa.bwt\"\n</span> \tconda:\n \t\t\"envs/bwa.yaml\"\n \tlog:\n<span class=\"p\">@@ -66,11 +66,11 @@</span> rule indexgenome:\n<span class=\"err\">\n</span> rule align:\n \tinput:\n<span class=\"gd\">-\t\tr1=\"{sample}_1.trim.fq\",\n-\t\tr2=\"{sample}_1.trim.fq\",\n-\t\tindex=\"{genome}.fna.bwt\"\n</span><span class=\"gi\">+\t\tr1=\"trim/{sample}_1.trim.fq\",\n+\t\tr2=\"trim/{sample}_1.trim.fq\",\n+\t\tindex=\"reference/{genome}.fna.bwt\"\n</span> \toutput:\n<span class=\"gd\">-\t\t\"{genome}/{sample}.bam\"\n</span><span class=\"gi\">+\t\t\"alignments/{genome}/{sample}.bam\"\n</span> \tconda:\n \t\t\"envs/bwa.yaml\"\n \tlog:\n<span class=\"p\">@@ -78,5 +78,5 @@</span> rule align:\n \t\tout=\"logs/samtools.{genome}.{sample}.out\",\n \t\terr=\"logs/samtools.{genome}.{sample}.err\"\n \tshell:\n<span class=\"gd\">-\t\t\"bwa mem {wildcard.genome}.fna {input.r1} {input.r2} 2&gt;{log.bwaerr} | \"\n</span><span class=\"gi\">+\t\t\"bwa mem reference/{wildcards.genome}.fna.gz {input.r1} {input.r2} 2&gt;{log.bwaerr} | \"\n</span> \t\t\"samtools sort -O bam -o {output} &gt;{log.out} 2&gt;{log.err}\"\n</code></pre></div>    </div>\n  </blockquote>\n</blockquote>\n\n<p>Notice how while updating data location, we only had to update the input and output boxes of the Snakefile, we didn’t need to change any commands because there we used <code class=\"language-plaintext highlighter-rouge\">{input}</code> or <code class=\"language-plaintext highlighter-rouge\">{output}</code> which are automatically templated for us. Except for the last command where we had to use a wildcard and manually construct the path to work around the issue of ‘fake’ inputs where the tool expected a filename that was the common subset of all of the files it would produce.</p>\n\n<h3 id=\"set-a-default-task\">Set a Default Task</h3>\n\n<p>In the Makefile we had an <code class=\"language-plaintext highlighter-rouge\">all</code> rule which was the first and default action to take. Let’s reproduce that.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Add an all task</hands-on-title>\n  <p>It should build <code class=\"language-plaintext highlighter-rouge\">alignments/GCA_000017985.1_ASM1798v1_genomic/SRR2584863.bam</code></p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n    <p>We add this to the very top of our file.</p>\n    <div class=\"language-diff highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"gd\">--- a/Snakefile\n</span><span class=\"gi\">+++ b/Snakefile\n</span><span class=\"p\">@@ -1,3 +1,7 @@</span>\n<span class=\"gi\">+rule all:\n+\tinput:\n+\t\t\"alignments/GCA_000017985.1_ASM1798v1_genomic/SRR2584863.bam\"\n+\n</span> rule download:\n \toutput:\n \t\t\"reads/{sample}.fq.gz\"\n</code></pre></div>    </div>\n\n    <blockquote class=\"tip\">\n      <tip-title>Why Input and not Output?</tip-title>\n      <p>Because rule all is taking in some other outputs as an input to it. If we used outputs, rule all would do nothing (it has no pre-requisite steps), and since it produces nothing by itself, snakemake would see that the outputs you expected have not been created and flag it as an error.</p>\n    </blockquote>\n\n  </blockquote>\n</blockquote>\n\n<h2 id=\"final-pipeline\">Final Pipeline</h2>\n\n<p>This is starting to look like a pretty good workflow! Let’s preview how it will run:</p>\n\n<blockquote class=\"code-in\">\n  <code-in-title></code-in-title>\n  <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ snakemake -np\n</code></pre></div>  </div>\n</blockquote>\n<blockquote class=\"code-out code-max-300\">\n  <code-out-title></code-out-title>\n  <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Building DAG of jobs...\nJob stats:\njob                count    min threads    max threads\n---------------  -------  -------------  -------------\nalign                  1              1              1\nall                    1              1              1\ndownload               2              1              1\ndownload_genome        1              1              1\nindexgenome            1              1              1\ntrimmomatic            1              1              1\ntotal                  7              1              1\n\n\n[Fri Oct  8 16:59:39 2021]\nrule download:\n    output: reads/SRR2584863_2.fq.gz\n    log: logs/download.SRR2584863_2.out, logs/download.SRR2584863_2.err\n    jobid: 4\n    wildcards: sample=SRR2584863_2\n    resources: tmpdir=/tmp\n\nwget https://zenodo.org/record/5562251/SRR2584863_2.fq.gz -O reads/SRR2584863_2.fq.gz &gt;logs/download.SRR2584863_2.out 2&gt;logs/download.SRR2584863_2.err\n\n[Fri Oct  8 16:59:39 2021]\nrule download:\n    output: reads/SRR2584863_1.fq.gz\n    log: logs/download.SRR2584863_1.out, logs/download.SRR2584863_1.err\n    jobid: 3\n    wildcards: sample=SRR2584863_1\n    resources: tmpdir=/tmp\n\nwget https://zenodo.org/record/5562251/SRR2584863_1.fq.gz -O reads/SRR2584863_1.fq.gz &gt;logs/download.SRR2584863_1.out 2&gt;logs/download.SRR2584863_1.err\n\n[Fri Oct  8 16:59:39 2021]\nrule download_genome:\n    output: reference/GCA_000017985.1_ASM1798v1_genomic.fna.gz\n    log: logs/download.out, logs/download.err\n    jobid: 6\n    resources: tmpdir=/tmp\n\nwget https://zenodo.org/record/5562251/GCA_000017985.1_ASM1798v1_genomic.fna.gz -O reference/GCA_000017985.1_ASM1798v1_genomic.fna.gz &gt;logs/download.out 2&gt;logs/download.err\n\n[Fri Oct  8 16:59:39 2021]\nrule trimmomatic:\n    input: reads/SRR2584863_1.fq.gz, reads/SRR2584863_2.fq.gz\n    output: trim/SRR2584863_1.trim.fq, trim/SRR2584863_2.trim.fq, trim/SRR2584863_1un.trim.fq, trim/SRR2584863_2un.trim.fq\n    log: logs/trimmomatic.SRR2584863.out, logs/trimmomatic.SRR2584863.err\n    jobid: 2\n    wildcards: sample=SRR2584863\n    resources: tmpdir=/tmp\n\ntrimmomatic PE reads/SRR2584863_1.fq.gz reads/SRR2584863_2.fq.gz trim/SRR2584863_1.trim.fq trim/SRR2584863_1un.trim.fq trim/SRR2584863_2.trim.fq trim/SRR2584863_2un.trim.fq SLIDINGWINDOW:4:20 MINLEN:25 ILLUMINACLIP:NexteraPE-PE.fa:2:40:15 &gt;logs/trimmomatic.SRR2584863.out 2&gt;logs/trimmomatic.SRR2584863.err\n\n[Fri Oct  8 16:59:39 2021]\nrule indexgenome:\n    input: reference/GCA_000017985.1_ASM1798v1_genomic.fna.gz\n    output: reference/GCA_000017985.1_ASM1798v1_genomic.fna.gz.bwt\n    log: logs/bwa.index.out, logs/bwa.index.err\n    jobid: 5\n    resources: tmpdir=/tmp\n\nbwa index reference/GCA_000017985.1_ASM1798v1_genomic.fna.gz &gt;logs/bwa.index.out 2&gt;logs/bwa.index.err\n\n[Fri Oct  8 16:59:39 2021]\nrule align:\n    input: trim/SRR2584863_1.trim.fq, trim/SRR2584863_1.trim.fq, reference/GCA_000017985.1_ASM1798v1_genomic.fna.gz.bwt\n    output: alignments/GCA_000017985.1_ASM1798v1_genomic/SRR2584863.bam\n    log: logs/bwa.GCA_000017985.1_ASM1798v1_genomic.SRR2584863.err, logs/samtools.GCA_000017985.1_ASM1798v1_genomic.SRR2584863.out, logs/samtools.GCA_000017985.1_ASM1798v1_genomic.SRR2584863.err\n    jobid: 1\n    wildcards: genome=GCA_000017985.1_ASM1798v1_genomic, sample=SRR2584863\n    resources: tmpdir=/tmp\n\nbwa mem reference/GCA_000017985.1_ASM1798v1_genomic.fna.gz trim/SRR2584863_1.trim.fq trim/SRR2584863_1.trim.fq 2&gt;logs/bwa.GCA_000017985.1_ASM1798v1_genomic.SRR2584863.err | samtools sort -O bam -o alignments/GCA_000017985.1_ASM1798v1_genomic/SRR2584863.bam &gt;logs/samtools.GCA_000017985.1_ASM1798v1_genomic.SRR2584863.out 2&gt;logs/samtools.GCA_000017985.1_ASM1798v1_genomic.SRR2584863.err\n\n[Fri Oct  8 16:59:39 2021]\nlocalrule all:\n    input: alignments/GCA_000017985.1_ASM1798v1_genomic/SRR2584863.bam\n    jobid: 0\n    resources: tmpdir=/tmp\n\nJob stats:\njob                count    min threads    max threads\n---------------  -------  -------------  -------------\nalign                  1              1              1\nall                    1              1              1\ndownload               2              1              1\ndownload_genome        1              1              1\nindexgenome            1              1              1\ntrimmomatic            1              1              1\ntotal                  7              1              1\n\nThis was a dry-run (flag -n). The order of jobs does not reflect the order of execution.\n</code></pre></div>  </div>\n</blockquote>\n\n<p>Gosh that’s a lot of output! Let’s build the <abbr title=\"Directed Acyclic Graph\">DAG</abbr> to see a more concise representation of what is going to happen:</p>\n\n<blockquote class=\"code-in\">\n  <code-in-title></code-in-title>\n  <div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>snakemake <span class=\"nt\">--dag</span> | dot <span class=\"nt\">-Tsvg</span> <span class=\"o\">&gt;</span> out.svg\n</code></pre></div>  </div>\n</blockquote>\n\n<blockquote class=\"code-out\">\n  <code-out-title></code-out-title>\n  <p><a href=\"../../images/snakemake.dag.svg\" rel=\"noopener noreferrer\"><img src=\"../../images/snakemake.dag.svg\" alt=\"Image of the snakemake dag. Conspicuously missing is FastQC jobs!\" loading=\"lazy\" /></a></p>\n</blockquote>\n\n<p>But wait, where is FastQC? It’s missing! 😱 Let’s summarize the transition from a Makefile to a Snakemake file and then we’ll cover the case of the missing FastQC.</p>\n\n<h2 id=\"why-snakemake\">Why Snakemake</h2>\n\n<p>So now comes the question, why Snakemake? <strong>Better for science</strong>. While it is quite similar to good old <code class=\"language-plaintext highlighter-rouge\">make</code>, Snakemake adds several features that are important for science like dependency management with Conda/Docker/Singularity, and better execution on HPCs and Clusters.</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Aspect</th>\n      <th>Make</th>\n      <th>Snakemake</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Language style</td>\n      <td>Generic rules are written which say how to do the operation, but not on which data</td>\n      <td>Same</td>\n    </tr>\n    <tr>\n      <td>Partial re-run</td>\n      <td>Only the missing files are created</td>\n      <td>Same</td>\n    </tr>\n    <tr>\n      <td>How it is invoked</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">make</code></td>\n      <td><code class=\"language-plaintext highlighter-rouge\">snakemake</code></td>\n    </tr>\n    <tr>\n      <td>Running with different data?</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">make read1111.sam read2222.sam</code></td>\n      <td><code class=\"language-plaintext highlighter-rouge\">snakemake read1111.sam read2222.sam</code></td>\n    </tr>\n    <tr>\n      <td>Paralellisation?</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">make -j 8</code></td>\n      <td><code class=\"language-plaintext highlighter-rouge\">snakemake --cores 8</code></td>\n    </tr>\n    <tr>\n      <td>Filename</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">Makefile</code></td>\n      <td><code class=\"language-plaintext highlighter-rouge\">Snakefile</code></td>\n    </tr>\n    <tr>\n      <td>Dependencies</td>\n      <td>Up to you to manage</td>\n      <td>Built-in dependency management with Conda</td>\n    </tr>\n    <tr>\n      <td>Multiple output files per step</td>\n      <td>A bit tricky</td>\n      <td>Incredibly easy</td>\n    </tr>\n    <tr>\n      <td>Cluster/HPC Friendliness</td>\n      <td>Everything is manual</td>\n      <td>Very good support</td>\n    </tr>\n  </tbody>\n</table>\n\n<h2 id=\"the-case-of-the-missing-fastqc\">The Case of the Missing FastQC</h2>\n\n<p>If you were reading closely above you’ve noticed we mention several times:</p>\n\n<blockquote class=\"quote\">\n  <p>outputs are only created when they’re needed</p>\n</blockquote>\n\n<p>This meant that if a file already existed on disk, Make and Snakemake would not re-run that step. Smart! But it <em>also</em> meant that if your <code class=\"language-plaintext highlighter-rouge\">all</code> rule did not mention a file, or if any of the tasks that were required to make the final output didn’t include or use the output of FastQC, then that file would not be created.</p>\n\n<p>So naturally when we request the final <code class=\"language-plaintext highlighter-rouge\">bam</code> file, and none of the steps leading up to it need that FastQC output, of course it doesn’t run. To fix that, we need to declare FastQC as one of our pipeline’s outputs. Let’s look at how to solve this.</p>\n\n<h3 id=\"expand\">expand</h3>\n\n<p>You can use this function in inputs and outputs to help you list all expected files, without having to write out or hardcode that list of files. Here we define a <code class=\"language-plaintext highlighter-rouge\">sorted_reads/{sample}.bam</code> and then this is repeated for every value of samples</p>\n\n<blockquote class=\"code-in\">\n  <code-in-title>Snakemake Code</code-in-title>\n  <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>SAMPLES = [\"a\", \"b\", \"c\"]\nexpand(\"sorted_reads/{sample}.bam\", sample=SAMPLES)\n</code></pre></div>  </div>\n</blockquote>\n<blockquote class=\"code-out\">\n  <code-out-title>Snakemake Output</code-out-title>\n  <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>[\"sorted_reads/a.bam\", \"sorted_reads/b.bam\", \"sorted_reads/c.bam\"]\n</code></pre></div>  </div>\n</blockquote>\n\n<p>This can also be used with multiple variables:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>expand(\"sorted_reads/{sample}.{replicate}.bam\", sample=SAMPLES, replicate=[0, 1])\n</code></pre></div></div>\n\n<p>We should use something exactly like this for our samples. We can have a <code class=\"language-plaintext highlighter-rouge\">SAMPLES</code> variable representing our final output bam files we wish to generate, and then instead of <code class=\"language-plaintext highlighter-rouge\">replicates</code> we’ll have <code class=\"language-plaintext highlighter-rouge\">_1</code> and <code class=\"language-plaintext highlighter-rouge\">_2</code> or so. First let’s make the change to use the <code class=\"language-plaintext highlighter-rouge\">SAMPLES</code> and expand just for our final output.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Update `all` task to use expand</hands-on-title>\n  <p>And while you’re at it, define <code class=\"language-plaintext highlighter-rouge\">SAMPLES</code> to be a list (like in python) with two elements:</p>\n  <ul>\n    <li><code class=\"language-plaintext highlighter-rouge\">SRR2584863</code></li>\n    <li><code class=\"language-plaintext highlighter-rouge\">SRR2589044</code></li>\n  </ul>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <div class=\"language-diff highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"gd\">--- a/Snakefile\n</span><span class=\"gi\">+++ b/Snakefile\n</span><span class=\"p\">@@ -1,6 +1,8 @@</span>\n<span class=\"gi\">+SAMPLES = ['SRR2584863', 'SRR2589044']\n+\n</span> rule all:\n \tinput:\n<span class=\"gd\">-\t\t\"alignments/GCA_000017985.1_ASM1798v1_genomic/SRR2584863.bam\"\n</span><span class=\"gi\">+\t\texpand(\"alignments/GCA_000017985.1_ASM1798v1_genomic/{sample}.bam\", sample=SAMPLES)\n</span><span class=\"err\">\n</span> rule download:\n \toutput:\n</code></pre></div>    </div>\n  </blockquote>\n</blockquote>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Run the pipeline</hands-on-title>\n  <p>Run <code class=\"language-plaintext highlighter-rouge\">snakemake -c4 --use-conda</code>. Did it work?</p>\n</blockquote>\n\n<h3 id=\"adding-all-fastqc-reports\">Adding all FastQC reports</h3>\n\n<p>Now that you’ve done one expand, let’s do a more complicated one. The expand function can take multiple variables which we can use to expand both our samples AND our expected extensions</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Add FastQC outputs to `all`</hands-on-title>\n  <p>Which file extensions do we expect to see? (e.g. <code class=\"language-plaintext highlighter-rouge\">_1.fastqc</code>) Make a single expand that uses two variables, <code class=\"language-plaintext highlighter-rouge\">{sample}</code> and <code class=\"language-plaintext highlighter-rouge\">{ext}</code>? Add an expand that uses our previously defined <code class=\"language-plaintext highlighter-rouge\">SAMPLES</code> and now also a list of the extensions we expect.</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <div class=\"language-diff highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"gd\">--- a/Snakefile\n</span><span class=\"gi\">+++ b/Snakefile\n</span><span class=\"p\">@@ -2,7 +2,8 @@</span> SAMPLES = ['SRR2584863', 'SRR2589044']\n<span class=\"err\">\n</span> rule all:\n \tinput:\n<span class=\"gd\">-\t\texpand(\"alignments/GCA_000017985.1_ASM1798v1_genomic/{sample}.bam\", sample=SAMPLES)\n</span><span class=\"gi\">+\t\texpand(\"alignments/GCA_000017985.1_ASM1798v1_genomic/{sample}.bam\", sample=SAMPLES),\n+\t\texpand(\"fastqc/{sample}{ext}\", sample=SAMPLES, ext=[\"_1_fastqc.html\", \"_2_fastqc.html\"])\n</span><span class=\"err\">\n</span> rule download:\n \toutput:\n</code></pre></div>    </div>\n\n    <blockquote class=\"tip\">\n      <tip-title>Why not `_1.fastqc.html`?</tip-title>\n\n      <p>There’s not always a good answer for this, some tools will mangle names in unexpected ways. The best way to discover this in a <abbr title=\"Scientific Workflow Management System\">SciWMS</abbr> like Snakemake is to just write what you expect, and run it, and see how it fails. Here the filenames were not as expected, so, we updated the <code class=\"language-plaintext highlighter-rouge\">ext</code> to use <code class=\"language-plaintext highlighter-rouge\">_1_fastqc.html</code> and everything works. This was done by <code class=\"language-plaintext highlighter-rouge\">fastqc</code> so if we really wanted the other style of naming we could read the FastQC manual to maybe determine why.</p>\n\n      <p>Here Snakemake failed, complaining “the output files weren’t created”, but we could ee they were, just not with the expected filename.</p>\n    </blockquote>\n  </blockquote>\n</blockquote>\n\n<p>Success! We’ve got a bunch of FastQC reports. But something is wrong, we only have the pre-trimming reports, none of the post-trimming reports. You can see why in our FastQC rule:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>rule fastqc:\n\tinput:\n\t\t\"reads/{sample}.fq.gz\"\n</code></pre></div></div>\n\n<p>This rule only knows how to input files from the <code class=\"language-plaintext highlighter-rouge\">reads</code> directory. We have some options:</p>\n\n<ol>\n  <li>We can probably most easily solve this by simply replacing our <code class=\"language-plaintext highlighter-rouge\">trimmed</code> folder with the <code class=\"language-plaintext highlighter-rouge\">reads</code> folder and making them the same. This way all fastq files will be in the same place, but perhaps it will be less clear later which files we can delete if we need to clean up. Right now we know we can remove the <code class=\"language-plaintext highlighter-rouge\">trimmed</code> folder if we need some space, and our pipeline can re-create the data. If we mixed them, it would be slightly more complicated.</li>\n  <li>\n    <p>We could probably use <code class=\"language-plaintext highlighter-rouge\">reads</code> as a wildcard (like our <code class=\"language-plaintext highlighter-rouge\">{genome}</code> or <code class=\"language-plaintext highlighter-rouge\">{sample}</code>), but here we’d have to have some additional complexity as a result, like the folder name would en up part of the <code class=\"language-plaintext highlighter-rouge\">output</code> name, as is required by <code class=\"language-plaintext highlighter-rouge\">Snakemake</code> to prevent accidental conflicts.</p>\n\n    <blockquote class=\"tip\">\n      <tip-title>How would this look?</tip-title>\n      <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>--- a/Snakefile\n+++ b/Snakefile\n@@ -16,16 +16,16 @@ rule download:\n\n rule fastqc:\n        input:\n-               \"reads/{sample}.fq.gz\"\n+               \"{folder}/{sample}.fq.gz\"\n        output:\n-               \"fastqc/{sample}_fastqc.html\"\n+               \"fastqc/{folder}-{sample}_fastqc.html\"\n        conda:\n                \"envs/fastqc.yaml\"\n        log:\n-               out=\"logs/fastqc.{sample}.out\",\n-               err=\"logs/fastqc.{sample}.err\"\n+               out=\"logs/fastqc.{folder}-{sample}.out\",\n+               err=\"logs/fastqc.{folder}-{sample}.err\"\n        shell:\n                \"fastqc {input} --outdir fastqc/ &gt;{log.out} 2&gt;{log.err}\"\n</code></pre></div>      </div>\n    </blockquote>\n  </li>\n  <li>Or, we could duplicate the fastqc rule, and have a separate rule for <code class=\"language-plaintext highlighter-rouge\">fastqc-trimmed</code> that also outputs to a separate folder</li>\n</ol>\n\n<p>So with that said, let’s go with option three, duplicate our fastqc rule to have a <code class=\"language-plaintext highlighter-rouge\">fastqc-trimmed</code> version</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Add FastQC outputs to `all`</hands-on-title>\n  <p>Copy the rule and rename it appropriately, changing all of the variables where necessary to take in trimmed fastq files.</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <div class=\"language-diff highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"gd\">--- a/Snakefile\n</span><span class=\"gi\">+++ b/Snakefile\n</span><span class=\"p\">@@ -3,7 +3,8 @@</span> SAMPLES = ['SRR2584863', 'SRR2589044']\n rule all:\n \tinput:\n \t\texpand(\"alignments/GCA_000017985.1_ASM1798v1_genomic/{sample}.bam\", sample=SAMPLES),\n<span class=\"gd\">-\t\texpand(\"fastqc/{sample}{ext}\", sample=SAMPLES, ext=[\"_1_fastqc.html\", \"_2_fastqc.html\"])\n</span><span class=\"gi\">+\t\texpand(\"fastqc/{sample}{ext}\", sample=SAMPLES, ext=[\"_1_fastqc.html\", \"_2_fastqc.html\"]),\n+\t\texpand(\"fastqc-trim/{sample}{ext}\", sample=SAMPLES, ext=[\"_1_fastqc.html\", \"_2_fastqc.html\", \"_1un_fastqc.html\", \"_2un_fastqc.html\"])\n</span><span class=\"err\">\n</span> rule download:\n \toutput:\n<span class=\"p\">@@ -36,6 +37,19 @@</span> rule fastqc:\n \tshell:\n \t\t\"fastqc {input} --outdir fastqc/ &gt;{log.out} 2&gt;{log.err}\"\n<span class=\"err\">\n</span><span class=\"gi\">+rule fastqc_trim:\n+\tinput:\n+\t\t\"reads/{sample}.fq.gz\"\n+\toutput:\n+\t\t\"fastqc/{sample}_fastqc.html\"\n+\tconda:\n+\t\t\"envs/fastqc.yaml\"\n+\tlog:\n+\t\tout=\"logs/fastqc.{sample}.out\",\n+\t\terr=\"logs/fastqc.{sample}.err\"\n+\tshell:\n+\t\t\"fastqc {input} --outdir fastqc/ &gt;{log.out} 2&gt;{log.err}\"\n+\n</span> rule trimmomatic:\n \tinput:\n \t\tr1=\"reads/{sample}_1.fq.gz\",\n</code></pre></div>    </div>\n\n  </blockquote>\n</blockquote>\n\n<p>Ok! That’s hopefully went successfully. Run your pipeline to check.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title></hands-on-title>\n\n  <ol>\n    <li>Dry-run snakemake\n      <blockquote class=\"code-in\">\n        <code-in-title>CLI</code-in-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>snakemake -np\n</code></pre></div>        </div>\n      </blockquote>\n\n      <blockquote class=\"code-out\">\n        <code-out-title></code-out-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Building DAG of jobs...\nAmbiguousRuleException:\nRules fastqc_trim and fastqc are ambiguous for the file fastqc/SRR2584863_1_fastqc.html.\nConsider starting rule output with a unique prefix, constrain your wildcards, or use the ruleorder directive.\nWildcards:\n\tfastqc_trim: sample=SRR2584863_1\n\tfastqc: sample=SRR2584863_1\nExpected input files:\n\tfastqc_trim: reads/SRR2584863_1.fq.gz\n\tfastqc: reads/SRR2584863_1.fq.gz\nExpected output files:\n\tfastqc_trim: fastqc/SRR2584863_1_fastqc.html\n\tfastqc: fastqc/SRR2584863_1_fastqc.html\n</code></pre></div>        </div>\n      </blockquote>\n    </li>\n    <li>\n      <p>Uhoh! There was an error. If we read the error message we see <strong>Rules fastqc_trim and fastqc are ambiguous for the file fastqc/SRR2584863_1_fastq</strong>, because both rules produce the same file. We should rename the folder, <code class=\"language-plaintext highlighter-rouge\">fastqc-trimmed</code>.</p>\n\n      <div class=\"language-diff highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"gd\">--- a/Snakefile\n</span><span class=\"gi\">+++ b/Snakefile\n</span><span class=\"p\">@@ -28,7 +28,7 @@</span> rule fastqc:\n \tinput:\n \t\t\"reads/{sample}.fq.gz\"\n \toutput:\n<span class=\"gd\">-\t\t\"fastqc/{sample}_fastqc.html\"\n</span><span class=\"gi\">+\t\t\"fastqc-trim/{sample}_fastqc.html\"\n</span> \tconda:\n \t\t\"envs/fastqc.yaml\"\n \tlog:\n</code></pre></div>      </div>\n    </li>\n    <li>\n      <p>Re-run the dry-run.</p>\n\n      <blockquote class=\"code-in\">\n        <code-in-title>CLI</code-in-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>snakemake -np\n</code></pre></div>        </div>\n      </blockquote>\n\n      <blockquote class=\"code-in\">\n        <code-in-title>CLI</code-in-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>...\nJob stats:\njob         count    min threads    max threads\n--------  -------  -------------  -------------\nall             1              1              1\ndownload        4              1              1\nfastqc          8              1              1\ntotal          13              1              1\n\nThis was a dry-run (flag -n). The order of jobs does not reflect the order of execution.\n</code></pre></div>        </div>\n      </blockquote>\n    </li>\n    <li>That looks good!</li>\n  </ol>\n</blockquote>\n\n<p>Now that we’ve got a pipeline successfully completing the dry-run, let’s try it again.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Run the pipeline!</hands-on-title>\n  <ol>\n    <li>\n      <p>Run the pipeline</p>\n\n      <blockquote class=\"code-in\">\n        <code-in-title>CLI</code-in-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>snakemake --use-conda -c4\n</code></pre></div>        </div>\n      </blockquote>\n\n      <blockquote class=\"code-in\">\n        <code-in-title>CLI</code-in-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Error in rule download:\nRemoving output files of failed job download since they might be corrupted:\nreads/SRR2584863_2un.fq.gz\n    jobid: 24\n    output: reads/SRR2589044_1un.fq.gz\n    log: logs/download.SRR2589044_1un.out, logs/download.SRR2589044_1un.err (check log file(s) for error message)\n    shell:\n        wget https://zenodo.org/record/5562251/SRR2589044_1un.fq.gz -O reads/SRR2589044_1un.fq.gz &gt;logs/download.SRR2589044_1un.out 2&gt;logs/download.SRR2589044_1un.err\n        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)\n\nRemoving output files of failed job download since they might be corrupted:\nreads/SRR2589044_1un.fq.gz\n[Fri Oct  8 17:15:46 2021]\nError in rule download:\n    jobid: 26\n    output: reads/SRR2589044_2un.fq.gz\n    log: logs/download.SRR2589044_2un.out, logs/download.SRR2589044_2un.err (check log file(s) for error message)\n    shell:\n        wget https://zenodo.org/record/5562251/SRR2589044_2un.fq.gz -O reads/SRR2589044_2un.fq.gz &gt;logs/download.SRR2589044_2un.out 2&gt;logs/download.SRR2589044_2un.err\n        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)\n\nRemoving output files of failed job download since they might be corrupted:\nreads/SRR2589044_2un.fq.gz\nWaiting at most 5 seconds for missing files.\nMissingOutputException in line 55 of /tmp/snake.q5mqtdhfg6/Snakefile:\nJob Missing files after 5 seconds:\nfastqc-trim/SRR2589044_1_fastqc.html\nThis might be due to filesystem latency. If that is the case, consider to increase the wait time with --latency-wait.\nJob id: 21 completed successfully, but some output files are missing. 21\n</code></pre></div>        </div>\n      </blockquote>\n    </li>\n    <li>\n      <p>Now it is complaining that it cannot download the requested files, we didn’t even want to download new read files, we should have used the files from the <code class=\"language-plaintext highlighter-rouge\">trimmed</code> folder. Let’s fix our rule again.</p>\n\n      <div class=\"language-diff highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"gd\">--- a/Snakefile\n</span><span class=\"gi\">+++ b/Snakefile\n</span><span class=\"p\">@@ -26,7 +26,7 @@</span> rule download_genome:\n<span class=\"err\">\n</span> rule fastqc:\n \tinput:\n<span class=\"gd\">-\t\t\"reads/{sample}.fq.gz\"\n</span><span class=\"gi\">+\t\t\"trim/{sample}.fq.gz\"\n</span> \toutput:\n \t\t\"fastqc-trim/{sample}_fastqc.html\"\n \tconda:\n</code></pre></div>      </div>\n    </li>\n    <li>\n      <p>And dry-run</p>\n\n      <blockquote class=\"code-in\">\n        <code-in-title>CLI</code-in-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>snakemake -np\n</code></pre></div>        </div>\n      </blockquote>\n\n      <blockquote class=\"code-out\">\n        <code-out-title>CLI</code-out-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Building DAG of jobs...\nMissingInputException in line 55 of /tmp/snake.q5mqtdhfg6/Snakefile:\nMissing input files for rule fastqc:\ntrim/SRR2584863_1.fq.gz\n</code></pre></div>        </div>\n      </blockquote>\n    </li>\n    <li>\n      <p>Ok, now it says it can’t find the input file. The <code class=\"language-plaintext highlighter-rouge\">.gz</code> suffix wasn’t part of the <code class=\"language-plaintext highlighter-rouge\">trim</code> output filenames, and if we look there they all have <code class=\"language-plaintext highlighter-rouge\">.trim.fq</code> as the suffix. Let’s use that.</p>\n\n      <div class=\"language-diff highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"gd\">--- a/Snakefile\n</span><span class=\"gi\">+++ b/Snakefile\n</span><span class=\"p\">@@ -26,7 +26,7 @@</span> rule download_genome:\n<span class=\"err\">\n</span> rule fastqc:\n \tinput:\n<span class=\"gd\">-\t\t\"trim/{sample}.fq.gz\"\n</span><span class=\"gi\">+\t\t\"trim/{sample}.trim.fq\"\n</span> \toutput:\n \t\t\"fastqc-trim/{sample}_fastqc.html\"\n \tconda:\n</code></pre></div>      </div>\n    </li>\n    <li>\n      <p>And finally? Success?</p>\n\n      <blockquote class=\"code-in\">\n        <code-in-title>CLI</code-in-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>snakemake --use-conda -c4\n</code></pre></div>        </div>\n      </blockquote>\n\n      <blockquote class=\"code-out\">\n        <code-out-title>Output</code-out-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>   raise IOError(\nOSError: Missing files after 5 seconds:\nfastqc-trim/SRR2589044_1_fastqc.html\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n File \"/home/hxr/arbeit/deps/miniconda3.9/envs/gtn-test/lib/python3.9/site-packages/snakemake/scheduler.py\", line 529, in _finish_jobs\n   self.get_executor(job).handle_job_success(job)\n File \"/home/hxr/arbeit/deps/miniconda3.9/envs/gtn-test/lib/python3.9/site-packages/snakemake/executors/__init__.py\", line 608, in handle_job_success\n   super().handle_job_success(job)\n File \"/home/hxr/arbeit/deps/miniconda3.9/envs/gtn-test/lib/python3.9/site-packages/snakemake/executors/__init__.py\", line 265, in handle_job_success\n   job.postprocess(\n File \"/home/hxr/arbeit/deps/miniconda3.9/envs/gtn-test/lib/python3.9/site-packages/snakemake/jobs.py\", line 1011, in postprocess\n   self.dag.check_and_touch_output(\n File \"/home/hxr/arbeit/deps/miniconda3.9/envs/gtn-test/lib/python3.9/site-packages/snakemake/dag.py\", line 500, in check_and_touch_output\n   raise MissingOutputException(\nsnakemake.exceptions.MissingOutputException: Job Missing files after 5 seconds:\nfastqc-trim/SRR2589044_1_fastqc.html\nThis might be due to filesystem latency. If that is the case, consider to increase the wait time with --latency-wait.\nJob id: 19 completed successfully, but some output files are missing. 19\n</code></pre></div>        </div>\n      </blockquote>\n\n      <p>Shoot! No, ok. If we read this message it says <strong>Job Missing files after 5 seconds</strong> which means it couldn’t find the file. Specifically it tells us it is missing <code class=\"language-plaintext highlighter-rouge\">fastqc-trim/SRR2589044_1_fastqc.html</code> and that makes sense, since all of our output fastqc reports had the full input name, so those should have <code class=\"language-plaintext highlighter-rouge\">trim</code> in them too.</p>\n\n      <blockquote class=\"tip\">\n        <tip-title>Filesystem Latency?</tip-title>\n        <p>On servers with shared directories using Network File Systems, it can happen that when you run a job on one machine, it may take time for the files to be visible on other machines, it isn’t instantaneous. In our case this is <strong>not</strong> the issue.</p>\n      </blockquote>\n    </li>\n    <li>Let’s see what files are available, so we know how to fix the command.\n      <blockquote class=\"code-in\">\n        <code-in-title>CLI</code-in-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>ls fastqc-trim\n</code></pre></div>        </div>\n      </blockquote>\n\n      <blockquote class=\"code-out\">\n        <code-out-title>Output</code-out-title>\n        <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>SRR2584863_1.trim_fastqc.html    SRR2584863_2.trim_fastqc.html\nSRR2589044_1.trim_fastqc.html    SRR2589044_2.trim_fastqc.html\nSRR2584863_1.trim_fastqc.zip     SRR2584863_2.trim_fastqc.zip\nSRR2589044_1.trim_fastqc.zip     SRR2589044_2.trim_fastqc.zip\nSRR2584863_1un.trim_fastqc.html  SRR2584863_2un.trim_fastqc.html\nSRR2589044_1un.trim_fastqc.html  SRR2589044_2un.trim_fastqc.html\nSRR2584863_1un.trim_fastqc.zip   SRR2584863_2un.trim_fastqc.zip\nSRR2589044_1un.trim_fastqc.zip   SRR2589044_2un.trim_fastqc.zip\n</code></pre></div>        </div>\n      </blockquote>\n    </li>\n    <li>\n      <p>So we need to adjust our <code class=\"language-plaintext highlighter-rouge\">all</code> rule where we requested the files with the wrong names.</p>\n\n      <div class=\"language-diff highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"gd\">--- a/Snakefile\n</span><span class=\"gi\">+++ b/Snakefile\n</span><span class=\"p\">@@ -4,7 +4,7 @@</span> rule all:\n \tinput:\n \t\texpand(\"alignments/GCA_000017985.1_ASM1798v1_genomic/{sample}.bam\", sample=SAMPLES),\n \t\texpand(\"fastqc/{sample}{ext}\", sample=SAMPLES, ext=[\"_1_fastqc.html\", \"_2_fastqc.html\"]),\n<span class=\"gd\">-\t\texpand(\"fastqc-trim/{sample}{ext}\", sample=SAMPLES, ext=[\"_1_fastqc.html\", \"_2_fastqc.html\", \"_1un_fastqc.html\", \"_2un_fastqc.html\"])\n</span><span class=\"gi\">+\t\texpand(\"fastqc-trim/{sample}{ext}\", sample=SAMPLES, ext=[\"_1.trim_fastqc.html\", \"_2.trim_fastqc.html\", \"_1un.trim_fastqc.html\", \"_2un.trim_fastqc.html\"])\n</span><span class=\"err\">\n</span> rule download:\n \toutput:\n</code></pre></div>      </div>\n    </li>\n    <li>\n      <p>Maybe it works now? Yes! Huzzah!</p>\n\n      <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>[Fri Oct  8 17:25:41 2021]\nFinished job 0.\n15 of 15 steps (100%) done\nComplete log: /tmp/snake.q5mqtdhfg6/.snakemake/log/2021-10-08T172535.438752.snakemake.log\n</code></pre></div>      </div>\n    </li>\n  </ol>\n\n</blockquote>\n\n<p>This interactive debugging of your pipeline is <strong>very common</strong>, if you need to write a pipeline expect to go through a development cycle like this, where you make a change or write a rule, dry-run, and run, and find errors that you need to fix.</p>\n\n<p>This is why we always work with test datasets to confirm our pipeline works first, and then we scale up to big data.</p>\n\n<h3 id=\"multiqc\">MultiQC</h3>\n\n<p>As a last step, we’ll summarize all of the FastQC files. With all of the expands at the top, we’re now receiving 4 trimmed FastQC reports plus 2 untrimmed FastQC reports per sample which is a lot of data to go through! So we can use MultiQC to aggregate all of these files and generate a single summary file which makes analysis much easier.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Add the MultiQC step</hands-on-title>\n  <p>The command we need to run is: <code class=\"language-plaintext highlighter-rouge\">multiqc --outdir multiqc *fastqc.zip</code>. You cannot use wildcards like that in Snakemake, so write this out as a proper rule that accepts all of the same inputs as you used in the <code class=\"language-plaintext highlighter-rouge\">rule all</code>. It outputs a file named <code class=\"language-plaintext highlighter-rouge\">multiqc/multiqc_report.html</code> (set by the <code class=\"language-plaintext highlighter-rouge\">--outdir</code> flag)</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n    <p>You’ll notice that we now need to replace our <code class=\"language-plaintext highlighter-rouge\">.html</code> outputs from the FastQC rules with the <code class=\"language-plaintext highlighter-rouge\">.zip</code> outputs which we need instead. We didn’t have to update the command line, because the output file name was thankfully not part of it.</p>\n\n    <div class=\"language-diff highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"gd\">--- a/Snakefile\n</span><span class=\"gi\">+++ b/Snakefile\n</span><span class=\"p\">@@ -3,8 +3,7 @@</span> SAMPLES = ['SRR2584863', 'SRR2589044']\n rule all:\n \tinput:\n \t\texpand(\"alignments/GCA_000017985.1_ASM1798v1_genomic/{sample}.bam\", sample=SAMPLES),\n<span class=\"gd\">-\t\texpand(\"fastqc/{sample}{ext}\", sample=SAMPLES, ext=[\"_1_fastqc.html\", \"_2_fastqc.html\"]),\n-\t\texpand(\"fastqc-trim/{sample}{ext}\", sample=SAMPLES, ext=[\"_1.trim_fastqc.html\", \"_2.trim_fastqc.html\", \"_1un.trim_fastqc.html\", \"_2un.trim_fastqc.html\"])\n</span><span class=\"gi\">+\t\t\"multiqc/multiqc_report.html\"\n</span><span class=\"err\">\n</span> rule download:\n \toutput:\n<span class=\"p\">@@ -28,7 +27,7 @@</span> rule fastqc:\n \tinput:\n \t\t\"trim/{sample}.trim.fq\"\n \toutput:\n<span class=\"gd\">-\t\t\"fastqc-trim/{sample}_fastqc.html\"\n</span><span class=\"gi\">+\t\t\"fastqc-trim/{sample}_fastqc.zip\"\n</span> \tconda:\n \t\t\"envs/fastqc.yaml\"\n \tlog:\n<span class=\"p\">@@ -41,7 +40,7 @@</span> rule fastqc_trim:\n \tinput:\n \t\t\"reads/{sample}.fq.gz\"\n \toutput:\n<span class=\"gd\">-\t\t\"fastqc/{sample}_fastqc.html\"\n</span><span class=\"gi\">+\t\t\"fastqc/{sample}_fastqc.zip\"\n</span> \tconda:\n \t\t\"envs/fastqc.yaml\"\n \tlog:\n<span class=\"p\">@@ -50,6 +49,21 @@</span> rule fastqc_trim:\n \tshell:\n \t\t\"fastqc {input} --outdir fastqc/ &gt;{log.out} 2&gt;{log.err}\"\n<span class=\"err\">\n</span><span class=\"gi\">+rule multiqc:\n+\tinput:\n+\t\texpand(\"fastqc/{sample}{ext}\", sample=SAMPLES, ext=[\"_1_fastqc.zip\", \"_2_fastqc.zip\"]),\n+\t\texpand(\"fastqc-trim/{sample}{ext}\", sample=SAMPLES, ext=[\"_1.trim_fastqc.zip\", \"_2.trim_fastqc.zip\", \"_1un.trim_fastqc.zip\", \"_2un.trim_fastqc.zip\"])\n+\toutput:\n+\t\t\"multiqc/multiqc_report.html\"\n+\tconda:\n+\t\t\"envs/multiqc.yaml\"\n+\tlog:\n+\t\tout=\"logs/multiqc.out\",\n+\t\terr=\"logs/multiqc.err\"\n+\tshell:\n+\t\t\"multiqc --outdir multiqc {input} &gt;{log.out} 2&gt;{log.err}\"\n+\n+\n</span> rule trimmomatic:\n \tinput:\n \t\tr1=\"reads/{sample}_1.fq.gz\",\n</code></pre></div>    </div>\n\n    <p>And your new <code class=\"language-plaintext highlighter-rouge\">envs/multiqc.yaml</code> should look like this:</p>\n\n    <div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">channels</span><span class=\"pi\">:</span>\n  <span class=\"pi\">-</span> <span class=\"s\">conda-forge</span>\n  <span class=\"pi\">-</span> <span class=\"s\">bioconda</span>\n  <span class=\"pi\">-</span> <span class=\"s\">defaults</span>\n<span class=\"na\">dependencies</span><span class=\"pi\">:</span>\n  <span class=\"pi\">-</span> <span class=\"s\">multiqc=1.11</span>\n</code></pre></div>    </div>\n  </blockquote>\n</blockquote>\n\n<p>And with that, you should have a working pipeline! Test it out.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Run the pipeline</hands-on-title>\n  <p>Run <code class=\"language-plaintext highlighter-rouge\">snakemake -c4 --use-conda</code></p>\n</blockquote>\n\n<p>Let’s check our <abbr title=\"Directed Acyclic Graph\">DAG</abbr> again</p>\n\n<blockquote class=\"code-in\">\n  <code-in-title></code-in-title>\n  <div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>snakemake <span class=\"nt\">--dag</span> | dot <span class=\"nt\">-Tsvg</span> <span class=\"o\">&gt;</span> out.svg\n</code></pre></div>  </div>\n</blockquote>\n\n<blockquote class=\"code-out\">\n  <code-out-title></code-out-title>\n  <p><a href=\"../../images/snakemake.dag2.svg\" rel=\"noopener noreferrer\"><img src=\"../../images/snakemake.dag2.svg\" alt=\"Image of the snakemake dag. FastQC and MultiQC are now there which add about 7 new boxes and a bunch of new arrows. This makes the graph very wide and quite hard to read.\" loading=\"lazy\" /></a></p>\n</blockquote>\n\n<h1 id=\"conclusion\">Conclusion</h1>\n\n<p>With this you’ve made a real pipeline in Snakemake and hopefully learned a bit about how to manage jobs on the command line. If you’re going to work at the command line to do your bioinformatics or other analyses, this (or another <abbr title=\"Scientific Workflow Management System\">SciWMS</abbr>) is the way to do it! They all have pros and cons which you should evaluate.</p>\n\n<p>But for those of you who have done Galaxy work before, you’ll notice there is a <strong>lot</strong> of overhead, things you need to take care of yourself. Is the program installed, are the dependencies correct, how many cores would you like this job to use, what is precisely the command line you would like to run. How would you like to batch your data, by sample? By another method? And this is one of the major benefits of using a system like Galaxy, it abstracts away all of the command line, all of the resource management for you. Our administrators check things like how much memory each step should have, or how many cores, the tool developers work to make sure the interface has all of the options that are available on the command line. You get less control over your data and the processes, but in exchange you don’t need to worry about these intricate details of low level bioinformatics.</p>\n\n<p>Let’s do a final comparison table for the systems, and since this is the Galaxy Training Network we’ll include Galaxy in the comparison. Here we categorise features as ‘manual’ if you can accomplish those features with manual work, ‘automatic’ if they’re built in parts of the system, <code class=\"language-plaintext highlighter-rouge\">none</code> if the concept doesn’t really apply</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Aspect</th>\n      <th>Bash</th>\n      <th>Make</th>\n      <th>Snakemake</th>\n      <th>Galaxy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Language style</td>\n      <td>Line-by-line</td>\n      <td>Custom Generic Rules</td>\n      <td>Custom Generic Rules</td>\n      <td>Pre-built rules via Galaxy Tools</td>\n    </tr>\n    <tr>\n      <td>Partial re-run</td>\n      <td>Manual</td>\n      <td>Manual</td>\n      <td>Automatic</td>\n      <td>Automatic (but requires a user preference.)</td>\n    </tr>\n    <tr>\n      <td>How it is invoked</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">bash script.sh</code></td>\n      <td><code class=\"language-plaintext highlighter-rouge\">make</code></td>\n      <td><code class=\"language-plaintext highlighter-rouge\">snakemake</code></td>\n      <td>Clicking ‘execute’</td>\n    </tr>\n    <tr>\n      <td>Running with different data?</td>\n      <td>Manual</td>\n      <td>Automatic</td>\n      <td>Automatic</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <td>Paralellisation?</td>\n      <td>Manual</td>\n      <td>Automatic</td>\n      <td>Automatic</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <td>Memory / CPU core Management</td>\n      <td>Manual</td>\n      <td>Manual</td>\n      <td>Manual</td>\n      <td>Autoamtic</td>\n    </tr>\n    <tr>\n      <td>Filename</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">*.sh</code></td>\n      <td><code class=\"language-plaintext highlighter-rouge\">Makefile</code></td>\n      <td><code class=\"language-plaintext highlighter-rouge\">Snakefile</code> or <code class=\"language-plaintext highlighter-rouge\">*.snk</code></td>\n      <td>Workflows stored in website, downloadable as <code class=\"language-plaintext highlighter-rouge\">.ga</code> files.</td>\n    </tr>\n    <tr>\n      <td>Dependencies</td>\n      <td>None</td>\n      <td>None+Difficult</td>\n      <td>Conda is integrated</td>\n      <td>Automatic, done by tool devs for you.</td>\n    </tr>\n    <tr>\n      <td>Multiple output files per step</td>\n      <td>n/a</td>\n      <td>Complicated</td>\n      <td>Yes!</td>\n      <td>Automatic, done by tool devs for you.</td>\n    </tr>\n    <tr>\n      <td>Cluster/HPC Friendliness</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Yes, but manual</td>\n      <td>Automatic, handled by Galaxy Admins</td>\n    </tr>\n    <tr>\n      <td>Installation/Maintenance</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Requires regular updates and management.</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>The author’s biases are probably quite clear in the above table, and you can find an alternative viewpoint from Snakemake’s documentation, but it comes down to different audiences. If you care how many CPU cores a job receives and need precise control over the command line, or can’t/don’t want to deploy Galaxy and just want a quick command line tool.</p>\n"],"ref_slides":[],"hands_on":true,"slides":false,"mod_date":"2024-06-10 22:46:11 +0000","pub_date":"2021-11-18 12:06:25 +0000","version":18,"api":"https://training.galaxyproject.org/training-material/api/topics/data-science/tutorials/snakemake/tutorial.json","tools":[],"supported_servers":{"exact":[],"inexact":[{"name":"UseGalaxy.eu","url":"https://usegalaxy.eu","id":"eu","human":"Galaxy Europe","usegalaxy":true},{"name":"UseGalaxy.org","url":"https://usegalaxy.org","id":"us","human":"Galaxy Main","usegalaxy":true},{"name":"UseGalaxy.org.au","url":"https://usegalaxy.org.au","id":"au","human":"Galaxy Australia","usegalaxy":true},{"name":"UseGalaxy.fr","url":"https://usegalaxy.fr","id":"fr","human":"Galaxy France","usegalaxy":true}]},"topic_name_human":"Foundations of Data Science","admin_install":{"install_tool_dependencies":true,"install_repository_dependencies":true,"install_resolver_dependencies":true,"tools":[]},"admin_install_yaml":"---\ninstall_tool_dependencies: true\ninstall_repository_dependencies: true\ninstall_resolver_dependencies: true\ntools: []\n","tours":false,"video":false,"slides_recordings":false,"translations":{"tutorial":[],"slides":[],"video":false},"license":"CC-BY-4.0","type":"tutorial"}