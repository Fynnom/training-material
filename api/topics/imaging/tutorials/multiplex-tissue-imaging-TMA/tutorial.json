{"layout":"tutorial_hands_on","title":"End-to-End Tissue Microarray Image Analysis with Galaxy-ME","zenodo_link":"https://doi.org/10.5281/zenodo.7622545","questions":["What tools are available for pre-processing multiplex tissue images in Galaxy?","What tools are available for downstream analysis of multiplex tissue images in Galaxy?","How do I pre-process and analyze Tissue Microarray data?","How can I visualize multiplex tissue images and associated data?","How can I assign phenotypes to cells in an MTI dataset?"],"objectives":["Understand the tools available in Galaxy for multiplex tissue imaging analysis","Analyze and visualize publicly available TMA data using Galaxy"],"time_estimation":"3H","key_points":["Galaxy has tools and workflows that can be used to process and analyze multiplex tissue images","Cell feature tables produced by the Galaxy TMA workflow can be used for downstream single-cell and spatial analyses","There are powerful interactive visualization tools available in Galaxy that can combine the real images with associated data","Tissue Microarray data can be analyzed using workflows that invoke MTI tools in batch","Segmentation quality can vary significantly depending on features of the input image, tool used, and parameters"],"contributors":[{"name":"Cameron Watson","joined":"2022-07","email":"watsocam@ohsu.edu","orcid":"0000-0002-6942-2469","id":"CameronFRWatson","url":"https://training.galaxyproject.org/training-material/api/contributors/CameronFRWatson.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/CameronFRWatson/"},{"name":"Allison Creason","email":"creason@ohsu.edu","orcid":"0000-0001-5724-1276","joined":"2023-02","id":"alliecreason","url":"https://training.galaxyproject.org/training-material/api/contributors/alliecreason.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/alliecreason/"}],"js_requirements":{"mathjax":null,"mermaid":false},"short_id":"T00334","url":"/topics/imaging/tutorials/multiplex-tissue-imaging-TMA/tutorial.html","topic_name":"imaging","tutorial_name":"multiplex-tissue-imaging-TMA","dir":"topics/imaging/tutorials/multiplex-tissue-imaging-TMA","symlink":null,"id":"imaging/multiplex-tissue-imaging-TMA","ref_tutorials":["<p>Multiplex tissue images are large, multi-channel images that contain intensity data for numerous biomarkers. The methods for generating multiplex tissue images are diverse, and each method can require specialized knowledge for downstream processing and analysis. The MCMICRO (<span class=\"citation\"><a href=\"#Schapiro2021\">Schapiro <i>et al.</i> 2021</a></span>) pipeline was developed to process multiplex images into single-cell data, and to have the range of tools to accomodate for different imaging methods. The tools used in the MCMICRO pipeline, in addition to tools for single-cell analysis, spatial analysis, and interactive visualization are available in Galaxy to facilitate comprehensive and accessible analyses of multiplex tissue images. The MCMICRO tools available in Galaxy are capable of processing Whole Slide Images (WSI) and Tissue Microarrays (TMA). WSIs are images in which a tissue section from a single sample occupies the entire microscope slide; whereas, TMAs multiplex smaller cores from multiple samples onto a single slide. This tutorial will demonstrate how to use the Galaxy multiplex imaging tools to process and analyze publicly available TMA test data provided by MCMICRO (Figure 1.).</p>\n\n<p>Find a full <a href=\"https://cancer.usegalaxy.org/u/watsocam/h/gtnexemplar002tma\">example history</a></p>\n\n<figure id=\"figure-1\" style=\"max-width: 90%;\"><img src=\"../../images/multiplex-tissue-imaging-TMA/ex2_combined_avivator.png\" alt=\"Aviator screenshot, described in figure caption. \" width=\"1152\" height=\"986\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/multiplex-tissue-imaging-TMA/ex2_combined_avivator.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 1</strong>:</span> Fully registered image of the MCMICRO Exemplar-002 Tissue microarray. Exemplar-002 consists of four cores, each with a distinct tissue organization and expression of biomarkers. In the image, there are six biomarkers shown: DNA (white), CD163 (yellow), CD3D (blue), CD31 (red), VDAC1 (green), and Keratin (orange). This image is being viewed using Avivator, an interactive tool that allows the user to selectively view channels and adjust channel intensities.</figcaption></figure>\n\n<blockquote class=\"agenda\">\n  <h3 id=\"agenda\">Agenda</h3>\n\n  <p>In this tutorial, we will cover:</p>\n\n<ol id=\"markdown-toc\">\n  <li><a href=\"#get-data\" id=\"markdown-toc-get-data\">Get data</a></li>\n  <li><a href=\"#tile-illumination-correction-with-basic-illumination\" id=\"markdown-toc-tile-illumination-correction-with-basic-illumination\">Tile illumination correction with <strong>BaSiC Illumination</strong></a></li>\n  <li><a href=\"#stitching-and-registration-with-ashlar\" id=\"markdown-toc-stitching-and-registration-with-ashlar\">Stitching and registration with <strong>ASHLAR</strong></a></li>\n  <li><a href=\"#tma-dearray-with-unetcoreograph\" id=\"markdown-toc-tma-dearray-with-unetcoreograph\">TMA dearray with <strong>UNetCoreograph</strong></a></li>\n  <li><a href=\"#nuclear-segmentation-with-mesmer\" id=\"markdown-toc-nuclear-segmentation-with-mesmer\">Nuclear segmentation with <strong>Mesmer</strong></a></li>\n  <li><a href=\"#calculate-single-cell-features-with-quantification\" id=\"markdown-toc-calculate-single-cell-features-with-quantification\">Calculate single-cell features with <strong>Quantification</strong></a></li>\n  <li><a href=\"#convert-mcmicro-output-to-anndata\" id=\"markdown-toc-convert-mcmicro-output-to-anndata\"><strong>Convert McMicro Output to Anndata</strong></a></li>\n  <li><a href=\"#scimap-single-cell-phenotyping\" id=\"markdown-toc-scimap-single-cell-phenotyping\">Scimap: <strong>Single Cell Phenotyping</strong></a></li>\n  <li><a href=\"#interactive-visualization-of-multiplex-tissue-images\" id=\"markdown-toc-interactive-visualization-of-multiplex-tissue-images\">Interactive visualization of multiplex tissue images</a>    <ol>\n      <li><a href=\"#converting-unetcoreograph-images-to-ome-tiff-using-the-convert-image-tool\" id=\"markdown-toc-converting-unetcoreograph-images-to-ome-tiff-using-the-convert-image-tool\">Converting UNetCoreograph images to OME-TIFF using the <strong>Convert image</strong> tool</a></li>\n      <li><a href=\"#rename-ome-tiff-channels\" id=\"markdown-toc-rename-ome-tiff-channels\"><strong>Rename OME-TIFF Channels</strong></a></li>\n      <li><a href=\"#initial-visualization-with-avivator\" id=\"markdown-toc-initial-visualization-with-avivator\">Initial visualization with <strong>Avivator</strong></a></li>\n      <li><a href=\"#generating-an-interactive-visualization-dashboard-with-vitessce\" id=\"markdown-toc-generating-an-interactive-visualization-dashboard-with-vitessce\">Generating an interactive visualization dashboard with <strong>Vitessce</strong></a></li>\n    </ol>\n  </li>\n  <li><a href=\"#next-steps-compositional-and-spatial-analyses\" id=\"markdown-toc-next-steps-compositional-and-spatial-analyses\">Next steps: Compositional and spatial analyses</a></li>\n  <li><a href=\"#conclusion\" id=\"markdown-toc-conclusion\">Conclusion</a></li>\n</ol>\n\n</blockquote>\n\n<h1 id=\"get-data\">Get data</h1>\n\n<p>Multiplex tissue images come in a variety of forms and file-types depending on the modality or platform used. For this tutorial, the Exemplar-002 data was imaged using Cyclic Immunofluorescence (CycIF) with a RareCyte slide scanner. Many of the steps in this workflow have platform-specific parameters, and the hands-on sections will show the best parameters for CycIF RareCyte images; however, notes will be made where critical differences may occur depending on the modality or platform throughout the tutorial.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title> Data import to history </hands-on-title>\n\n  <ol>\n    <li>\n      <p>Create a new history for this tutorial</p>\n\n      <!--SNIPPET-->\n      <blockquote class=\"tip\">   <div class=\"box-title tip-title\" id=\"tip-creating-a-new-history\"><button class=\"gtn-boxify-button tip\" type=\"button\" aria-controls=\"tip-creating-a-new-history\" aria-expanded=\"true\"><i class=\"far fa-lightbulb\" aria-hidden=\"true\"></i> <span>Tip: Creating a new history</span><span class=\"fold-unfold fa fa-minus-square\"></span></button></div>   <p>Click the <i class=\"fas fa-plus\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">new-history</span> icon at the top of the history panel:</p>   <p><img src=\"/training-material/shared/images/history_create_new.svg\" alt=\"UI for creating new history\" /></p>   <!-- the original drawing can be found here https://docs.google.com/drawings/d/1cCBrLAo4kDGic5QyB70rRiWJAKTenTU8STsKDaLcVU8/edit?usp=sharing --> </blockquote>\n      <p><!--END_SNIPPET--></p>\n    </li>\n    <li>Import the files from <a href=\"https://doi.org/10.5281/zenodo.7622545\">Zenodo</a> or from\nthe shared data library (<code class=\"language-plaintext highlighter-rouge\">GTN - Material</code> -&gt; <code class=\"language-plaintext highlighter-rouge\">imaging</code>\n -&gt; <code class=\"language-plaintext highlighter-rouge\">End-to-End Tissue Microarray Image Analysis with Galaxy-ME</code>):\n      <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>https://zenodo.org/record/7622545/files/markers.csv\nhttps://zenodo.org/record/7622545/files/exemplar_002_phenotypes.csv\nhttps://zenodo.org/record/7622545/files/exemplar-002-cycle-01.ome.tiff\nhttps://zenodo.org/record/7622545/files/exemplar-002-cycle-02.ome.tiff\nhttps://zenodo.org/record/7622545/files/exemplar-002-cycle-03.ome.tiff\nhttps://zenodo.org/record/7622545/files/exemplar-002-cycle-04.ome.tiff\nhttps://zenodo.org/record/7622545/files/exemplar-002-cycle-05.ome.tiff\nhttps://zenodo.org/record/7622545/files/exemplar-002-cycle-06.ome.tiff\nhttps://zenodo.org/record/7622545/files/exemplar-002-cycle-07.ome.tiff\nhttps://zenodo.org/record/7622545/files/exemplar-002-cycle-08.ome.tiff\nhttps://zenodo.org/record/7622545/files/exemplar-002-cycle-09.ome.tiff\nhttps://zenodo.org/record/7622545/files/exemplar-002-cycle-10.ome.tiff\n</code></pre></div>      </div>\n      <!--SNIPPET-->\n      <blockquote class=\"tip\">   <div class=\"box-title tip-title\" id=\"tip-importing-via-links\"><button class=\"gtn-boxify-button tip\" type=\"button\" aria-controls=\"tip-importing-via-links\" aria-expanded=\"true\"><i class=\"far fa-lightbulb\" aria-hidden=\"true\"></i> <span>Tip: Importing via links</span><span class=\"fold-unfold fa fa-minus-square\"></span></button></div>   <ul>   <li>Copy the link location</li>   <li>     <p>Click <i class=\"fas fa-upload\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-upload</span> <strong>Upload Data</strong> at the top of the tool panel</p>   </li>   <li>Select <i class=\"fa fa-edit\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-wf-edit</span> <strong>Paste/Fetch Data</strong></li>   <li>     <p>Paste the link(s) into the text field</p>   </li>   <li>     <p>Press <strong>Start</strong></p>   </li>   <li><strong>Close</strong> the window</li> </ul> </blockquote>\n      <p><!--END_SNIPPET--></p>\n    </li>\n    <li>Group the datasets into <a href=\"/training-material/topics/galaxy-interface/tutorials/collections/tutorial.html\">collections</a>. Make a collection of the OME-TIFF, ordering the files by cycle number.</li>\n  </ol>\n\n</blockquote>\n\n<blockquote class=\"warning\">\n  <warning-title>**Imaging platform differences**</warning-title>\n\n  <p>The Exemplar-002 raw images are in <em>ome.tiff</em> format; however, commonly seen raw file-types are <em>ome.tiff</em>, <em>tiff</em>, <em>czi</em>, and <em>svs</em>. If your input images are not <em>ome.tiff</em> or <em>tiff</em>, you may have to edit the dataset attributes in Galaxy to allow tools to recognize them as viable inputs.</p>\n\n</blockquote>\n\n<p>The raw files for each round (10 in total) of the exemplar-002 data are available on <a href=\"https://cancer.usegalaxy.org\">cancer.usegalaxy.org</a> under <strong>Data Libraries</strong> (Figure 2.). Import the raw files into a new history as a <strong>list collection</strong>.</p>\n\n<figure id=\"figure-2\" style=\"max-width: 90%;\"><img src=\"../../images/multiplex-tissue-imaging-TMA/ex2_getData.png\" alt=\"Screenshot of the Galaxy data libraries on cancer.usegalaxy.org, highlighting the path to the dataset, Libraries, Exemplar 002, raw. The UI shows all datasets in that folder selected before using the Export to History button to import them as a Collection.\" width=\"1296\" height=\"665\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/multiplex-tissue-imaging-TMA/ex2_getData.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 2</strong>:</span> Finding the Exemplar-002 data on cancer.usegalaxy.org Data Libraries.</figcaption></figure>\n\n<h1 id=\"tile-illumination-correction-with-basic-illumination\">Tile illumination correction with <strong>BaSiC Illumination</strong></h1>\n\n<p>Commonly, raw MTI data will consist of one image per round of imaging. These individual round images are frequently captured in tiles, and there can be slight variations in how each tile was illuminated across the course of imaging. Prior to tile stitching and image registration, the tiles have to undergo illumination correction with <strong>BaSiC Illumination</strong> (<span class=\"citation\"><a href=\"#Peng2017\">Peng <i>et al.</i> 2017</a></span>) to account for this. Unlike many of the other tools in this workflow, BaSiC has no extra parameters to think about: Just input the collection of raw images and press <em>go</em>!</p>\n\n<p>Two new list collections will appear in the history upon completion:</p>\n\n<ul>\n  <li>BaSiC Illumination on Collection <code class=\"language-plaintext highlighter-rouge\">X</code>: FFP (flat-field)</li>\n  <li>BaSiC Illumination on Collection <code class=\"language-plaintext highlighter-rouge\">X</code>: DFP (deep-field)</li>\n</ul>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title> Illumination correction </hands-on-title>\n\n  <ol>\n    <li>\n      <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/perssond/basic_illumination/basic_illumination/1.0.3+galaxy1\" title=\"BaSiC Illumination tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>BaSiC Illumination</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 1.0.3+galaxy1)</span> with the following parameters:</p>\n\n      <ul>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Raw Cycle Images: “</em>: List collection of raw images</li>\n      </ul>\n    </li>\n  </ol>\n\n</blockquote>\n\n<h1 id=\"stitching-and-registration-with-ashlar\">Stitching and registration with <strong>ASHLAR</strong></h1>\n\n<p>After illumination is corrected across round tiles, the tiles must be stitched together, and subsequently, each round mosaic must be registered together into a single pyramidal OME-TIFF file. <strong>ASHLAR</strong> (<span class=\"citation\"><a href=\"#Muhlich2022\">Muhlich <i>et al.</i> 2022</a></span>) from MCMICRO provides both of these functions.</p>\n\n<blockquote class=\"comment\">\n  <comment-title>Important detail: Marker File</comment-title>\n\n  <p><strong>ASHLAR</strong> optionally reads a marker metadata file to name the channels in the output OME-TIFF image. This marker file will also be used in later steps. Make sure that the marker file is comma-separated and has the <code class=\"language-plaintext highlighter-rouge\">marker_names</code> as the third column (Figure 3.).</p>\n\n  <figure id=\"figure-3\" style=\"max-width: 90%;\"><img src=\"../../images/multiplex-tissue-imaging-TMA/ex2_markersFile.png\" alt=\"screenshot of the markers table. \" width=\"1008\" height=\"582\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/multiplex-tissue-imaging-TMA/ex2_markersFile.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 3</strong>:</span> Markers file, used both in ASHLAR and downstream steps. Critically, the marker_names are in the third column.</figcaption></figure>\n\n</blockquote>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>: Image stitching and registration </hands-on-title>\n\n  <ol>\n    <li>\n      <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/perssond/ashlar/ashlar/1.14.0+galaxy1\" title=\"ASHLAR tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>ASHLAR</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 1.14.0+galaxy1)</span> with the following parameters:</p>\n\n      <ul>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Raw Images”</em>: List collection of raw images</li>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Deep Field Profile Images”</em>: List collection of DFP images produced by <strong>BaSiC Illumination</strong></li>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Flat Field Profile Images”</em>: List collection of FFP images produced by <strong>BaSiC Illumination</strong></li>\n        <li>\n          <p><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Markers File (optional)”</em>: Comma-separated markers file with marker_names in third column</p>\n        </li>\n        <li>In <em>“Advanced Options”</em>:\n          <ul>\n            <li><em>“Write output as a single pyramidal TIFF”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n          </ul>\n        </li>\n      </ul>\n    </li>\n  </ol>\n\n</blockquote>\n\n<blockquote class=\"warning\">\n  <warning-title>**Imaging platform differences**</warning-title>\n\n  <p>ASHLAR, among other tools in the MCMICRO and Galaxy-ME pre-processing tools have some parameters that are specific to the \nimaging patform used. By default, ASHLAR is oriented to work with images from RareCyte scanners. AxioScan scanners render images\nin a different orientation. Because of this, when using ASHLAR on AxioScan images, it is important to select the <strong>Flip Y-Axis</strong>\nparameter to <em>Yes</em></p>\n\n  <p>ASHLAR will work for most imaging modalities; however, certain modalities require different tools to be registered. For example,\nmultiplex immunohistochemistry (mIHC) images must use an aligner that registers each moving image to a reference Hematoxylin image. \nFor this, Galaxy-ME includes the alternative registration tool <span><strong><strong>PALOM</strong></strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i></span>.</p>\n\n</blockquote>\n\n<h1 id=\"tma-dearray-with-unetcoreograph\">TMA dearray with <strong>UNetCoreograph</strong></h1>\n\n<p>Many downstream processing and analysis steps require each individual core from the TMA to be in a separate image file. To accomplish this from our registered ome.tiff image, we can use <strong>UNetCoreograph</strong> to detect and crop each core into separate files.</p>\n\n<p>UNetCoreograph will output images (used for downstream steps), masks, and a preview image (Figure 4.).</p>\n\n<figure id=\"figure-4\" style=\"max-width: 90%;\"><img src=\"../../images/multiplex-tissue-imaging-TMA/ex2_dearray.png\" alt=\"Image of four cores (numbered 1-4) on a slide.\" width=\"193\" height=\"194\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/multiplex-tissue-imaging-TMA/ex2_dearray.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 4</strong>:</span> Preview image from UNetCoreograph, outlines show detection of each individual core in the TMA.</figcaption></figure>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title> TMA dearray </hands-on-title>\n\n  <ol>\n    <li>\n      <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/perssond/coreograph/unet_coreograph/2.2.8+galaxy1\" title=\"UNetCoreograph tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>UNetCoreograph</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 2.2.8+galaxy1)</span> with the following parameters:</p>\n\n      <ul>\n        <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Registered TIFF”</em>: The output of <strong>ASHLAR</strong> (registered, pyramidal OME-TIFF file)</li>\n      </ul>\n\n      <blockquote class=\"comment\">\n        <comment-title>What about Whole Slide Images?</comment-title>\n\n        <p>Whole slide images do not need to be dearrayed, so in most cases, this step can be skipped; however, UNetCoreograph has the <em>“Tissue”</em> option, which when selected, can act to separate the whole tissue from the background in a whole slide image which can be useful. In this case, it is important to toggle the <em>“Downsample factor”</em> as this often needs to be higher when extracting whole tissues.</p>\n      </blockquote>\n    </li>\n  </ol>\n\n</blockquote>\n\n<h1 id=\"nuclear-segmentation-with-mesmer\">Nuclear segmentation with <strong>Mesmer</strong></h1>\n\n<p>Cell segmentation is the basis for all downstream single-cell analyses. Different segmentation tools work highly variably depending on the imaging modality or platform used. Because of this, Galaxy-ME has incorporated several cell segmentation tools so users may find the tool that works optimally for their data.</p>\n\n<p>Available segmentation tools in Galaxy-ME:</p>\n\n<ul>\n  <li>Mesmer (<span class=\"citation\"><a href=\"#Greenwald2021\">Greenwald <i>et al.</i> 2021</a></span>)</li>\n  <li>UnMicst and s3segmenter (<span class=\"citation\"><a href=\"#Yapp2022\">Yapp <i>et al.</i> 2022</a></span>)</li>\n  <li>Cellpose (<span class=\"citation\"><a href=\"#Stringer2020\">Stringer <i>et al.</i> 2020</a></span>)</li>\n  <li>ilastik (<span class=\"citation\"><a href=\"#Berg2019\">Berg <i>et al.</i> 2019</a></span>)</li>\n</ul>\n\n<p>In this tutorial, we use <strong>Mesmer</strong> because it tends to perform generally well on a diverse range of image types, and has a limited number of parameters to understand.</p>\n\n<blockquote class=\"comment\">\n  <comment-title>Important detail: Running images in batches</comment-title>\n\n  <p>Now that each image has been split into individual core images, downstream tools must be run on the images separately. Luckily, Galaxy makes this easy by including the option to run each tool in batch across a collection of inputs. Next to the input for the tool, select <i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> (<strong>Dataset collection</strong>) as the input type, and pass the collection output by UNetCoreograph as input.</p>\n\n</blockquote>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title> Nuclear segmentation </hands-on-title>\n\n  <ol>\n    <li><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/goeckslab/mesmer/mesmer/0.12.3+galaxy2\" title=\"Mesmer tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Mesmer</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 0.12.3+galaxy2)</span> with the following parameters:\n      <ul>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Image containing the nuclear marker(s) “</em>: Collection output of UNetCoreograph (images)</li>\n        <li><em>“Resolution of the image in microns-per-pixel”</em>: <code class=\"language-plaintext highlighter-rouge\">0.65</code></li>\n        <li><em>“Compartment for segmentation prediction:”</em>: <code class=\"language-plaintext highlighter-rouge\">Nuclear</code></li>\n      </ul>\n\n      <blockquote class=\"comment\">\n        <comment-title>np.squeeze</comment-title>\n\n        <p>The <strong>np.squeeze</strong> parameter is very important to select as <code class=\"language-plaintext highlighter-rouge\">Yes</code> to make the output compatible with next steps</p>\n      </blockquote>\n    </li>\n  </ol>\n\n</blockquote>\n\n<blockquote class=\"warning\">\n  <warning-title>Imaging platform differences: Image resolution**</warning-title>\n\n  <p>A crucial parameter for Mesmer and other segmentation tools is the <strong>Image resolution</strong>. This is reported in microns/pixel, and can vary depending on the imaging platform used and the settings at image acquisition. Mesmer accepts the resolution in microns/pixel; however, if using UnMICST, the resolution must be reported as a ratio of the resolution of UnMICST’s training images (0.65). For example, when using UnMICST, if your images were captured at a resolution of 0.65, then the UnMICST value would be 1, but if your images were captured at 0.325 microns/pixel, then the value you would enter for UnMICST would be 0.5.</p>\n\n</blockquote>\n\n<h1 id=\"calculate-single-cell-features-with-quantification\">Calculate single-cell features with <strong>Quantification</strong></h1>\n\n<p>After generating a segmentation mask, the mask and the original registered image can be used to extract mean intensities for each marker in the panel, spatial coordinates, and morphological features for every cell. This step is performed by MCMICRO’s <strong>Quantification</strong> module.</p>\n\n<p>Once again, as this is a TMA, we will be running this in batch mode for every core image and its segmentation mask.</p>\n\n<p>The quantification step will produce a CSV cell feature table for every image in the batch.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title> Quantification </hands-on-title>\n\n  <ol>\n    <li>\n      <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/perssond/quantification/quantification/1.5.3+galaxy1\" title=\"Quantification tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Quantification</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 1.5.3+galaxy1)</span> with the following parameters:</p>\n\n      <ul>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Registered TIFF “</em>: Collection output of UNetCoreograph (images)</li>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Primary Cell Mask “</em>: Collection output of Mesmer (or other segmentation tool)</li>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Additional Cell Masks “</em>: <code class=\"language-plaintext highlighter-rouge\">Nothing Selected</code> (Other tools may produce multiple mask types)</li>\n        <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Marker channels”</em>: Comma-separated markers file with marker_names in third column</li>\n      </ul>\n\n      <blockquote class=\"comment\">\n        <comment-title>Mask metrics and Intensity metrics</comment-title>\n\n        <p>Leaving the <em>“mask metrics”</em> and <em>“intensity metrics”</em> blank will by default run all available metrics</p>\n\n      </blockquote>\n    </li>\n  </ol>\n\n</blockquote>\n\n<h1 id=\"convert-mcmicro-output-to-anndata\"><strong>Convert McMicro Output to Anndata</strong></h1>\n\n<p>Anndata (<span class=\"citation\"><a href=\"#Virshup2021\">Virshup <i>et al.</i> 2021</a></span>) is a Python package and file format schema for working with annotated data matrices that has gained popularity in the single-cell analysis community. Many downstream analysis tools, including Scimap from MCMICRO, Scanpy (<span class=\"citation\"><a href=\"#Wolf2018\">Wolf <i>et al.</i> 2018</a></span>), and Squidpy (<span class=\"citation\"><a href=\"#Palla2022\">Palla <i>et al.</i> 2022</a></span>) are built around anndata format files (h5ad). This tool splits the marker intensity data into a separate dataframe (<code class=\"language-plaintext highlighter-rouge\">X</code>), and places all observational data (spatial coordinates, morphological features, etc.) in the cell feature table into a separate dataframe (<code class=\"language-plaintext highlighter-rouge\">obs</code>) that shares the same indices as <code class=\"language-plaintext highlighter-rouge\">X</code>. In downstream analyses, new categorical variables, such as phenotype assignments for each cell, are stored in the <code class=\"language-plaintext highlighter-rouge\">obs</code> dataframe.</p>\n\n<p>Learn more about this file format at the <a href=\"https://anndata.readthedocs.io/en/latest/index.html\">anndata documentation</a>.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title> Conver to Anndata </hands-on-title>\n\n  <ol>\n    <li>\n      <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/goeckslab/scimap_mcmicro_to_anndata/scimap_mcmicro_to_anndata/0.17.7+galaxy0\" title=\"Convert McMicro Output to Anndata tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Convert McMicro Output to Anndata</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 0.17.7+galaxy0)</span> with the following parameters:</p>\n\n      <ul>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Select the input image or images”</em>: Collection output of Quantification (cellMaskQuant)</li>\n        <li>In <em>“Advanced Options”</em>:\n          <ul>\n            <li><em>“Whether to remove the DNA channels from the final output”</em>: <code class=\"language-plaintext highlighter-rouge\">No</code></li>\n            <li><em>“Whether to use unique name for cells/rows”</em>: <code class=\"language-plaintext highlighter-rouge\">No</code></li>\n          </ul>\n        </li>\n      </ul>\n\n      <blockquote class=\"warning\">\n        <warning-title>Important parameter: Unique names for cells/rows</warning-title>\n\n        <p>Setting <em>“Whether to use unique name for cells/rows”</em> to <code class=\"language-plaintext highlighter-rouge\">No</code> to ensures that downstream interactive visualizations will be able to map observational features to the mask CellIDs.</p>\n      </blockquote>\n    </li>\n  </ol>\n\n</blockquote>\n\n<h1 id=\"scimap-single-cell-phenotyping\">Scimap: <strong>Single Cell Phenotyping</strong></h1>\n\n<p>There are several ways to classify cells available in Galaxy-ME. Unsupervised approaches, such as Leiden clustering, can be performed on all cells and phenotypes can be manually annotated based on marker expression patterns observed by the user. This approach is time consuming, so here we will demonstrate automated phenotyping based on thresholds of specific lineage markers using MCMICRO’s Scimap. Scimap phenotyping can either be provided a table of manual gate values for each marker of interest (which can be determined using the <strong>GateFinder</strong> tool in Galaxy-ME), or by default, Scimap will fit a Gaussian Mixture Model (GMM) to the <code class=\"language-plaintext highlighter-rouge\">log(intensity)</code> data for each marker to determine positive and negative populations for that marker. The marker intensity values are rescaled between (0,1) with 0.5 being the cut-off between negative and positive populations. Scimap uses a ‘Phenotype workflow’ to guide the classification of cells (Figure 5.). For more on how to construct a Scimap workflow, see the <a href=\"https://scimap-doc.readthedocs.io/en/latest/tutorials/scimap-tutorial-cell-phenotyping/\">Scimap documentation</a>.</p>\n\n<figure id=\"figure-5\" style=\"max-width: 90%;\"><img src=\"../../images/multiplex-tissue-imaging-TMA/ex2_phenotypeWF.png\" alt=\"Screenshot of the phenotypes table. \" width=\"1008\" height=\"316\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/multiplex-tissue-imaging-TMA/ex2_phenotypeWF.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 5</strong>:</span> Example of a phenotype workflow compatible with Scimap. 'Pos' means that the marker must be positive to be classified as the respective phenotype. 'Anypos' means any, but not necessarily all, of the listed markers can be positive to call the respective phenotype.</figcaption></figure>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title> Single Cell Phenotyping with Scimap </hands-on-title>\n\n  <ol>\n    <li>\n      <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/goeckslab/scimap_phenotyping/scimap_phenotyping/0.17.7+galaxy0\" title=\"Single Cell Phenotyping tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Single Cell Phenotyping</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 0.17.7+galaxy0)</span> with the following parameters:</p>\n\n      <ul>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Select the input anndata”</em>: Output of <strong>Convert MCMICRO output to Anndata</strong></li>\n        <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Select the dataset containing manual gate information”</em>: (Optional) manually determined gates in CSV format. Gates will be determined automatically using a GMM for each marker if this file is not provided</li>\n        <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Select the dataset containing gating workflow”</em>: <code class=\"language-plaintext highlighter-rouge\">exemplar_002_phenotypes.csv</code>, CSV phenotype workflow (Figure 5.)</li>\n        <li><em>“Save the GMM gates plots If True”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n      </ul>\n\n      <blockquote class=\"comment\">\n        <comment-title>Limitations of GMM automated phenotyping</comment-title>\n\n        <p>When manual gates are not provided, Scimap fits a GMM to determine a threshold between positive and negative cells. This automated gating works well when markers are highly abundant within the tissue, and the data shows a bimodal distribution (Figure 6A.). GMM gating can lead to spurious thresholds, however, when the data does not appear to be bimodal (Figure 6B.). This tends to happen when the marker is not highly abundant in the tissue, so there isn’t a large positive population. Markers that have a highly continuous range of intensity, like certain functional markers, can also be problematic with GMM gating. It is recommended to always look at the GMM plots output by Scimap, and validate any potentially spurious gates manually.</p>\n\n        <figure id=\"figure-6\" style=\"max-width: 90%;\"><img src=\"../../images/multiplex-tissue-imaging-TMA/ex2_example_GMMs.png\" alt=\"Two bar plots with overlain curves. Left in A shows a bimodal distribution of CD3D, right in B shows a unimodal distribution in CD11B.\" width=\"1152\" height=\"445\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/multiplex-tissue-imaging-TMA/ex2_example_GMMs.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 6</strong>:</span> Scimap automatic gating GMMs for two markers. (A) An example of a marker with a bimodal distribution and a reasonable looking gate. (B) An example of a marker with a unimodal distribution that is not ideal for fitting with a GMM, and would be a candidate for manual validation and gating.</figcaption></figure>\n\n      </blockquote>\n    </li>\n  </ol>\n\n</blockquote>\n\n<h1 id=\"interactive-visualization-of-multiplex-tissue-images\">Interactive visualization of multiplex tissue images</h1>\n\n<p>Visual analysis is an important part of multiplex tissue imaging workflows. Galaxy-ME has several tools that make interactive visualization easy, and can be used at various stages of analysis.</p>\n\n<h2 id=\"converting-unetcoreograph-images-to-ome-tiff-using-the-convert-image-tool\">Converting UNetCoreograph images to OME-TIFF using the <strong>Convert image</strong> tool</h2>\n\n<p>UNetCoreograph outputs each individual core image in <code class=\"language-plaintext highlighter-rouge\">tiff</code> format. Interactive visualization tools, such as <strong>Vitessce</strong> and <strong>Avivator</strong> require the images to be in <code class=\"language-plaintext highlighter-rouge\">OME-TIFF</code> format to be viewed. Galaxy-ME includes a conversion tool that can accomodate this, along with many other useful conversion functions.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title> Convert image </hands-on-title>\n\n  <ol>\n    <li><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/imgteam/bfconvert/ip_convertimage/6.7.0+galaxy0\" title=\"Convert image tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Convert image</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 6.7.0+galaxy0)</span> with the following parameters:\n      <ul>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Input Image”</em>: <code class=\"language-plaintext highlighter-rouge\">UNetCoreograph Images</code></li>\n        <li><em>“Output data type”</em>: <code class=\"language-plaintext highlighter-rouge\">OME TIFF</code></li>\n        <li><em>“Tile image”</em>: <code class=\"language-plaintext highlighter-rouge\">Tile image</code></li>\n        <li><em>“Pyramid image”</em>: <code class=\"language-plaintext highlighter-rouge\">Generate Pyramid</code></li>\n      </ul>\n    </li>\n  </ol>\n\n</blockquote>\n\n<h2 id=\"rename-ome-tiff-channels\"><strong>Rename OME-TIFF Channels</strong></h2>\n\n<p>Some tools can cause the channel names in an OME-TIFF image to be lost. To fix this, or to change the channel names to whatever the user prefers, the <strong>Rename OME-TIFF Channels</strong> tool can be invoked using a markers file similar to the one used in previous steps.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title> Rename channels </hands-on-title>\n\n  <ol>\n    <li>\n      <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/goeckslab/rename_tiff_channels/rename_tiff_channels/0.0.1+galaxy1\" title=\"Rename OME-TIFF Channels tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Rename OME-TIFF Channels</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 0.0.1+galaxy1)</span> with the following parameters:</p>\n\n      <ul>\n        <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Input image in OME-tiff format”</em>: <code class=\"language-plaintext highlighter-rouge\">Convert image</code></li>\n        <li><em>“Format of input image”</em>: <code class=\"language-plaintext highlighter-rouge\">ome.tiff</code></li>\n        <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Channel metadata CSV”</em>: <code class=\"language-plaintext highlighter-rouge\">markers.csv</code>, Comma-separated markers file with marker_names in third column</li>\n      </ul>\n    </li>\n  </ol>\n\n</blockquote>\n\n<h2 id=\"initial-visualization-with-avivator\">Initial visualization with <strong>Avivator</strong></h2>\n\n<p>For any <code class=\"language-plaintext highlighter-rouge\">OME-TIFF</code> image in a Galaxy-ME history, there will be an option to view the image using <strong>Avivator</strong>. This is a great way to perform an initial inspection of an image for QC purposes before continuing with downstream steps. The <strong>Avivator</strong> window can be launched by expanding the dataset information in the history panel and clicking the link (Figure 7.).</p>\n\n<figure id=\"figure-7\" style=\"max-width: 90%;\"><img src=\"../../images/multiplex-tissue-imaging-TMA/ex2_avivatorHistory.png\" alt=\"Screenshot shows a galaxy dataset expanded, and then the 'display at aviator' link expanded into a screenshot of Aviator showing a multicoloured histology slide.\" width=\"1152\" height=\"566\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/multiplex-tissue-imaging-TMA/ex2_avivatorHistory.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 7</strong>:</span> The highlighted link automatically appears for any OME-TIFF image (left) and, when clicked, launches an Avivator window to explore the image (right).</figcaption></figure>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title> View Images with Avivator </hands-on-title>\n  <ol>\n    <li>Expand the dataset <code class=\"language-plaintext highlighter-rouge\">ASHLAR</code>: OME-TIFF image to be viewed</li>\n    <li>Click on <em>“display at Avivator”</em></li>\n  </ol>\n\n</blockquote>\n\n<h2 id=\"generating-an-interactive-visualization-dashboard-with-vitessce\">Generating an interactive visualization dashboard with <strong>Vitessce</strong></h2>\n\n<p><strong>Vitessce</strong> is a powerful visualization tool that creates interactive dashboards (Figure 8.) to look at a multiplex <code class=\"language-plaintext highlighter-rouge\">OME-TIFF</code> images in conjunction with data generated during analysis and stored in an anndata file. The segmentation mask can be overlaid onto the image to qualitatively assess the segmentation performance. The mask can then be colored with associated observational data (Figure 9A.), such as <code class=\"language-plaintext highlighter-rouge\">phenotype</code>, with the same colors appearing in barplots (Figure 9B.), UMAP representations, heatmaps, and marker intensity violin plots for comrehensive data exploration.</p>\n\n<figure id=\"figure-8\" style=\"max-width: 90%;\"><img src=\"../../images/multiplex-tissue-imaging-TMA/ex2_fullVitessce.png\" alt=\"Screenshot of the vitessce dashboard.\" width=\"1728\" height=\"959\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/multiplex-tissue-imaging-TMA/ex2_fullVitessce.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 8</strong>:</span> A Full view of a vitesse dashboard for one core from Exemplar-002.</figcaption></figure>\n\n<figure id=\"figure-9\" style=\"max-width: 90%;\"><img src=\"../../images/multiplex-tissue-imaging-TMA/ex2_vitessce_zoomed.png\" alt=\"screenshot of vitessce interface, on the left in A is a picture of a cell highlighted. On the right in B is a bar chart comparing cell size vs lineages.\" width=\"1728\" height=\"706\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/multiplex-tissue-imaging-TMA/ex2_vitessce_zoomed.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 9</strong>:</span> Each window in the dashboard can be resized to view the components in more detail. A closer look at the phenotype-labeled mask overlaid on the actual image (A), and the phenotype barplot (B).</figcaption></figure>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title> Vitessce visualization </hands-on-title>\n\n  <ol>\n    <li>\n      <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/goeckslab/vitessce_spatial/vitessce_spatial/1.0.4+galaxy0\" title=\"Vitessce Visualization tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Vitessce Visualization</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 1.0.4+galaxy0)</span> with the following parameters:</p>\n\n      <ul>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Select the OME Tiff image”</em>: OME-TIFF image to be viewed (or collection of files to run in batch)</li>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Select masks for the OME Tiff image (Optional)”</em>: Output of Mesmer (or other segmentation tool)</li>\n        <li><em>“Whether to do phenotyping”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code>\n          <ul>\n            <li><em>“Select the anndata contaning phenotyping info”</em>: <code class=\"language-plaintext highlighter-rouge\">Single Cell Phenotyping</code>, an anndata file that includes includes cell phenotype annotations.</li>\n            <li><em>“Select an embedding algorithm for scatterplot”</em>: <code class=\"language-plaintext highlighter-rouge\">UMAP</code></li>\n            <li><em>“Input phenotyping keys”</em>: <code class=\"language-plaintext highlighter-rouge\">Multiple choices</code>\n              <ul>\n                <li><em>“Select the key(s)”</em>: <code class=\"language-plaintext highlighter-rouge\">phenotype</code></li>\n              </ul>\n            </li>\n          </ul>\n        </li>\n      </ul>\n    </li>\n  </ol>\n\n</blockquote>\n\n<h1 id=\"next-steps-compositional-and-spatial-analyses\">Next steps: Compositional and spatial analyses</h1>\n\n<p>Galaxy-ME includes additional tools from <strong>Scimap</strong> and tools from the <strong>Squidpy</strong> package (<span class=\"citation\"><a href=\"#Palla2022\">Palla <i>et al.</i> 2022</a></span>) that can be used to perform a variety of downstream analyses. For example, once phenotypes have been assigned to individual cells, <strong>Squidpy</strong> has several methods for understanding the spatial organization of the tissue. Using <strong>Squidpy</strong>, a spatial neighborhood graph is first generated, from which the organization of specific phenotype groups and their interactions can be quantified.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title> Spatial analysis with Squidpy </hands-on-title>\n\n  <ol>\n    <li>\n      <p><span><strong><strong>Squidpy Graph and Plotting</strong></strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i></span> generate a spatial neighborhood graph with the following parameters:</p>\n\n      <ul>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Select the input anndata”</em>: Anndata file containing phenotype information (or other variable of interest)</li>\n        <li><em>“Select an analysis”</em>: <code class=\"language-plaintext highlighter-rouge\">Spatial neighbors -- Create a graph from spatial coordinates</code></li>\n      </ul>\n    </li>\n    <li>\n      <p><span><strong><strong>Squidpy Graph and Plotting</strong></strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i></span> compute and plot a neighborhood enrichment analysis with the following parameters:</p>\n\n      <ul>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Select the input anndata”</em>: Output of step 1 (anndata file with spatial neighborhood graph)</li>\n        <li><em>“Select an analysis”</em>: <code class=\"language-plaintext highlighter-rouge\">nhood_enrichment -- Compute neighborhood enrichment by permutation test</code></li>\n        <li><em>“Key in anndata.AnnData.obs where clustering is stored”</em>: <code class=\"language-plaintext highlighter-rouge\">phenotype</code></li>\n      </ul>\n\n      <blockquote class=\"comment\">\n        <comment-title>Neighborhood enrichment plot</comment-title>\n\n        <p><strong>Squidpy</strong> was used to calculate neighborhood enrichments for each phenotype in core 2 of exemplar 2 (Figure 10.). This shows which phenotypes co-locate most frequently within the tissue.</p>\n\n        <figure id=\"figure-10\" style=\"max-width: 90%;\"><img src=\"../../images/multiplex-tissue-imaging-TMA/ex2_squidpy_enrichment.png\" alt=\"Heatmap showing phenotype vs neighbourhood enrichment. Most of the heatmap is blue/green (low) but one cell under epithelial is bright yellow (high). \" width=\"4040\" height=\"3126\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/multiplex-tissue-imaging-TMA/ex2_squidpy_enrichment.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 10</strong>:</span> The output of Squidpy's neighborhood enrichment on core 2 from Exemplar-002.</figcaption></figure>\n\n      </blockquote>\n    </li>\n    <li>\n      <p><span><strong><strong>Squidpy Graph and Plotting</strong></strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i></span> calculate Ripley’s L curves for each phenotype with the following parameters:</p>\n\n      <ul>\n        <li><i class=\"far fa-folder\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-collection</span> <em>“Select the input anndata”</em>: Output of step 1 (anndata file with spatial neighborhood graph)</li>\n        <li><em>“Select an analysis”</em>: <code class=\"language-plaintext highlighter-rouge\">nhood_enrichment -- Compute neighborhood enrichment by permutation test</code></li>\n        <li><em>“Key in anndata.AnnData.obs where clustering is stored”</em>: <code class=\"language-plaintext highlighter-rouge\">phenotype</code></li>\n        <li>In <em>“Advanced Graph Options”</em>:\n          <ul>\n            <li><em>“Which Ripley’s statistic to compute”</em>: <code class=\"language-plaintext highlighter-rouge\">L</code></li>\n          </ul>\n        </li>\n        <li>In <em>“Plotting Options”</em>:\n          <ul>\n            <li><em>“Ripley’s statistic to be plotted”</em>: <code class=\"language-plaintext highlighter-rouge\">L</code></li>\n          </ul>\n        </li>\n      </ul>\n\n      <blockquote class=\"comment\">\n        <comment-title>Ripley's L plot</comment-title>\n\n        <p><strong>Squidpy</strong> was used to calculate Ripley’s L curves for each phenotype in core 2 of exemplar 2 (Figure 11.). This shows the overall organization of each phenotype in the tissue. If the curve for a given phenotype lies above the light grey null line (Example: Epithelial cells in Figure 11.), the phenotype is statistically significantly clustered. If the curve lies on the null line (Example: Myeloid lineage in Figure 11.), it’s spatial distribution within the tissue is random. If the curve is underneath the null line (Example: T cells in Figure 11.), it’s spatial distribution is statistically significantly dispersed.</p>\n\n        <figure id=\"figure-11\" style=\"max-width: 90%;\"><img src=\"../../images/multiplex-tissue-imaging-TMA/ex2_squidpy_ripleys.png\" alt=\"Graph of Ripley's L. Value is plotted against bins, all of which show cursves starting at 0 and increasing as bins increase. Epithelial is the highest curve.\" width=\"3706\" height=\"2264\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/multiplex-tissue-imaging-TMA/ex2_squidpy_ripleys.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 11</strong>:</span> The output of Squidpy's Ripley's L curve on core 2 from Exemplar-002.</figcaption></figure>\n\n      </blockquote>\n    </li>\n  </ol>\n\n</blockquote>\n\n<h1 id=\"conclusion\">Conclusion</h1>\n\n<p>In this tutorial, we demonstrated a complete multiplex tissue imaging analysis workflow performed entirely in a web browser using Galaxy-ME. Using an example tissue microarray imaged with cylic immunofluoresence provided by MCMICRO, we…</p>\n\n<ul>\n  <li>Corrected illumination between imaging tiles</li>\n  <li>Stitched and registered input images to produce a single, pyramidal OME-TIFF image that is viewable in multiple built-in interactive viewing tools (Avivator, Vitessce)</li>\n  <li>Split the TMA into separate images for each core</li>\n  <li>Processed each core in parallel, beginning with nuclear segmentation</li>\n  <li>Quantified the mean marker intensities, morphological features, and spatial coordinates of each cell in each core</li>\n  <li>Converted the resulting tabular data to anndata format for convenient downstream anaylses and visualizations</li>\n  <li>Performed marker-based, automatically gated, phenotyping of cells</li>\n  <li>Prepared the dearrayed images and viewed them interactively in a dashboard combined with observational data</li>\n</ul>\n\n<figure id=\"figure-12\" style=\"max-width: 90%;\"><img src=\"../../images/multiplex-tissue-imaging-TMA/ex2_galaxyWF.png\" alt=\"Image of a galaxy workflow with all of the tools from this tutorial.\" width=\"2561\" height=\"834\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/multiplex-tissue-imaging-TMA/ex2_galaxyWF.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 12</strong>:</span> The entire workflow used in this tutorial.</figcaption></figure>\n"],"ref_slides":[],"hands_on":true,"slides":false,"mod_date":"2023-11-03 14:30:27 +0000","pub_date":"2023-02-14 08:03:56 +0000","version":15,"workflows":[{"workflow":"main_workflow.ga","tests":false,"url":"https://training.galaxyproject.org/training-material/topics/imaging/tutorials/multiplex-tissue-imaging-TMA/workflows/main_workflow.ga","path":"topics/imaging/tutorials/multiplex-tissue-imaging-TMA/workflows/main_workflow.ga","wfid":"imaging-multiplex-tissue-imaging-TMA","wfname":"main_workflow","trs_endpoint":"https://training.galaxyproject.org/training-material/api/ga4gh/trs/v2/tools/imaging-multiplex-tissue-imaging-TMA/versions/main_workflow","license":null,"creators":[],"name":"GTN_Exemplar_002_TMA_workflow","title":"GTN_Exemplar_002_TMA_workflow","test_results":null,"modified":"2024-06-14 12:21:30 +0000","mermaid":"flowchart TD\n  0[\"ℹ️ Input Collection\\nInput Dataset Collection\"];\n  style 0 stroke:#2c3143,stroke-width:4px;\n  1[\"ℹ️ Input Dataset\\nmarkers.csv\"];\n  style 1 stroke:#2c3143,stroke-width:4px;\n  2[\"ℹ️ Input Dataset\\nPhenotypeWorkflow\"];\n  style 2 stroke:#2c3143,stroke-width:4px;\n  3[\"BaSiC Illumination\"];\n  0 -->|output| 3;\n  4[\"ASHLAR\"];\n  3 -->|output_dfp| 4;\n  3 -->|output_ffp| 4;\n  0 -->|output| 4;\n  1 -->|output| 4;\n  5[\"UNetCoreograph\"];\n  4 -->|output| 5;\n  6[\"Mesmer\"];\n  5 -->|tma_sections| 6;\n  ee73bee3-59e7-4e1c-87fd-197b8eac7e15[\"Output\\nMesmer on input dataset(s): Mask\"];\n  6 --> ee73bee3-59e7-4e1c-87fd-197b8eac7e15;\n  style ee73bee3-59e7-4e1c-87fd-197b8eac7e15 stroke:#2c3143,stroke-width:4px;\n  7[\"Convert image\"];\n  5 -->|tma_sections| 7;\n  8[\"MCQUANT\"];\n  1 -->|output| 8;\n  5 -->|tma_sections| 8;\n  6 -->|mask| 8;\n  fe28534a-2b3f-4ecc-8ba9-a106b2d1425c[\"Output\\nPrimary Mask Quantification\"];\n  8 --> fe28534a-2b3f-4ecc-8ba9-a106b2d1425c;\n  style fe28534a-2b3f-4ecc-8ba9-a106b2d1425c stroke:#2c3143,stroke-width:4px;\n  9[\"Rename OME-TIFF Channels\"];\n  1 -->|output| 9;\n  7 -->|output| 9;\n  10[\"Convert McMicro Output to Anndata\"];\n  8 -->|cellmask| 10;\n  11[\"Single Cell Phenotyping\"];\n  10 -->|outfile| 11;\n  2 -->|output| 11;\n  12[\"Vitessce Visualization\"];\n  11 -->|output| 12;\n  9 -->|renamed_image| 12;\n  6 -->|mask| 12;"}],"api":"https://training.galaxyproject.org/training-material/api/topics/imaging/tutorials/multiplex-tissue-imaging-TMA/tutorial.json","tools":["toolshed.g2.bx.psu.edu/repos/goeckslab/mesmer/mesmer/0.12.3+galaxy2","toolshed.g2.bx.psu.edu/repos/goeckslab/rename_tiff_channels/rename_tiff_channels/0.0.1+galaxy1","toolshed.g2.bx.psu.edu/repos/goeckslab/scimap_mcmicro_to_anndata/scimap_mcmicro_to_anndata/0.17.7+galaxy0","toolshed.g2.bx.psu.edu/repos/goeckslab/scimap_phenotyping/scimap_phenotyping/0.17.7+galaxy0","toolshed.g2.bx.psu.edu/repos/goeckslab/vitessce_spatial/vitessce_spatial/1.0.4+galaxy0","toolshed.g2.bx.psu.edu/repos/imgteam/bfconvert/ip_convertimage/6.7.0+galaxy0","toolshed.g2.bx.psu.edu/repos/perssond/ashlar/ashlar/1.14.0+galaxy1","toolshed.g2.bx.psu.edu/repos/perssond/basic_illumination/basic_illumination/1.0.3+galaxy1","toolshed.g2.bx.psu.edu/repos/perssond/coreograph/unet_coreograph/2.2.8+galaxy1","toolshed.g2.bx.psu.edu/repos/perssond/quantification/quantification/1.5.3+galaxy1"],"supported_servers":{"exact":[],"inexact":[{"url":"https://usegalaxy.be/","name":"UseGalaxy.be","usegalaxy":false},{"url":"https://usegalaxy.no/","name":"UseGalaxy.no","usegalaxy":false}]},"topic_name_human":"Imaging","admin_install":{"install_tool_dependencies":true,"install_repository_dependencies":true,"install_resolver_dependencies":true,"tools":[{"name":"mesmer","owner":"goeckslab","revisions":"187918c47051","tool_panel_section_label":"Spatial Omics","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"rename_tiff_channels","owner":"goeckslab","revisions":"09e240a12897","tool_panel_section_label":"Imaging","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"scimap_mcmicro_to_anndata","owner":"goeckslab","revisions":"8ca435ec19be","tool_panel_section_label":"Imaging","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"scimap_phenotyping","owner":"goeckslab","revisions":"dcfcad35e847","tool_panel_section_label":"Imaging","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"vitessce_spatial","owner":"goeckslab","revisions":"9f60ef2d586e","tool_panel_section_label":"Imaging","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"bfconvert","owner":"imgteam","revisions":"f3360fbeda64","tool_panel_section_label":"Imaging","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"ashlar","owner":"perssond","revisions":"33ab2058c6d9","tool_panel_section_label":"Spatial Omics","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"basic_illumination","owner":"perssond","revisions":"acc6f509968c","tool_panel_section_label":"Spatial Omics","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"coreograph","owner":"perssond","revisions":"ee92746d141a","tool_panel_section_label":"Spatial Omics","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"quantification","owner":"perssond","revisions":"3a916c4e9f5f","tool_panel_section_label":"Spatial Omics","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"}]},"admin_install_yaml":"---\ninstall_tool_dependencies: true\ninstall_repository_dependencies: true\ninstall_resolver_dependencies: true\ntools:\n- name: mesmer\n  owner: goeckslab\n  revisions: 187918c47051\n  tool_panel_section_label: Spatial Omics\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: rename_tiff_channels\n  owner: goeckslab\n  revisions: '09e240a12897'\n  tool_panel_section_label: Imaging\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: scimap_mcmicro_to_anndata\n  owner: goeckslab\n  revisions: 8ca435ec19be\n  tool_panel_section_label: Imaging\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: scimap_phenotyping\n  owner: goeckslab\n  revisions: dcfcad35e847\n  tool_panel_section_label: Imaging\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: vitessce_spatial\n  owner: goeckslab\n  revisions: 9f60ef2d586e\n  tool_panel_section_label: Imaging\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: bfconvert\n  owner: imgteam\n  revisions: f3360fbeda64\n  tool_panel_section_label: Imaging\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: ashlar\n  owner: perssond\n  revisions: 33ab2058c6d9\n  tool_panel_section_label: Spatial Omics\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: basic_illumination\n  owner: perssond\n  revisions: acc6f509968c\n  tool_panel_section_label: Spatial Omics\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: coreograph\n  owner: perssond\n  revisions: ee92746d141a\n  tool_panel_section_label: Spatial Omics\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: quantification\n  owner: perssond\n  revisions: 3a916c4e9f5f\n  tool_panel_section_label: Spatial Omics\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n","tours":false,"video":false,"slides_recordings":false,"translations":{"tutorial":[],"slides":[],"video":false},"license":"CC-BY-4.0","type":"tutorial"}