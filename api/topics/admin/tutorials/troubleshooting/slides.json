{"layout":"tutorial_slides","logo":"assets/images/gat.png","title":"Galaxy Troubleshooting","contributors":["martenson","natefoo"],"subtopic":"maintenance","js_requirements":{"mathjax":null,"mermaid":false},"short_id":"S00026","url":"/topics/admin/tutorials/troubleshooting/slides.html","topic_name":"admin","tutorial_name":"troubleshooting","dir":"topics/admin/tutorials/troubleshooting","symlink":null,"id":"admin/troubleshooting","ref_tutorials":[],"ref_slides":["In system administration...\n# Everything always goes wrong\n\n---\n\n# When things go wrong, where do you begin?\n\n--\n\n## LOGS\n\n--\n\n.left[Check **all** the logs]\n- gunicorn/gravity logs\n- handler logs (if not all-in-one)\n- Pulsar logs\n- nginx error and access logs\n- syslog/messages\n- authlog\n- browser console log\n\n---\n\n# Most common problems\n\n- Startup problems\n- Web/UI problems\n- Tool failures\n- Job execution problems\n- General performance problems\n- Dependency issues\n- Other stuff\n\n---\n\n# Startup problems\n\n--\n\nWhere do you begin? In the...\n\n--\n\n## LOGS\n\nSpecifically, gravity/gunicorn and job handler logs.\n\n---\n\n# Database migration\n\n.reduce90[\n```console\ngalaxy.model.migrations.OutdatedDatabaseError: Your galaxy database has version e0e3bb173ee6, but\nthis code expects version caa7742f7bca. To upgrade your database, run `manage_db.sh upgrade`. For\nmore options (e.g. upgrading/downgrading to a specific version) see instructions in that file.\nPlease remember to backup your database before migrating.\n```\n]\n\nUse Ansible! This is permanently solved for you.\n\nOtherwise, upgrade as instructed.\n\n.left[If you believe this message is in error, you can:]\n- Check DB table `alembic_version`, column `version`.\n- Check folder `lib/galaxy/model/migrations/alembic/versions_gxy/` - the latest migration should match the DB.\n- Clean the `*.pyc` files in migrate versions folder to make sure there is no remnant from other code revisions.\n  - See [makepyc.py in galaxyproject.galaxy](https://github.com/galaxyproject/ansible-galaxy/blob/master/files/makepyc.py).\n  - Ansible role does this for you.\n\n---\nclass: left\n\n# Database migration\n\n**Downgrading** - Perform in this order:\n  1. Downgrade the DB with `manage_db.sh`\n  2. Downgrade Galaxy with `git checkout`\n  3. Clean `*.pyc`\n\n---\n\n# Stuck in a restart loop\n\n.reduce90[\n```console\nExecuting: PYTHONPATH=lib GALAXY_CONFIG_FILE=/srv/galaxy/config/galaxy.yml VIRTUAL_ENV=/srv/galaxy/venv\n  /srv/galaxy/venv/bin/gunicorn 'galaxy.webapps.galaxy.fast_factory:factory()' --timeout 300 ...\nDEBUG:galaxy.app:python path is: /srv/galaxy/server, /srv/galaxy/venv/bin, /srv/galaxy/server/lib, ...\n... bunch of stuff ...\nExecuting: PYTHONPATH=lib GALAXY_CONFIG_FILE=/srv/galaxy/config/galaxy.yml VIRTUAL_ENV=/srv/galaxy/venv\n  /srv/galaxy/venv/bin/gunicorn 'galaxy.webapps.galaxy.fast_factory:factory()' --timeout 300 ...\nDEBUG:galaxy.app:python path is: /srv/galaxy/server, /srv/galaxy/venv/bin, /srv/galaxy/server/lib, ...\n... bunch of stuff ...\nExecuting: PYTHONPATH=lib GALAXY_CONFIG_FILE=/srv/galaxy/config/galaxy.yml VIRTUAL_ENV=/srv/galaxy/venv\n  /srv/galaxy/venv/bin/gunicorn 'galaxy.webapps.galaxy.fast_factory:factory()' --timeout 300 ...\nDEBUG:galaxy.app:python path is: /srv/galaxy/server, /srv/galaxy/venv/bin, /srv/galaxy/server/lib, ...\n...\n```\n]\n\n1. Open the log *without* following\n2. Scroll to the end\n3. Search/scroll back to the last startup attempt\n4. The lines *directly preceding* should offer some insight\n\n---\n# Stuck in a restart loop\n\nThe reason that Galaxy is dying might not be in the log. If it's not, then\n\nIf using **systemd** then it should be in `journalctl -eu galaxy-gunicorn`\n\nIf using something else, it's wherever `stderr` is being redirected to (supervisor?)\n\nOr maybe the system is killing it... (`/var/log/{messages,syslog,kern.log}`, `dmesg`)\n\n---\n\n# Web/UI Problems\n\n--\n\nWhere do you begin? In the...\n\n--\n\n## LOGS\n\nSpecifically: gunicorn, nginx, and browser console logs\n\n---\n\n# 502 Bad Gateway\n\nYour reverse proxy has failed to connect to the Galaxy socket\n\n- `systemctl status galaxy-gunicorn`\n- Check that Galaxy is running / not in a reboot loop\n- Check that your proxy and Galaxy/gunicorn socket options match\n  - For UNIX domain sockets, ensure the web server user can r/w the socket\n- Check proxy server logs (e.g. `/var/log/nginx`)\n- Check gunicorn logs for `[<PID>] [ERROR] Connection in use: ('localhost', 8080)`\n  - Check that something is listening on the correct port (`sudo ss -tlpn 'sport = :port'` (demo!) or `sudo lsof -i :port` (demo!))\n  - If the culprit is gunicorn, make sure it's not an old one!\n\n---\n\n# 504 Gateway Timeout\n\nUse `htop` (demo!) and `ps` (demo!)\n\n- `htop` process state **D** (*kernel uninterruptable sleep*)?\n\n.reduce90[\n```console\n$ htop -u galaxy\n    0[||                                           1.6%]   Tasks: 98, 244 thr; 1 running\n    1[||                                           2.7%]   Load average: 105.04 102.08 91.04\n  Mem[||||||||||||||||||||||||||||||||||||||2.28G/15.6G]   Uptime: 3 days, 15:46:31\n  Swp[                                            0K/0K]\n\n    PID USER      PRI  NI  VIRT   RES   SHR S CPU%▽MEM%   TIME+  Command\n   3440 galaxy     20   0 2806M  297M 53364 D 17.2  5.2  3:11.40 python3 gunicorn ...\n...\n```\n]\n\n---\n\n# 504 Gateway Timeout\n\n- `ps` process state **D**?\n\n.reduce90[\n```console\n$ ps uwwU galaxy\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\ngalaxy    3440 17.2  5.2 2873344 304128 ?      D    Nov10   3:11 python3 gunicorn ...\n...\n```\n]\n\n---\n\n# 504 Gateway Timeout\n\nCycling state **D**/**S**/**R** is fine, but stuck on **D** is Very Bad™\n\nProbably IO - check filesystems, disks.\n\nRestart Galaxy\n\n.reduce70[.footnote[A later slide will cover how to investigate kernel uninterruptable sleep processes]]\n\n---\n\n# 504 Gateway Timeout or slow UI\n\nCheck load\n\n```console\n$ uptime\n 16:08:15 up 3 days,  8:34,  8 users,  load average: 0.12, 0.23, 0.24\n```\n\nAverages are 1, 5, 15 minutes.\n\nAverage should be <= number of cores (`lscpu`, (beware SMT) or just `htop`)\n\nMore on troubleshooting load later\n\n---\n# Where do you begin? In the...\n\n## LOGS*\n\n--\n\n*often I now begin in Grafana\n\n![Grafana Load Graph](../../images/troubleshooting/grafana-load-graph.png \"Grafana Load Graph\")\n\n---\n# 504 Gateway Timeout or slow UI\n\n- Investigate load\n  - Web server(s)\n  - Database server\n- Investigate memory usage, swapping\n- Investigate iowait\n\n---\n\n# Galaxy UI is slow\n\n- [Tutorial from @mvdbeek](https://docs.galaxyproject.org/en/master/dev/finding_and_improving_slow_code.html#profiling)\n- Use Galaxy [heartbeat](https://github.com/galaxyproject/galaxy/blob/8c2066f07ac7bb48c59cf8378e5a852e6fb82a4e/config/galaxy.yml.sample#L1036) (not super relevant anymore thanks to...)\n- Use `py-spy` (demo later!)\n\n---\n\n# Blank page or no CSS/JavaScript\n\nServing of static content is broken.\n\n- Check browser console for 404 errors.\n- Check proxy error log for permission errors.\n- Verify that your proxy static configuration is correct.\n- If you have recently upgraded Galaxy or changed the GUI in some way, you will need to rebuild the client\n\n---\n\n# Tool failures\n\nTools can fail for a variety of reasons, some valid, some invalid.\n\nSome made up examples follow.\n\n---\n\n# Tool missing from Galaxy\n\n- Restart Galaxy and watch the log for\n```console\nLoaded tool id: toolshed.g2.bx.psu.edu/repos/iuc/sickle/sickle/1.33, version: 1.33 into tool panel....\n```\n\n- After startup, check `integrated_tool_panel.xml` for\n```xml\n<tool id=\"toolshed.g2.bx.psu.edu/repos/iuc/sickle/sickle/1.33\" />\n```\n\n- If it is TS tool check `shed_tool_conf.xml` for\n```xml\n<tool file=\"toolshed.g2.bx.psu.edu/repos/iuc/sickle/43e081d32f90/sickle/sickle.xml\" guid=\"toolshed.g2.bx.psu.edu/repos/iuc/sickle/sickle/1.33\">\n...\n</tool>\n```\n\n- Multiple job handlers? Sometimes they don't all get the update.\n\n---\n\n# Tool errors\n\nTool stdout/stderr is available in UI under \"i\" icon on history dataset\n\n.left[Debugging on the filesystem:]\n1. Set `cleanup_job` to `onsuccess`\n2. Cause a job failure\n3. Go to job working directory (find in logs or `/srv/galaxy/jobs/<hash>/<job_id>`)\n4. Poke around, try running things (`srun --pty bash` considered useful)\n\nFamiliarize yourself with the places Galaxy keeps things (demo?)\n\n---\n\n# Tool errors - stderr\n\n**Galaxy considers *any* output to standard error (stderr) to be an error when no tool profile version is set by a tool.**\n\nWhy would it do this????!?!!!11\n\nIn the old days, tools were bad about setting the exit code on failure, so it could not be trusted. Galaxy had no functionality to inspect output to decide on failure.\n\n---\nclass: left\n\n# Tool errors\n\nSo what if tool stderr contains:\n```console\nCongratulations, running SuperAwesome tool was successful!\n```\n\nWhat happens: job fails (!!?!?)\n\nSolutions:\n- If the wrapped tool uses proper exit codes, use `<tool profile=\"16.04\">` or later to ignore stderr\n- Using current tool development best practices ensures this is the case\n- [List of tool profiles](https://docs.galaxyproject.org/en/latest/dev/schema.html#tool-profile)\n\n---\nclass: left\n\n# Tool errors\n\nTool output contains:\n```console\nWarning: Discarded 10000 lines of /input/dataset_1.dat because they looked funny\n```\n\nMaybe a problem, maybe not.\n\nSolutions:\n- Check tool input(s) and parameters (maybe requires some biological knowledge)\n- Verify input is not corrupt\n- User education\n\n---\nclass: left\n\n# Tool errors - memory errors\n\nTool output contains one of:\n```console\nMemoryError                 # Python\nwhat():  std::bad_alloc     # C++\nSegmentation Fault          # C - but could be other problems too\nKilled                      # Linux OOM Killer\n```\n\nSolutions:\n- Change input sizes or params\n  - Map/reduce?\n- Decrease the amount of memory the tool needs\n- Increase the amount of memory available to the job\n  - Request more memory from cluster scheduler\n  - Use job resubmission to automatically rerun with a larger memory allocation\n- Cross your fingers and rerun the job\n\n---\nclass: left\n\n# Tool errors - system errors\n\nTool output contains:\n```console\nopen(): /input/dataset_1.dat: No such file or directory\n```\n\nSolutions:\n- Verify that `/input/dataset_1.dat` exists.\n  - On node the job ran on\n  - As the user the job ran as\n- Fix the filesystem error (NFS?) and rerun the job\n- See NFS caching errors slide later\n\n---\nclass: left\n\n# Tool errors - dependency problems\n\nTool output contains:\n```console\nsh: command not found: samtools\n```\n\nSolutions:\n- Verify that `tool_dependency_dir` is accessible *on the cluster, as the user running Galaxy jobs*\n- Verify that tool dependencies are properly installed: Galaxy UI \"Admin > Manage dependencies\"\n- Use BioContainers (Docker/Singularity)\n\n---\n\n# Manage Dependencies\n\nAn incredibly useful feature to hit unruly tool dependencies with a large hammer.\n\n![Manage Dependencies](../../images/troubleshooting/manage-dependencies.png \"Manage Dependencies\")\n\n--\n\n(demo!)\n\n---\n\n# An aside - dependency problems on geriatric Galaxies\n\nGalaxy Tool Shed dependencies are dead.<sup>1</sup> If you don't know what Tool Shed dependencies are (lucky you) skip this slide.\n\nDon't attempt to fix Galaxy Tool Shed dependencies, just update tool and use container (or Conda) deps.\n\nPut Conda first in [dependency_resolvers_conf.xml](https://github.com/galaxyproject/galaxy/blob/dev/config/dependency_resolvers_conf.xml.sample) if you still need to support both.\n\n.reduce70[.footnote[<sup>1</sup> The Tool Shed should only be used for Galaxy Tool configuration files and wrapper scripts]]\n\n---\nclass: left\n\n# Tool errors - dependency problems\n\nTool output contains:\n```console\nfoo: error while loading shared libraries: libdeepthought.so.42: cannot open shared object file: No such file or directory\n```\n\n`foo` was compiled against `libdeepthought.so.42` but it's not on the runtime linker path\n\nSolutions:\n- Reinstall tool dependencies (\"Admin > Manage dependencies\"). If it still fails<sup>2</sup>:\n  - Determine conda package providing `libdeepthought.so`\n  - Downgrade it to the version that provides `libdeepthought.so.42`\n- Use BioContainers (Docker/Singularity)\n\n.center[.reduce70[.footnote[<sup>2</sup> First, Google the error because someone named Björn has probably already found and fixed the problem.]]]\n\n???\nGalaxy ensures that the correct version(s) of tool(s) immediate dependencies are controlled, but dependencies of dependencies are up to conda. Occasionally, upgrades to these second level dependencies break existing conda packages, requiring package authors to update the first level dependencies to correct the issue.\n\n---\nclass: left\n\n# Tool errors - Empty green history item\n\n1. The tool is not correctly detecting error conditions: inspect stdout/stderr\n2. The tool correctly produced an empty dataset for the given params, inputs\n\nSolutions:\n- Fix the tool wrapper to detect errors\n- User education\n\n---\n\n# Summary of types of tool failures\n\n- Input/parameter problem (user or tool wrapper author problem)\n- Tool wrapper bug (tool wrapper author problem)\n- Tool bug (tool wrapper author or tool developer problem)\n- Resource problem (sysadmin problem)\n\n--\n\nEverything else: always the sysadmin's problem\n\n---\n\n# One last word on tool errors\n\nAll IUC/devteam tools in the Tool Shed have tests\n\nUse these tests (automateable with [Ephemeris](https://github.com/galaxyproject/ephemeris)!) to verify that the tool works in the basic case\n\n---\n\n# Job execution problems\n\n---\nclass: smaller\n\n# Jobs aren't running: always gray\n\nCorresponds to `job.state = 'new'` or `'queued'` in database\n\n.left[Check the Galaxy server log for errors. Successful job lifecycle:]\n\n<pre class=\"reduce50\" style=\"text-align: left\">\ngalaxy.tools INFO 2023-04-20 13:51:20,736 [pN:main.1,p:273250,tN:WSGI_0] Validated and populated state for tool request (4.308 ms)\ngalaxy.tools.actions INFO 2023-04-20 13:51:20,747 [pN:main.1,p:273250,tN:WSGI_0] Handled output named out_file1 for tool secure_hash_message_digest (0.756 ms)\ngalaxy.tools.actions INFO 2023-04-20 13:51:20,759 [pN:main.1,p:273250,tN:WSGI_0] Added output datasets to history (12.102 ms)\ngalaxy.tools.actions INFO 2023-04-20 13:51:20,761 [pN:main.1,p:273250,tN:WSGI_0] Setup for job Job[unflushed,tool_id=secure_hash_message_digest] complete, ready to be enqueued (1.097 ms)\ngalaxy.tools.execute DEBUG 2023-04-20 13:51:20,761 [pN:main.1,p:273250,tN:WSGI_0] Tool secure_hash_message_digest created job None (21.968 ms)\ngalaxy.web_stack.handlers INFO 2023-04-20 13:51:20,792 [pN:main.1,p:273250,tN:WSGI_0] (Job[id=2,tool_id=secure_hash_message_digest]) Handler '_default_' assigned using 'db-skip-locked' assignment method\ngalaxy.tools.execute DEBUG 2023-04-20 13:51:20,797 [pN:main.1,p:273250,tN:WSGI_0] Created 1 job(s) for tool secure_hash_message_digest request (60.168 ms)\ngalaxy.jobs.handler DEBUG 2023-04-20 13:51:20,879 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 2\ntpv.rules.gateway INFO 2023-04-20 13:51:20,920 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] loading tpv rules from: ['https://gxy.io/tpv/db.yml', '/srv/galaxy/config/TPV_DO_NOT_TOUCH/tpv_rules_local.yml']\ntpv.rules.gateway INFO 2023-04-20 13:51:21,266 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] Watching for changes in file: /srv/galaxy/config/TPV_DO_NOT_TOUCH/tpv_rules_local.yml\ngalaxy.util.watcher DEBUG 2023-04-20 13:51:21,266 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] Watching for changes to file: /srv/galaxy/config/TPV_DO_NOT_TOUCH/tpv_rules_local.yml\ntpv.core.entities DEBUG 2023-04-20 13:51:21,354 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=local_runner, ... (line truncated)\ngalaxy.jobs.mapper DEBUG 2023-04-20 13:51:21,354 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] (2) Mapped job to destination id: local_env\ngalaxy.jobs.handler DEBUG 2023-04-20 13:51:21,370 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] (2) Dispatching to local_runner runner\ngalaxy.jobs DEBUG 2023-04-20 13:51:21,387 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] (2) Persisting job destination (destination id: local_env)\ngalaxy.jobs DEBUG 2023-04-20 13:51:21,402 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] (2) Working directory for job is: /data/jobs/000/2\ngalaxy.jobs.runners DEBUG 2023-04-20 13:51:21,412 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] Job [2] queued (41.730 ms)\ngalaxy.jobs.handler INFO 2023-04-20 13:51:21,423 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] (2) Job dispatched\ngalaxy.jobs DEBUG 2023-04-20 13:51:21,500 [pN:handler_1,p:272701,tN:LocalRunner.work_thread-3] Job wrapper for Job [2] prepared (70.012 ms)\ngalaxy.jobs.command_factory INFO 2023-04-20 13:51:21,508 [pN:handler_1,p:272701,tN:LocalRunner.work_thread-3] Built script [/data/jobs/000/2/tool_script.sh] for tool command [python '/srv/galaxy/server/tools/filters/secure_hash_message_digest.py' --input '/data/datasets/5/9/6/dataset_596da164-5b91-4003-8699-db43afd9f26d.dat' --output '/data/jobs/000/2/outputs/galaxy_dataset_bfc51e23-4d98-4968-b9f6-a7fc970fad28.dat' --algorithm \"sha256\"]\ngalaxy.jobs.runners DEBUG 2023-04-20 13:51:21,554 [pN:handler_1,p:272701,tN:LocalRunner.work_thread-3] (2) command is: (multi-line output trimmed)\ngalaxy.jobs.runners.local DEBUG 2023-04-20 13:51:21,558 [pN:handler_1,p:272701,tN:LocalRunner.work_thread-3] (2) executing job script: /data/jobs/000/2/galaxy_2.sh\ngalaxy.jobs.runners.util.process_groups DEBUG 2023-04-20 13:51:25,191 [pN:handler_1,p:272701,tN:LocalRunner.work_thread-3] check_pg(): No process found in process group 587010\ngalaxy.jobs.runners.local DEBUG 2023-04-20 13:51:25,192 [pN:handler_1,p:272701,tN:LocalRunner.work_thread-3] execution finished: /data/jobs/000/2/galaxy_2.sh\ngalaxy.jobs DEBUG 2023-04-20 13:51:25,202 [pN:handler_1,p:272701,tN:LocalRunner.work_thread-3] finish(): Moved /data/jobs/000/2/outputs/galaxy_dataset_bfc51e23-4d98-4968-b9f6-a7fc970fad28.dat to /data/datasets/b/f/c/dataset_bfc51e23-4d98-4968-b9f6-a7fc970fad28.dat\ngalaxy.model.metadata DEBUG 2023-04-20 13:51:25,212 [pN:handler_1,p:272701,tN:LocalRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 2\ngalaxy.jobs INFO 2023-04-20 13:51:25,235 [pN:handler_1,p:272701,tN:LocalRunner.work_thread-3] Collecting metrics for Job 2 in /data/jobs/000/2\ngalaxy.jobs DEBUG 2023-04-20 13:51:25,250 [pN:handler_1,p:272701,tN:LocalRunner.work_thread-3] job_wrapper.finish for job 2 executed (51.404 ms)\n</pre>\n\n---\nclass: smaller, left\n\n# Successful job lifecycle\n\nNote `[pN:NNNN,p:PPPP,tN:NNNN]` in log messages:\n\n.reduce70[\n```console\ngalaxy.tools.execute DEBUG 2023-04-20 13:51:20,761 [pN:main.1,p:273250,tN:WSGI_0] Tool secure_hash_message_digest created job None (21.968 ms)\ngalaxy.jobs.mapper DEBUG 2023-04-20 13:51:21,354 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] (2) Mapped job to destination id: local_env\n```\n]\n\n- `[pN:main.1,p:273250,tN:WSGI_0]`: PID 273250, web worker (not a job handler)\n- `[pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread]`: PID 272701, job handler (not a web worker)\n\n---\nclass: smaller\n\n# Successful job lifecycle\n\nDissecting the lifecycle messages\n\n.reduce70[\n```console\ngalaxy.tools INFO 2023-04-20 13:51:20,736 [pN:main.1,p:273250,tN:WSGI_0] Validated and populated state for tool request (4.308 ms)\ngalaxy.tools.actions INFO 2023-04-20 13:51:20,747 [pN:main.1,p:273250,tN:WSGI_0] Handled output named out_file1 for tool secure_hash_message_digest (0.756 ms)\ngalaxy.tools.actions INFO 2023-04-20 13:51:20,759 [pN:main.1,p:273250,tN:WSGI_0] Added output datasets to history (12.102 ms)\ngalaxy.tools.actions INFO 2023-04-20 13:51:20,761 [pN:main.1,p:273250,tN:WSGI_0] Setup for job Job[unflushed,tool_id=secure_hash_message_digest] complete, ready to be enqueued (1.097 ms)\ngalaxy.tools.execute DEBUG 2023-04-20 13:51:20,761 [pN:main.1,p:273250,tN:WSGI_0] Tool secure_hash_message_digest created job None (21.968 ms)\ngalaxy.web_stack.handlers INFO 2023-04-20 13:51:20,792 [pN:main.1,p:273250,tN:WSGI_0] (Job[id=2,tool_id=secure_hash_message_digest]) Handler '_default_' assigned using 'db-skip-locked' assignment method\ngalaxy.tools.execute DEBUG 2023-04-20 13:51:20,797 [pN:main.1,p:273250,tN:WSGI_0] Created 1 job(s) for tool secure_hash_message_digest request (60.168 ms)\n```\n]\n\n- Job is assigned **Galaxy** job ID 2\n- \"Executed\" is misleading - the Job has been created in the `job` table of the database, but is not picked up by a job handler yet.\n- All of this has occurred in the web worker.\n- If \"Executed\" is the last message you see, verify job assigned to a valid handler.\n\n---\nclass: smaller\n\n# Successful job lifecycle\n\n.reduce70[\n```console\ngalaxy.jobs.handler DEBUG 2023-04-20 13:51:20,879 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] Grabbed Job(s): 2\ntpv.rules.gateway INFO 2023-04-20 13:51:20,920 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] loading tpv rules from: ['https://gxy.io/tpv/db.yml', '/srv/galaxy/config/TPV_DO_NOT_TOUCH/tpv_rules_local.yml']\ntpv.rules.gateway INFO 2023-04-20 13:51:21,266 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] Watching for changes in file: /srv/galaxy/config/TPV_DO_NOT_TOUCH/tpv_rules_local.yml\ngalaxy.util.watcher DEBUG 2023-04-20 13:51:21,266 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] Watching for changes to file: /srv/galaxy/config/TPV_DO_NOT_TOUCH/tpv_rules_local.yml\ntpv.core.entities DEBUG 2023-04-20 13:51:21,354 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] Ranking destinations: [runner=local_runner, dest_name=local_env, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=1, max_accepted_mem=None, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[], handler_tags=None<class 'tpv.core.entities.Destination'> id=local_env, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=None, params={'tmp_dir': True}, resubmit=None, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context=None, rules={}, runner=local_runner, dest_name=singularity, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=1, max_accepted_mem=None, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[], handler_tags=None<class 'tpv.core.entities.Destination'> id=singularity, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[{'name': 'LC_ALL', 'value': 'C'}, {'name': 'SINGULARITY_CACHEDIR', 'value': '/tmp/singularity'}, {'name': 'SINGULARITY_TMPDIR', 'value': '/tmp'}], params={'singularity_enabled': True}, resubmit=None, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=None, context=None, rules={}, runner=slurm, dest_name=slurm, min_accepted_cores=None, min_accepted_mem=None, min_accepted_gpus=None, max_accepted_cores=24, max_accepted_mem=256, max_accepted_gpus=None, tpv_dest_tags=<class 'tpv.core.entities.TagSetManager'> tags=[], handler_tags=None<class 'tpv.core.entities.Destination'> id=slurm, abstract=False, cores=None, mem=None, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = 2, max_mem = 8, max_gpus = None, env=[{'name': 'LC_ALL', 'value': 'C'}, {'name': 'SINGULARITY_CACHEDIR', 'value': '/tmp/singularity'}, {'name': 'SINGULARITY_TMPDIR', 'value': '/tmp'}], params={'singularity_enabled': True, 'native_specification': \"--nodes=1 --ntasks=1 --cpus-per-task={cores} --time={params['walltime']}:00:00\"}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[], rank=, inherits=singularity, context={}, rules={}] for entity: <class 'tpv.core.entities.Tool'> id=default, abstract=False, cores=1, mem=4, gpus=None, min_cores = None, min_mem = None, min_gpus = None, max_cores = None, max_mem = None, max_gpus = None, env=[], params={'walltime': 8}, resubmit={}, tags=<class 'tpv.core.entities.TagSetManager'> tags=[<Tag: name=scheduling, value=offline, type=TagType.REJECT>], rank=helpers.we, inherits=None, context={}, rules={} using custom function\n```\n]\n\n- handler_1 \"grabbed\" (pulled the job from the database and assigned itself) by setting `job.handler` to its own `server_name`\n- The job is passed to TPV, which evaluates its rules and decides where to send the job\n\n---\nclass: smaller\n\n# Successful job lifecycle\n\n.reduce70[\n```console\ngalaxy.jobs.mapper DEBUG 2023-04-20 13:51:21,354 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] (2) Mapped job to destination id: slurm_env\ngalaxy.jobs.handler DEBUG 2023-04-20 13:51:21,370 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] (2) Dispatching to slurm_runner runner\ngalaxy.jobs DEBUG 2023-04-20 13:51:21,387 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] (2) Persisting job destination (destination id: slurm_env)\ngalaxy.jobs DEBUG 2023-04-20 13:51:21,402 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] (2) Working directory for job is: /data/jobs/000/2\ngalaxy.jobs.runners DEBUG 2023-04-20 13:51:21,412 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] Job [2] queued (41.730 ms)\ngalaxy.jobs.handler INFO 2023-04-20 13:51:21,423 [pN:handler_1,p:272701,tN:JobHandlerQueue.monitor_thread] (2) Job dispatched\n```\n]\n\n- `(2)` at beginning of job log messages is **Galaxy** job ID\n- Job is mapped to job environment `slurm_env`\n- Job is dispatched to job runner plugin `slurm_runner`\n- The job working directory is created\n\n---\nclass: smaller\n\n# Successful job lifecycle\n\n.reduce70[\n```console\ngalaxy.jobs DEBUG 2023-04-20 13:51:21,500 [pN:handler_1,p:272701,tN:SlurmRunner.work_thread-3] Job wrapper for Job [2] prepared (70.012 ms)\ngalaxy.jobs.command_factory INFO 2023-04-20 13:51:21,508 [pN:handler_1,p:272701,tN:SlurmRunner.work_thread-3] Built script [/data/jobs/000/2/tool_script.sh] for tool command [python '/srv/galaxy/server/tools/filters/secure_hash_message_digest.py' --input '/data/datasets/5/9/6/dataset_596da164-5b91-4003-8699-db43afd9f26d.dat' --output '/data/jobs/000/2/outputs/galaxy_dataset_bfc51e23-4d98-4968-b9f6-a7fc970fad28.dat' --algorithm \"sha256\"]\ngalaxy.jobs.runners DEBUG 2023-04-20 13:51:21,554 [pN:handler_1,p:272701,tN:SlurmRunner.work_thread-3] (2) command is: [command trimmed, see tool script (above), job script (below)]\ngalaxy.jobs.runners.drmaa DEBUG 2023-04-20 13:51:21,821 [pN:handler_1,p:272701,tN:SlurmRunner.work_thread-3] (2) submitting file /srv/galaxy/jobs/000/2/galaxy_2.sh\ngalaxy.jobs.runners.drmaa DEBUG 2023-04-20 13:51:21,843 [pN:handler_1,p:272701,tN:SlurmRunner.work_thread-3] (2) queued as 1\ngalaxy.jobs.runners.drmaa DEBUG 2023-04-20 13:51:21,867 [pN:handler_1,p:272701,tN:SlurmRunner.work_thread-3] (2) Persisting job destination (destination id: slurm_env)\n```\n]\n\n- The job has been dispatched and has been assigned **Slurm** job ID 1\n\n---\nclass: smaller\n\n# Successful job lifecycle\n\n```console\ngalaxy.jobs.runners.drmaa DEBUG 2023-04-20 13:51:22,158 [pN:handler_1,p:272701,tN:SlurmRunner.work_thread-3] (2/1) state change: job is queued and active\ngalaxy.jobs.runners.drmaa DEBUG 2023-04-20 13:51:23,171 [pN:handler_1,p:272701,tN:SlurmRunner.work_thread-3] (2/1) state change: job is running\ngalaxy.jobs.runners.drmaa DEBUG 2023-04-20 13:51:51,666 [pN:handler_1,p:272701,tN:SlurmRunner.work_thread-3] (2/1) state change: job finished normally\ngalaxy.model.metadata DEBUG 2023-04-20 13:51:25,212 [pN:handler_1,p:272701,tN:SlurmRunner.work_thread-3] loading metadata from file for: HistoryDatasetAssociation 2\ngalaxy.jobs INFO 2023-04-20 13:51:25,235 [pN:handler_1,p:272701,tN:SlurmRunner.work_thread-3] Collecting metrics for Job 2 in /data/jobs/000/2\ngalaxy.jobs DEBUG 2023-04-20 13:51:25,250 [pN:handler_1,p:272701,tN:SlurmRunner.work_thread-3] job_wrapper.finish for job 2 executed (51.404 ms)\n```\n\n- `(2/1)` at beginning of job log messages now includes **Slurm** job ID\n- The job is done\n- Its `state` column and its output datasets' `state` columns have been updated to `ok`\n\n---\n# Jobs aren't running\n\n![Job in new state](../../images/troubleshooting/hda-new.png \"Job in new state\")\n\nCorresponds to `job.state = 'new'` in database\n\nNot yet picked up by the Galaxy job handler subsystem\n\nTroubleshooting depends on your job handler configuration\n\n---\n\nSolutions:\n- If using single process\n  - Ensure no `handlers` in job conf\n  - Check Galaxy logs\n- If using `assign: \"db-skip-locked\"`\n  - Ensure no `default` key in `handling:`\n  - Ensure no individual `handler:` defined\n  - Ensure `handler` column of `job` table is being set to `_default_`\n  - Ensure handlers started with `--attach-to-pool=job-handlers`\n\n---\nclass: left, reduce90\n\n# Handler ID to server_name match check\n\nJob handler assignment check:\n\n```console\n$ journalctl -g ' is running$' -u 'galaxy-handler*'\ngalaxy.web.stack INFO 2019-01-31 15:18:35,228 [MainThread] Galaxy server instance 'handler_0' is running\ngalaxy.web.stack INFO 2019-01-31 15:18:35,228 [MainThread] Galaxy server instance 'handler_1' is running\n```\n\n```console\n$ gxadmin query job-info 2\n```\n.reduce70[\nid  | tool_id | state |    handler        | username |        create_time         | job_runner_name | job_runner_external_id\n--- | ------- | ----- | ----------------- | -------- | -------------------------- | --------------- | -----------------------\n21  | testing | new   | **job_handler_0** | admin    | 2019-02-01 14:30:20.540327 |                 |\n]\n\nIn this case, `job_handler_0` is not `handler_0` or `handler_1` (probably due to a misconfiguration in `handlers` section of job conf), so no handler will find this job.\n\n---\n\n# An aside - unruly logs\n\n`galaxyctl follow` or `journalctl -fu 'galaxy*'` follows *all* logs, which can make it hard to find what you're lookng for when watching live logs.\n\n.left[Limit to specific services, e.g.:]\n\n`galaxyctl` | `journalctl`\n--- | ---\n`galaxyctl follow gunicorn` | `journalctl -fu galaxy-gunicorn`\n`galaxyctl follow handler` | `journalctl -fu 'galaxy-handler*'`\n`galaxyctl follow tusd` | `journalctl -fu 'galaxy-tusd'`\n\n---\n\n# Jobs aren't running\n\n![Job in queued state](../../images/troubleshooting/hda-queued.png \"Job in queued state\")\n\nCorresponds to `job.state = 'queued'` in database\n\nA handler has seen this job\n\n.left[Verify concurrency limits unmet in job conf:]\n- Local jobs: value of plugin `workers` attribute (default: 4)\n- All jobs: Entire `limits:` section:\n\nUsers are *not* informed when they have reached the job limits. Exceeding disk quota also pauses jobs, but users are notified of this.\n\n---\n\n# Jobs aren't running\n\n.left[Check database for:]\n- Destination ID (`gxadmin query job-info`)\n- Job runner external (DRM) ID (`gxadmin query job-info`)\n- Jobs owned by user in non-terminal state if limits in use (`gxadmin query jobs-nonterminal [user]`)\n- Check handler **logs**\n\nIf external ID is assigned, job is queued on a cluster. Use cluster queue status tool(s) to investigate further.\n\n---\n\n# Jobs aren't finishing\n\n![Job in running state](../../images/troubleshooting/hda-running.png \"Job in running state\")\n\nCorresponds to `job.state = 'running'` in database\n\nGet job runner external (DRM) ID (`gxadmin query job-info`), use cluster queue status tool(s) to investigate further.\n\n.left[If the DRM job is finished but the Galaxy job is still \"running\":]\n- Check last job handler log message for job\n- Setting/collecting metadata can be slow: wait\n- Check handlers health (`py-spy` or `gdb` (demos later!))\n\n---\n\n# Overall slow processing of jobs\n\nProcess state **D**?\n\n```console\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\ngalaxy    3440 17.2  5.2 1696480 863536 ?      D    Nov10 167:46 python3 scripts/galaxy-main --server-name=handler0 ...\n```\n\nKernel uninterruptable sleep. Probably IO. Check filesystems, disks.\n\n.reduce70[.footnote[A later slide will cover how to investigate kernel uninterruptable sleep processes]]\n\n---\n\n# Overall slow processing of jobs\n\nProcess state *not* **D**?\n\n- Use `py-spy` (demo!)\n- Use `gdb` (demo!)\n\n---\n\n# General performance problems\n\n---\n\n# Kernel uninterruptable sleep\n\nProcess state **D**?\n\n```console\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\ngalaxy    3440 17.2  5.2 1696480 863536 ?      D    Nov10 167:46 python3 scripts/galaxy-main --server-name=handler0 ...\n```\n\nKernel uninterruptable sleep. Probably IO. Check filesystems, disks.\n\n- Investigate `/proc/<pid>/fd` (demo!) or `lsof -p <pid>` (demo!)\n- Use `strace` (demo!)\n\n.reduce70[.footnote[This slide covers how to investigate kernel uninterruptable sleep processes]]\n\n---\n\n# Local or Network FS slow/down\n\n- Use `iostat` and/or `nfsiostat` to see device performance (demo!)\n- Use `dstat` to see pretty device performance summary (demo!)\n- Use `time dd` (quick and dirty) or `fio` to test write performance (demo!)\n- Use Wireshark\n\n![Packet capture in Wireshark](../../images/troubleshooting/wireshark.png \"Packet capture in Wireshark\")\n\n---\n\n# Local or Network FS slow/down\n\nSolutions:\n- Don't put the Galaxy server in that FS. Local distribution, CVMFS, ??\n- Install Galaxy in two places and use [Pulsar Embedded Mode](https://github.com/galaxyproject/galaxy/blob/3a90b833d1169100b07ba64332886a817aebb55d/lib/galaxy/config/sample/job_conf.sample.yml#L319) with [file actions](https://pulsar.readthedocs.io/en/latest/galaxy_conf.html#data-staging) to rewrite paths<sup>3</sup>\n- Get a better network FS\n\n.reduce70[.footnote[<sup>3</sup> Ply @jmchilton with McDonalds hashbrowns for more Pulsar Embedded Mode documentation]]\n\n---\n\n# NFS caching errors\n\nGalaxy gets \"No such file or directory\" for files that exist. NFS attribute caching is to blame. Set:\n\n```yaml\ngalaxy:\n    retry_job_output_collection: 5\n```\n\n[retry_job_output_collection](https://github.com/galaxyproject/galaxy/blob/476b1948190436664581cfe56c8c1c1dcc0b2370/lib/galaxy/jobs/__init__.py#L1469)\n\n---\n\n# Database problems\n\nSlow queries, high load, etc.\n\n- Use `EXPLAIN ANALYZE` (demo!)\n  - [Example of the \"jobs ready to run\" query](https://gist.github.com/natefoo/da46bea8136ba67d65f616c86a27c454)\n  - `database_engine_option_echo` (but warning, extremely verbose)\n  - `slow_query_log_threshold` logs to Galaxy log file\n  - `sentry_sloreq_threshold` if using Sentry\n  - [Postgres EXPLAIN Visualizer (PEV)](https://tatiyants.com/pev/#/plans) considered useful ([demo data](https://gist.github.com/hexylena/467c7726b5ab9e18c47080893dbc072e))\n- Use `VACUUM ANALYZE`\n- `gxadmin query pg-*` commands\n\nIncrease `shared_buffers`. 2GB on Main (16GB of memory on VM). Better: [Use PGTune!](https://pgtune.leopard.in.ua/)\n\n---\n\n# Other stuff\n\n---\n\n# error: [Errno 32] Broken pipe\n\nThis error is not indicative of any kind of failure. It just means that the client closed a connection before the server finished sending a response.\n\n---\n\n# Other stuff\n\n- Galaxy server process (not jobs): Run Galaxy in a cgroup with a memory limit\n- `scripts/helper.py` and `scripts/secret_decoder_ring.py` can encode/decode IDs from UI\n- `scripts/helper.py` can also fail jobs with a notice to the user\n\n---\n\n# Job failures\n\n\"Unable to run job due to a misconfiguration of the Galaxy job running system.  Please contact a site administrator.\"\n\nThere is a traceback in the Galaxy log. Go find it.\n\n---\n\n# Node failures\n\n```console\n$ sinfo -Nel\nFri Nov 11 09:50:01 2016\nNODELIST   NODES PARTITION       STATE CPUS    S:C:T MEMORY TMP_DISK WEIGHT FEATURES REASON\nlocalhost      1    debug*        down    2    2:1:1      1        0      1   (null) Node unexpectedly rebooted\n```\n\nFigure out why it rebooted and:\n\n```console\n$ sudo scontrol update nodename=localhost state=resume\n```\n\n---\n\n# User over quota\n\nInstruct user (or use impersonate with consent) to check for *deleted* but not *purged* histories\n\nIn the Admin/Users menu you can run `Recalculate Disk Usage` on a certain user\n\nThere is also a command line version: `scripts/set_user_disk_usage.py`\n\n\n\n---\n\n# Any troubling Galaxy situations you have?\n\n---\n\n# Where to get help\n\n- [Admins Chat](https://matrix.to/#/#galaxyproject_admins:gitter.im)\n- [Galaxy Help](https://help.galaxyproject.org/)\n- [Hub Support page](https://galaxyproject.org/support/)\n"],"hands_on":false,"slides":true,"mod_date":"2024-02-14 09:44:48 +0000","pub_date":"2019-01-28 04:08:04 +0000","version":27,"api":"https://training.galaxyproject.org/training-material/api/topics/admin/tutorials/troubleshooting/tutorial.json","tools":[],"supported_servers":[],"topic_name_human":"Galaxy Server administration","admin_install":{"install_tool_dependencies":true,"install_repository_dependencies":true,"install_resolver_dependencies":true,"tools":[]},"admin_install_yaml":"---\ninstall_tool_dependencies: true\ninstall_repository_dependencies: true\ninstall_resolver_dependencies: true\ntools: []\n","tours":false,"video":false,"slides_recordings":false,"translations":{"tutorial":[],"slides":[],"video":false},"license":"CC-BY-4.0","type":"tutorial","redirect_from":["/short/admin/troubleshooting/slides","/short/S00026"]}