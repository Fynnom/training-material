{"layout":"tutorial_hands_on","title":"Creating metadata using Ecological Metadata Language (EML) standard with EML Assembly Line functionalities","zenodo_link":"https://zenodo.org/records/10663465","questions":["How to generate detailled metadata easily from biodiversity datasets ?","How to use international metadata standard?","How to update metadata informations ?"],"objectives":["Explain the necessity of using such tools when producing ecological metadata","Learn how to create rich metadata using Ecological Metadata Language (EML) standard","Learn how to update EML metadata"],"time_estimation":"30M","key_points":["This tool aims to improve FAIR quality of metadata focusing on user exeprience and automatic inferences","Creating metadata as FAIR as possible is a must","Be carefull of the format and standard of metadata used only EML metadata will work"],"tags":["Metadata","EML","Ecology","Biodiversity","FAIR","Data Paper","work-in-progress"],"draft":true,"contributions":{"authorship":["yvanlebras","ThibaudGlinez"],"editing":["yvanlebras","ThibaudGlinez","hexylena"],"funding":["fnso2019","pndb"]},"js_requirements":{"mathjax":null,"mermaid":false},"short_id":"T00422","url":"/topics/ecology/tutorials/MetaShARK_tutorial/tutorial.html","topic_name":"ecology","tutorial_name":"MetaShARK_tutorial","dir":"topics/ecology/tutorials/MetaShARK_tutorial","symlink":null,"id":"ecology/MetaShARK_tutorial","ref_tutorials":["<p align=\"justify\">This tutorial aims to teach <b>how to use functionalities of the EML Assembly Line R package to produce rich metadata</b> using the Ecological Metadata Language (EML) international metadata standard. Here, we will notably propose a concrete example on how to use <b>Galaxy Ecology tools to create, evaluate and modify EML metadata</b> content using both EML Assemby Line metadata template tabular files, easily readable and editable by humans, and XML file, devoted to machine.</p>\n\n<blockquote class=\"agenda\">\n  <agenda-title></agenda-title>\n\n  <p>In this tutorial, we will cover:</p>\n\n<ol id=\"markdown-toc\">\n  <li><a href=\"#1-how-can-eml-assembly-line-functionalities-help-producing-rich-metadata-easily\" id=\"markdown-toc-1-how-can-eml-assembly-line-functionalities-help-producing-rich-metadata-easily\">1] How can EML Assembly Line functionalities help producing rich metadata easily?</a></li>\n  <li><a href=\"#2-get-data-to-describe-\" id=\"markdown-toc-2-get-data-to-describe-\">2] Get data to describe üíæüìÇ</a></li>\n  <li><a href=\"#3-metashark---write-rapidly-an-eml-document-through-a-work-in-progress-interactive-app\" id=\"markdown-toc-3-metashark---write-rapidly-an-eml-document-through-a-work-in-progress-interactive-app\">3] MetaShARK ü¶à : Write rapidly an EML document through a work in progress interactive app</a></li>\n  <li><a href=\"#4-metashrimps---easily-fairness-assessment-and-data-paper-sketches-creation\" id=\"markdown-toc-4-metashrimps---easily-fairness-assessment-and-data-paper-sketches-creation\">4] MetaShRIMPS ü¶ê : Easily FAIRness assessment and data paper sketches creation</a></li>\n  <li><a href=\"#5-draft-of-data-paper-\" id=\"markdown-toc-5-draft-of-data-paper-\">5] Draft of Data Paper üìù</a></li>\n  <li><a href=\"#6-fair-quality-assessment-report-\" id=\"markdown-toc-6-fair-quality-assessment-report-\">6] FAIR Quality Assessment report üìä‚úÖ</a></li>\n  <li><a href=\"#7-conclusion\" id=\"markdown-toc-7-conclusion\">7] Conclusion</a></li>\n</ol>\n\n</blockquote>\n\n<h1 id=\"1-how-can-eml-assembly-line-functionalities-help-producing-rich-metadata-easily\">1] How can EML Assembly Line functionalities help producing rich metadata easily?</h1>\n\n<p align=\"justify\"> A major gap when a researcher is writing metadata documents is the fact that metadata international <b>standards often use formats not really human readable</b> and/or editable as XML or JSON. To answer this issue, <b>[Environmental Data Initiative](https://edirepository.org/) (EDI)</b> through the <b>EML Assembly Line R package</b> propose to generate intermediate metadata template files using classical tabular text format.\nAnother major issue regarding <b>metadata fill in</b>, is the fact that one <b>need to take a lot of time to write</b>, and often rewrite, metadata elements who can be already filled using automatic inferences or use of webservices. Here again, Environmental Data Initiaitve (EDI) through the <b>EML Assembly Line R</b> package propose to <b>generate automatically information</b> related to data attributes, geographic coverage, taxonomic coverage, using the content of provided datafiles.\n<br /><br />\nFinally, through the MetaShARK R Shiny app, an R Shiny app in beta version for test, created by the french biodiversity data hub research infrastructure (P√¥le national de donn√©es de Biodiversit√© (<b>PNDB</b>)), user can use a graphical user interface to apply the EML Assembly Line workflow and benefit from some additionnal functionnalities as:</p>\n\n<ul>\n  <li>Capacity to associate terminological resources terms coming from Bioportal ontologies to data attributes as keywords using CEDAR API</li>\n  <li>Automatic fill in of personal information using ORCID API</li>\n  <li>Automatic production of a data paper draft</li>\n</ul>\n\n<p><br /></p>\n\n<blockquote class=\"comment\">\n  <comment-title>What is a <b>Data Paper</b> ?</comment-title>\n  <p>According to the <a href=\"https://www.gbif.org/data-papers\">GBIF</a> (Global Biodiversity Information Facility), \nA data paper is a peer reviewed document describing a dataset, published in a peer reviewed journal. It takes effort to prepare, curate and describe data. \nData papers provide recognition for this effort by means of a scholarly article.</p>\n</blockquote>\n\n<h1 id=\"2-get-data-to-describe-\">2] Get data to describe üíæüìÇ</h1>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title> Data Upload </hands-on-title>\n\n  <ol>\n    <li>Create a new history for this tutorial. You can name it ‚ÄúEML assembly Line tutorial‚Äù for example</li>\n    <li>Download all files on your local computer from Zenodo: https://zenodo.org/api/records/10663465/files-archive. It is neccessary as for now, MetaShARK is deployed from Galaxy but without having a possibility to directly populate MetaShARK app with datafiles from Galaxy. You will thus then have to upload manually data files from your local computer to MetaShARK.</li>\n    <li>Unzip the donwloaded archive so you can access each file independently</li>\n    <li>Import tsv, netcdf and geotiff data files directly from <a href=\"https://zenodo.org/records/10663465\">Zenodo</a> so it can be used on some steps of the tutorial.\n -&gt; Training Data for ‚ÄúCreating metadata using Ecological Metadata Language (EML) standard with EML Assembly Line functionalities‚Äù Galaxy tutorial:\n      <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>https://zenodo.org/records/10663465/files/datafile_1.tsv\nhttps://zenodo.org/records/10663465/files/datafile_2.tsv\nhttps://zenodo.org/records/10663465/files/LakeGeneva_phytoplankton_1974-2004.nc\nhttps://zenodo.org/records/10663465/files/Present.Surface.pH.tif\n</code></pre></div>      </div>\n      <p><a href=\"./Images/0_Upload_datafiles.png\" rel=\"noopener noreferrer\"><img src=\"./Images/0_Upload_datafiles.png\" alt=\"Upload datafiles. \" width=\"1916\" height=\"1080\" loading=\"lazy\" /></a></p>\n    </li>\n    <li>Import shapefile related files into Galaxy using the Galaxy upload tool, then on the ‚Äúcomposite‚Äù tab, specifying ‚Äúshp‚Äù composite type, then uploading .dbf, .shp and .shx files on the dedicated spaces.\n<a href=\"./Images/1_upload_shapefile.png\" rel=\"noopener noreferrer\"><img src=\"./Images/1_upload_shapefile.png\" alt=\"Upload shapefile. \" width=\"1437\" height=\"652\" loading=\"lazy\" /></a></li>\n  </ol>\n</blockquote>\n\n<h1 id=\"3-metashark---write-rapidly-an-eml-document-through-a-work-in-progress-interactive-app\">3] MetaShARK ü¶à : Write rapidly an EML document through a work in progress interactive app</h1>\n\n<p>To deploy a MetaShARK app, you can go to the Galaxy tool <span class=\"tool\" data-tool=\"interactive_tool_metashark\" title=\"MetaShARK tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>MetaShARK</strong></span> and click ‚ÄúExecute‚Äù. Then, you have to wait the launch of the app, and when ready to be used, you will see the message ‚ÄúThere is an InteractiveTool result view available,‚Äù with an hyperlink on the ‚ÄúOpen‚Äù statement allowing you to reach the app clicking on it.</p>\n\n<blockquote class=\"comment\">\n  <comment-title>WARNING</comment-title>\n  <p>üöß Note that MetaShARK R shiny app is in beta version. You can thus encounter issues using it!</p>\n</blockquote>\n\n<p>When oppening MetaShARK, you will have an interface looking like this :</p>\n\n<p><a href=\"./Images/2_MetaShARK.png\" rel=\"noopener noreferrer\"><img src=\"./Images/2_MetaShARK.png\" alt=\"MetaShARK interface. \" width=\"1786\" height=\"763\" loading=\"lazy\" /></a></p>\n\n<p>To start creating metadata, you need to reach the <strong>Fill in EML</strong> module, then specify or complete the automatic <code class=\"language-plaintext highlighter-rouge\">Data package name</code> and mention the <code class=\"language-plaintext highlighter-rouge\">Dataset title</code>. Here a title can be ‚ÄúManage heterogeneous data files through EML‚Äù. Finally, you can choose an open licence between CC-BY-4.0, default, or CC0 then click on ‚ÄúCreate‚Äù.</p>\n\n<p><a href=\"./Images/3_MetaShARK_create.png\" rel=\"noopener noreferrer\"><img src=\"./Images/3_MetaShARK_create.png\" alt=\"Create EML Assembly Line &quot;data package&quot;. \" width=\"1922\" height=\"809\" loading=\"lazy\" /></a></p>\n\n<p>Then you can upload datafiles. Here, you can import these files from the downloaded Zenodo archive (link : https://zenodo.org/api/records/10663465/files-archive):</p>\n\n<p>üìÅ List of datasets :</p>\n<ul>\n  <li>datafile_1.<strong>tsv</strong></li>\n  <li>datafile_2.<strong>tsv</strong></li>\n  <li>LakeGeneva_phytoplankton_1974-2004.<strong>nc</strong></li>\n  <li>Present.Surface.pH.<strong>tif</strong></li>\n  <li>02_Ref.<strong>shp</strong></li>\n  <li>02_Ref.<strong>shx</strong></li>\n  <li>02_Ref.<strong>dbf</strong></li>\n</ul>\n\n<blockquote class=\"comment\">\n  <comment-title>NOTE</comment-title>\n  <p>The folder contains many files with different extensions but MetaShark will normally recognise several types of file extension (notably .tsv for tabulated text files, shapefiles, .geotiff and .geojson)!</p>\n</blockquote>\n\n<p><a href=\"./Images/4_MetaShARK_upload.png\" rel=\"noopener noreferrer\"><img src=\"./Images/4_MetaShARK_upload.png\" alt=\"Upload datafiles on MetaShARK. \" width=\"1915\" height=\"1079\" loading=\"lazy\" /></a></p>\n\n<p align=\"justify\">MetaShARK will normally guess that the three `02_Ref` files are representing a uniq shapefile. MetaShARK will normally guess each data type and infer list of attributes for each file but the geotiff `Present.Surface.pH.tif` one. So now you need to select this datafile and upload the `attributes_Present.Surface.pH.txt` metadata template file so MetaShARK can fill attributes of this file (here the attribute is named \"Present.Surface.pH\").</p>\n\n<p><a href=\"./Images/5_MetaShARK_geotiffattributes.png\" rel=\"noopener noreferrer\"><img src=\"./Images/5_MetaShARK_geotiffattributes.png\" alt=\"Upload metadata template for geotiff attributes. \" width=\"1894\" height=\"1019\" loading=\"lazy\" /></a></p>\n\n<p align=\"justify\">Then you can provide a description for this attribute, for example \"Present surface pH\", then look at each attribute information of each data file so you can click on the \"Next\" button and go to the next step, to give informations on categorical variables!</p>\n\n<p><a href=\"./Images/6_MetaShARK_catvars.png\" rel=\"noopener noreferrer\"><img src=\"./Images/6_MetaShARK_catvars.png\" alt=\"Categorical variables. \" width=\"1920\" height=\"1080\" loading=\"lazy\" /></a></p>\n\n<p align=\"justify\">Clicking \"Next\" button will then allows you to fill spatial informations about all GIS recognized datafiles, here the `Present.Surface.pH.tif` geotiff raster file and the `02_Ref` shapefile vector file. Geotiff is in pixel, accuracy can be set to unknown and shapefile is in Point, both are in `GCS_WGS_1984`spatial reference.</p>\n\n<p><a href=\"./Images/7_MetaShARK_spatialinfo.png\" rel=\"noopener noreferrer\"><img src=\"./Images/7_MetaShARK_spatialinfo.png\" alt=\"Spatial information. \" width=\"1922\" height=\"1051\" loading=\"lazy\" /></a></p>\n\n<p align=\"justify\">Next step is devoted to specifying geographic coverage.<br /><br /> You can use a method between \"columns\" or \"custom\". \"Custom\" allows you to create one to several geographical sites using a map widget where you can draw limits of each site or enter directly latitude and longitude coordinates. \"Columns\" method, used here, allows you to specify an attribute containing site names then associated latitude and longitudes attributes.</p>\n\n<p><a href=\"./Images/8_MetaShARK_geocov.png\" rel=\"noopener noreferrer\"><img src=\"./Images/8_MetaShARK_geocov.png\" alt=\"Geographic coverage. \" width=\"1917\" height=\"1074\" loading=\"lazy\" /></a></p>\n\n<p align=\"justify\">Now geographic coverage is set, one can specific taxonomic coverage.<br /><br /> To do so, you can select a data attribute containing taxonomic information then select kind of notation you want to have and finally on which taxonomic authority (or authorities) information will be compared. Note that this can take a while if you have a lot of taxons and time is duplicated for each selected additional authority.</p>\n\n<p><a href=\"./Images/9_MetaShARK_taxcov.png\" rel=\"noopener noreferrer\"><img src=\"./Images/9_MetaShARK_taxcov.png\" alt=\"Taxonomic coverage. \" width=\"1918\" height=\"953\" loading=\"lazy\" /></a></p>\n\n<p align=\"justify\">Now we can fill personal informations.<br /><br /> To do so, the easiest way is to provide ORCID identifiers for each individual person involved as creator, contact and/or PI. Depending on the information filled in ORCID by each individual and on the level of accessibility of each, all field can be automatically filled. If \"PI\" is selected, you can specify a project name, funder name and related funding number.</p>\n\n<p><a href=\"./Images/10_MetaShARK_personal.png\" rel=\"noopener noreferrer\"><img src=\"./Images/10_MetaShARK_personal.png\" alt=\"Personal informations. \" width=\"1920\" height=\"887\" loading=\"lazy\" /></a></p>\n\n<p>Then you can add final elements as:</p>\n\n<ul>\n  <li>An abstract (writing directly on the dedicated field or uploading a text file containing the abstract)</li>\n</ul>\n\n<p><a href=\"./Images/11_MetaShARK_abstract.png\" rel=\"noopener noreferrer\"><img src=\"./Images/11_MetaShARK_abstract.png\" alt=\"Abstract. \" width=\"1893\" height=\"1075\" loading=\"lazy\" /></a></p>\n\n<ul>\n  <li>Methods (writing directly on the dedicated field or uploading a text file, can be in markdown, containing details of the methods used to create data files)</li>\n</ul>\n\n<p><a href=\"./Images/12_MetaShARK_methods.png\" rel=\"noopener noreferrer\"><img src=\"./Images/12_MetaShARK_methods.png\" alt=\"Methods. \" width=\"1891\" height=\"1049\" loading=\"lazy\" /></a></p>\n\n<ul>\n  <li>Keywords, who can be linked to keyword thesaurus. This allows you to create ‚Äúgroup‚Äù of keywords and/or refer to existing terms classifications as we can find in terminological resources such as ontologies or thesaurus.</li>\n</ul>\n\n<p><a href=\"./Images/13_MetaShARK_keywords.png\" rel=\"noopener noreferrer\"><img src=\"./Images/13_MetaShARK_keywords.png\" alt=\"Keywords. \" width=\"1888\" height=\"1078\" loading=\"lazy\" /></a></p>\n\n<blockquote class=\"comment\">\n  <comment-title>You can add Semantic Annotations</comment-title>\n  <p><strong>You can add <a href=\"https://eml.ecoinformatics.org/semantic-annotation-primer\">semantic annotations</a>!</strong></p>\n\n  <p align=\"justify\"> To do so, you need to reach the MetaShARK parameters (upper right icon) then enter your CEDAR token. To create a CEDAR account, you can 1/ register here http://cedar.metadatacenter.org/ then 2/ go on the \"profile\" on http://cedar.metadatacenter.org/ and there 3/ you can find the API key.</p>\n\n  <p>API key format to enter is something like:</p>\n  <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>api 205b1e521f2eaf0ad4a361c438b63205b1e521f2eaf0ad4a361c438b63c438b63\n</code></pre></div>  </div>\n\n  <p align=\"justify\">You then can  use the `+` button on the keyword space to **Add keyword with dataset annotation**. You will have to choose a \"predicate\", from IAO ontology, then an \"object\" from ontologies coming from Bioportal to add information concerning a \"subject\", the ‚Äòthing‚Äô being annotated, here, regarding keyword, \"dataset\", but you can also apply the same to datafiles \"attributes\".</p>\n\n  <p><a href=\"./Images/17_MetaShARK_annotations_predicate.png\" rel=\"noopener noreferrer\"><img src=\"./Images/17_MetaShARK_annotations_predicate.png\" alt=\"Add semantic annotation predicate. \" width=\"1874\" height=\"1063\" loading=\"lazy\" /></a></p>\n\n  <p><a href=\"./Images/18_MetaShARK_annotations_object.png\" rel=\"noopener noreferrer\"><img src=\"./Images/18_MetaShARK_annotations_object.png\" alt=\"Add semantic annotation object. \" width=\"1836\" height=\"1062\" loading=\"lazy\" /></a></p>\n\n</blockquote>\n\n<p align=\"justify\">Finally, you can specify a temporal coverage and go to the last step of this MetaShARK workflow: Generat an EML metadata file! If everything is ok, you will have creation of an EML metadata file.</p>\n\n<p><a href=\"./Images/14_MetaShARK_makeeml.png\" rel=\"noopener noreferrer\"><img src=\"./Images/14_MetaShARK_makeeml.png\" alt=\"Produce EML metadata file. \" width=\"1920\" height=\"1080\" loading=\"lazy\" /></a></p>\n\n<p align=\"justify\">Once EML written, you can <b>download the data package through the button</b> \"Download Data Package\". This will allow you to <b>download a zip archive</b> you can unzip on your local computer. Resulting files are organized through 2 main folders : </p>\n\n<ul>\n  <li><strong>A main folder with data_objects</strong>\n    <ul>\n      <li><code class=\"language-plaintext highlighter-rouge\">all datafiles </code> you uploaded into MetaShARK</li>\n      <li><code class=\"language-plaintext highlighter-rouge\">eml </code> which is the EML metadata file written in XML format</li>\n      <li><code class=\"language-plaintext highlighter-rouge\">metadata_templates </code> with all metadata files written in text format, column separated by tabulations</li>\n    </ul>\n  </li>\n  <li>A <strong>second folder called ‚Äúemldown‚Äù</strong> where a <strong>draft of data paper</strong> written in html format can be accessed</li>\n</ul>\n\n<hr />\n\n<p align=\"center\"><b>üëè Congratulations! You've just produced your first EML yourself!üëè</b></p>\n<hr />\n\n<blockquote class=\"warning\">\n  <warning-title>MetaShARK can Freeze</warning-title>\n  <p><strong>At this final stage, MetaShARK can freeze and show like a ‚Äúfront grey filter‚Äù</strong></p>\n\n  <p>If this is the case, you can refresh MetaShARK app pressing F5 button of your keyboard for example. To dowload the resutling data package, you can go to the ‚ÄúFill In‚Äù module, select the data package you created and click on ‚ÄúDownload.zip‚Äù.</p>\n</blockquote>\n\n<blockquote class=\"tip\">\n  <tip-title>Returning on your MetaShARK instance</tip-title>\n  <p>If you close MetaShARK navigator window, you can reopen it clicking on Menu &gt; User &gt; Active InteractiveTools.\nYou can here click on ‚Äúmetashark visualization‚Äù hyperlink. You can then go on the Fill In module, select \nthe data package you created and click <strong>Load</strong>.</p>\n</blockquote>\n\n<h1 id=\"4-metashrimps---easily-fairness-assessment-and-data-paper-sketches-creation\">4] MetaShRIMPS ü¶ê : Easily FAIRness assessment and data paper sketches creation</h1>\n\n<p>To evaluate and modify metadata elements you have created, you can upload the EML xml file on the Galaxy history you created and all MetaShARK metadata templates files.</p>\n\n<p><a href=\"./Images/15_MetaShRIMPS.png\" rel=\"noopener noreferrer\"><img src=\"./Images/15_MetaShRIMPS.png\" alt=\"Use MetaShRIMPS. \" width=\"1919\" height=\"1080\" loading=\"lazy\" /></a></p>\n\n<p>Open the <a href=\"https://ecology.usegalaxy.eu/root?tool_id=interactive_tool_metashrimps\">MetaShRIMPS interactive tool form</a> and select the EML xml file you just generate with MetaShARK. Clicking on Execute will launch the MetaShRIMPS R Shiny app, the message <code class=\"language-plaintext highlighter-rouge\">There is an InteractiveTool result view available, waiting for view to become active... </code> is displayed until the app will be ready to use. After some time, the message <code class=\"language-plaintext highlighter-rouge\">There is an InteractiveTool result view available</code> confirm the app is deployed and you can access it clicking on <strong>Open</strong>. You will then have an interface looking like this:</p>\n\n<p><a href=\"./Images/upload_1.png\" rel=\"noopener noreferrer\"><img src=\"./Images/upload_1.png\" alt=\"MetaShRIMPS use. \" width=\"1110\" height=\"521\" loading=\"lazy\" /></a></p>\n\n<p>Click on the <strong>Execute</strong> Button, 2 new tabs called ‚ÄúDraft of Data Paper‚Äù and ‚ÄúFair Assessment‚Äù  will appear.\nYou can access all of the tool outputs by clicking on each tab (it can take a little time for your results to be displayed).</p>\n\n<h1 id=\"5-draft-of-data-paper-\">5] Draft of Data Paper üìù</h1>\n\n<p align=\"justify\">By clicking on the <b>\"Draft of Data Paper\"</b> tab, you will have access to the draft of Data Paper presented in an HTML format. You can either navigate through the Data Paper with the tabs or with the scrollbar on the right and access different elements.</p>\n\n<ul>\n  <li>You can at the top of the page <strong>download the draft</strong> in either an <em>HTML format</em> ‚Ä¶. :</li>\n</ul>\n\n<p><a href=\"./Images/Download_HTML.png\" rel=\"noopener noreferrer\"><img src=\"./Images/Download_HTML.png\" alt=\"MetaShRIMPS data paper download in HTLM format. \" width=\"1920\" height=\"1080\" loading=\"lazy\" /></a></p>\n\n<ul>\n  <li>‚Ä¶. or an editable <em>docx format</em> :</li>\n</ul>\n\n<p><a href=\"./Images/Download_docx.png\" rel=\"noopener noreferrer\"><img src=\"./Images/Download_docx.png\" alt=\"MetaShRIMPS editable data paper download in docx format. \" width=\"1267\" height=\"989\" loading=\"lazy\" /></a></p>\n\n<hr />\n\n<p>Voir comment mettre les deux photos c√¥t√©s √† c√¥tes ou un truc mieux</p>\n<hr />\n\n<h1 id=\"6-fair-quality-assessment-report-\">6] FAIR Quality Assessment report üìä‚úÖ</h1>\n\n<p><a href=\"https://www.go-fair.org/fair-principles/\">FAIR</a> stand for <strong>Findable, Accessible, Interoperable, Reusable</strong>. \n<br /> <br /></p>\n\n<p><a href=\"./Images/FAIR_data_principles.jpg\" rel=\"noopener noreferrer\"><img src=\"./Images/FAIR_data_principles.jpg\" alt=\"FAIR principles. \" width=\"1200\" height=\"407\" loading=\"lazy\" /></a></p>\n\n<p><br /></p>\n\n<p align=\"justify\">These principles were to <b>improve the access and usabiliy of data</b> by the machine and to help <b>making data reusable and shareable for users</b>. It covers the whole concept of why it is necessary to produce a rich and described metadata in order to permit external users to <b>understand and reuse data</b> for their own studies.\n  \nThere are several ways of computing the FAIR index, for each letter of the word is associated with a degree of FAIRitude of the data.</p>\n\n<blockquote class=\"comment\">\n  <comment-title>Metadata Quality</comment-title>\n  <p>The aim is to propose a metadata quality index and to see how it is possible to improve, not to punish the user üëç</p>\n</blockquote>\n\n<p>By clicking on the <code class=\"language-plaintext highlighter-rouge\">Fair Assessment</code> tab, you will access the FAIR Quality report of the metadata uploaded.</p>\n\n<p>You will have access to different figures such as a <strong>table displaying the results of all checks tested for your metadata</strong>:</p>\n\n<figure id=\"figure-1\" style=\"max-width: 90%;\"><img src=\"./Images/Fairscore_tab2.png\" alt=\"Table of results. \" width=\"1860\" height=\"966\" loading=\"lazy\" /><a target=\"_blank\" href=\"./Images/Fairscore_tab2.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 1</strong>:</span> Example of the table displaying the results of the Quality Checks</figcaption></figure>\n\n<p>You will also have acces to a graph presenting scores of Quality for each of the FAIR principles tested (Findable,\nAcessible, Interoperable, Reusable) on a 100 point scale.</p>\n\n<figure id=\"figure-2\" style=\"max-width: 90%;\"><img src=\"./Images/Fairscore_tab.png\" alt=\"FAIR scores. \" width=\"1422\" height=\"880\" loading=\"lazy\" /><a target=\"_blank\" href=\"./Images/Fairscore_tab.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 2</strong>:</span> Overall FAIR score</figcaption></figure>\n\n<hr />\n\n<p>Image un peu laide, je l‚Äôa modifierai un peu sur Paint pour optimiser sa taille vis √† vis du vide/blanc occup√© par certaines parties</p>\n<hr />\n\n<blockquote class=\"comment\">\n  <comment-title>How you can improve your FAIR score?</comment-title>\n\n  <p>You can look at the lines of the table for FAILURE (red) and WARNING (yellow) status. Two WARNING \nstatus lines  are related to an abstract content too short and an attribute definition too small.</p>\n\n  <figure id=\"figure-3\" style=\"max-width: 90%;\"><img src=\"./Images/WARNING.png\" alt=\"Warning status lines. \" width=\"1809\" height=\"278\" loading=\"lazy\" /><a target=\"_blank\" href=\"./Images/WARNING.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 3</strong>:</span> Overall FAIR score</figcaption></figure>\n</blockquote>\n\n<blockquote class=\"comment\">\n  <comment-title>Update metadata content to elevate FAIR score</comment-title>\n\n  <ol>\n    <li>\n      <p>Search ‚Äúabstract‚Äù and ‚Äúattributes_Present.Surface.pH.txt‚Äù metadarta files on your history</p>\n    </li>\n    <li>\n      <p>Modify each file using the Galaxy included text editor</p>\n\n      <p>To do so, you can go on the ‚Äúvisualize‚Äù functionnality of each datafile, clicking on the name of the dataset on your history then on the ‚Äúvisualize‚Äù button at the bottom of the dataset description. you can then select ‚ÄúEditor / Manually edit text‚Äù to update the content and generate a new version of the dataset.</p>\n    </li>\n    <li>\n      <p>Rename each datafile as original names (‚Äúabstract‚Äù and ‚Äúattributes_Present.Surface.pH.txt‚Äù), you can add a ‚Äúmodified‚Äù tag / label so you can better remember in the future the modification state.</p>\n    </li>\n    <li>\n      <p>Recreate a data collection with all metadata template files, taking the new ‚Äúabstract‚Äù and ‚Äúattributes_Present.Surface.pH.txt‚Äù files instead of old ones.</p>\n    </li>\n    <li>\n      <p>You can recreate an EML metadata file with <a href=\"https://ecology.usegalaxy.eu/root?tool_id=toolshed.g2.bx.psu.edu/repos/ecology/makeeml/makeeml/0.1.1+galaxy1\"><strong>Make EML</strong></a> EAL tool and then redeploy a metashrimps tool on the new EML. Before executing <a href=\"https://ecology.usegalaxy.eu/root?tool_id=toolshed.g2.bx.psu.edu/repos/ecology/makeeml/makeeml/0.1.1+galaxy1\"><strong>Make EML</strong></a> EAL tool, one need to pay attention to the rename composite datafiles (as here the shapefile one) as named originally (so <code class=\"language-plaintext highlighter-rouge\">02_Ref</code>) and then create a data collection gathering all ‚ÄúdataTable‚Äù datafiles (both .tsv files and .nc one), a data collection gathering all ‚ÄúspatialRaster‚Äù datafiles (here <code class=\"language-plaintext highlighter-rouge\">Present.Surface.pH.tif</code>) and a data collection gathering all ‚ÄúspatialVector‚Äù datafiles (here <code class=\"language-plaintext highlighter-rouge\">LakeGeneva_phytoplankton_1974-2004.nc</code>).</p>\n    </li>\n  </ol>\n\n</blockquote>\n\n<h1 id=\"7-conclusion\">7] Conclusion</h1>\n\n<p>Here is the end of this short tutorial aiming in explaining the purpose of MetaShARK and how to use it.</p>\n\n<p>Don‚Äôt hesitate to contact us if you have any questions ‚ò∫Ô∏è</p>\n"],"ref_slides":[],"video_library":{"tutorial":null,"slides":null,"demo":null,"both":null,"session":null},"hands_on":true,"slides":false,"mod_date":"2024-03-07 15:47:52 +0000","pub_date":"2024-03-04 15:18:02 +0000","version":45,"api":"https://training.galaxyproject.org/training-material/api/topics/ecology/tutorials/MetaShARK_tutorial/tutorial.json","tools":["interactive_tool_metashark"],"supported_servers":{"exact":[{"url":"https://usegalaxy.eu","name":"UseGalaxy.eu","usegalaxy":true},{"url":"https://usegalaxy.fr/","name":"UseGalaxy.fr","usegalaxy":false}],"inexact":[]},"topic_name_human":"Ecology","admin_install":{"install_tool_dependencies":true,"install_repository_dependencies":true,"install_resolver_dependencies":true,"tools":[]},"admin_install_yaml":"---\ninstall_tool_dependencies: true\ninstall_repository_dependencies: true\ninstall_resolver_dependencies: true\ntools: []\n","tours":false,"video":false,"translations":{"tutorial":[],"slides":[],"video":false},"license":"CC-BY-4.0","type":"tutorial","contributors":[{"name":"Yvan Le Bras","email":"yvan.le-bras@mnhn.fr","twitter":"Yvan2935","matrix":"yvanlebras:matrix.org","orcid":"0000-0002-8504-068X","joined":"2017-09","elixir_node":"fr","affiliations":["pndb","gallantries","fairease","fnso2019","elixir-europe"],"id":"yvanlebras","url":"https://training.galaxyproject.org/training-material/api/contributors/yvanlebras.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/yvanlebras/"},{"name":"Glinez Thibaud","email":"thibaud.glinez@mnhn.fr","orcid":"0009-0006-8655-7505","joined":"2024-02","elixir_node":"fr","affiliations":["pndb","elixir-europe"],"id":"ThibaudGlinez","url":"https://training.galaxyproject.org/training-material/api/contributors/ThibaudGlinez.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/ThibaudGlinez/"},{"name":"Yvan Le Bras","email":"yvan.le-bras@mnhn.fr","twitter":"Yvan2935","matrix":"yvanlebras:matrix.org","orcid":"0000-0002-8504-068X","joined":"2017-09","elixir_node":"fr","affiliations":["pndb","gallantries","fairease","fnso2019","elixir-europe"],"id":"yvanlebras","url":"https://training.galaxyproject.org/training-material/api/contributors/yvanlebras.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/yvanlebras/"},{"name":"Glinez Thibaud","email":"thibaud.glinez@mnhn.fr","orcid":"0009-0006-8655-7505","joined":"2024-02","elixir_node":"fr","affiliations":["pndb","elixir-europe"],"id":"ThibaudGlinez","url":"https://training.galaxyproject.org/training-material/api/contributors/ThibaudGlinez.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/ThibaudGlinez/"},{"name":"Helena Rasche","orcid":"0000-0001-9760-8992","maintainer_contact":"gitter","matrix":"hexylena:matrix.org","joined":"2017-09","elixir_node":"nl","affiliations":["gallantries","by-covid","erasmusmc","elixir-europe","elixir-converge"],"former_affiliations":["deNBI","avans-atgm","uni-freiburg"],"contact_for_training":false,"location":{"country":"NL","lat":51.91,"lon":4.46},"id":"hexylena","url":"https://training.galaxyproject.org/training-material/api/contributors/hexylena.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/"},{"name":"OpenMetaPaper","short_name":"FNSO","joined":"2023-05","avatar":"/training-material/shared/images/fnso.png","github":false,"funder":true,"url":"https://training.galaxyproject.org/training-material/api/funders/fnso2019.json","funder_name":"National Fund for Open Science","funding_id":"AAPFNSO2019OpenMetaPaper-14026","funding_statement":"This project (<a href=\"https://www.ouvrirlascience.fr/submit-your-data-its-published/\"><code class=\"language-plaintext highlighter-rouge\">AAPFNSO2019OpenMetaPaper-14026</code></a>) is funded with the support of the national Fund for Open Science programme of the French Minister of Higher Education, Research and Innovation. Their funding has supported development of data/metadata management tools and related tutorial for Ecology and FAIR topics.\n<img src=\"https://lamy-environnement.com/wp-content/uploads/2023/03/Logo-MESR.png\" alt=\"French research ministry flag with the text: with the support of the National Fund for Open Science programme of french Minister of Higher Education, Research and Innovation\" />\n<img src=\"/training-material/shared/images/fnso.png\" alt=\"FNSO logo\" />","members":["yvanlebras"],"id":"fnso2019","page":"https://training.galaxyproject.org/training-material/hall-of-fame/fnso2019/"},{"name":"P√¥le National de Donn√©es de Biodiversit√©","url":"https://training.galaxyproject.org/training-material/api/organisations/pndb.json","avatar":"/training-material/shared/images/PNDB_sub.png","github":false,"members":["colineroyaux","Marie59","yvanlebras","ThibaudGlinez"],"id":"pndb","page":"https://training.galaxyproject.org/training-material/hall-of-fame/pndb/"}]}