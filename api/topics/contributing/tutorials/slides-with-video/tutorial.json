{"layout":"tutorial_hands_on","title":"Adding auto-generated video to your slides","questions":["How can we add auto-generated video?","How does it work?","What do I need to do to make it optimal for viewers?"],"objectives":["Adding a video to a set of slides"],"time_estimation":"20m","subtopic":"writing","key_points":["Thanks to the GTN, videos are easy to add","Be mindful of your captions. Short sentences are good!"],"contributors":[{"name":"Helena Rasche","orcid":"0000-0001-9760-8992","maintainer_contact":"gitter","matrix":"hexylena:matrix.org","joined":"2017-09","elixir_node":"nl","affiliations":["gallantries","by-covid","erasmusmc","elixir-europe","elixir-converge"],"former_affiliations":["deNBI","avans-atgm","uni-freiburg"],"contact_for_training":false,"location":{"country":"NL","lat":51.91,"lon":4.46},"id":"hexylena","url":"https://training.galaxyproject.org/training-material/api/contributors/hexylena.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/"}],"js_requirements":{"mathjax":null,"mermaid":false},"short_id":"T00071","url":"/topics/contributing/tutorials/slides-with-video/tutorial.html","topic_name":"contributing","tutorial_name":"slides-with-video","dir":"topics/contributing/tutorials/slides-with-video","symlink":null,"id":"contributing/slides-with-video","ref_tutorials":["<h1 id=\"video-lectures\">Video Lectures</h1>\n\n<p>Based on the work by Delphine Larivière and James Taylor with their <a href=\"https://github.com/galaxyproject/video-lectures/\">COVID-19 Lectures</a> we have implemented a similar feature in the Galaxy Training Network.</p>\n\n<blockquote class=\"agenda\">\n  <agenda-title></agenda-title>\n\n  <p>In this tutorial, we will:</p>\n\n<ol id=\"markdown-toc\">\n  <li><a href=\"#video-lectures\" id=\"markdown-toc-video-lectures\">Video Lectures</a>    <ol>\n      <li><a href=\"#how-it-works\" id=\"markdown-toc-how-it-works\">How it Works</a></li>\n    </ol>\n  </li>\n  <li><a href=\"#enabling-video\" id=\"markdown-toc-enabling-video\">Enabling Video</a>    <ol>\n      <li><a href=\"#writing-good-captions\" id=\"markdown-toc-writing-good-captions\">Writing Good Captions</a></li>\n      <li><a href=\"#enable-the-video\" id=\"markdown-toc-enable-the-video\">Enable the Video</a></li>\n    </ol>\n  </li>\n  <li><a href=\"#voices\" id=\"markdown-toc-voices\">Voices</a></li>\n  <li><a href=\"#how-it-works-in-detail\" id=\"markdown-toc-how-it-works-in-detail\">How it works: In Detail</a></li>\n  <li><a href=\"#conclusion\" id=\"markdown-toc-conclusion\">Conclusion</a></li>\n</ol>\n\n</blockquote>\n\n<h2 id=\"how-it-works\">How it Works</h2>\n\n<p>We wrote a short script which does the following:</p>\n\n<p><em>Locally and in production</em>:</p>\n\n<ul>\n  <li>Extracts a ‘script’ from the slides. We extract every presenter comment in the slidedeck, and turn this into a text file.</li>\n  <li>Every line of this text file is then narrated by <a href=\"https://aws.amazon.com/polly/\">Amazon Polly</a> (if you have money) or <a href=\"https://github.com/synesthesiam/docker-mozillatts\">MozillaTTS</a> (free).</li>\n  <li>The slide deck is converted to a PDF, and then each slide is extracted as a PNG.</li>\n  <li>Captions are extracted from the audio components.</li>\n  <li>The narration is stitched together into an mp3</li>\n  <li>The images are stitched together into an mp4 file</li>\n  <li>The video, audio, and captions are muxed together into a final mp4 file</li>\n</ul>\n\n<p><em>In production</em></p>\n\n<ul>\n  <li>We use Amazon Polly, paid for by the Galaxyproject</li>\n  <li>The result is uploaded to an S3 bucket</li>\n</ul>\n\n<h1 id=\"enabling-video\">Enabling Video</h1>\n\n<p>We have attempted to simplify this process as much as possible, but making good slides which work well is up to you.</p>\n\n<h2 id=\"writing-good-captions\">Writing Good Captions</h2>\n\n<p>Every slide must have some narration in the presenter notes. It does not make sense for students to see a slide without commentary. For each slide, you’ll need to write presenter notes in full, but short sentences.</p>\n\n<h3 id=\"sentence-structure\">Sentence Structure</h3>\n\n<p>Use simple and uncomplex sentences whenever possible. Break up ideas into easy to digest bits. Students will be listening to this spoken and possibly reading the captions.</p>\n\n<p><em>2021-05-01</em> There used to be a limit of ~120 characters per sentence, but this is no longer an issue. We now break up sentences which are too long in the captions and show them over multiple timepoints. So if you need to write a really long sentence, you can, but we still advise to simplify sentences where possible.</p>\n\n<h3 id=\"captions-per-slide\">Captions per Slide</h3>\n\n<p>Every slide must have some speaker notes in this system, <strong>NO exceptions</strong>.</p>\n\n<h3 id=\"punctuation\">Punctuation</h3>\n\n<p>Sentences should end with punctuation like <code class=\"language-plaintext highlighter-rouge\">.</code> or <code class=\"language-plaintext highlighter-rouge\">?</code> or even <code class=\"language-plaintext highlighter-rouge\">!</code> if you’re feeling excited.</p>\n\n<h3 id=\"abbreviations\">Abbreviations</h3>\n\n<p>These are generally fine as-is. (e.g. <code class=\"language-plaintext highlighter-rouge\">e.g.</code>/<code class=\"language-plaintext highlighter-rouge\">i.e.</code> is fine as-is, <code class=\"language-plaintext highlighter-rouge\">RNA</code> is fine, etc.) Make sure abbreviations are all caps though.</p>\n\n<blockquote class=\"code-in\">\n  <p><strong>Good</strong>\nThis role deploys CVMFS.</p>\n</blockquote>\n\n<h3 id=\"weird-names\">“Weird” Names</h3>\n\n<p>In the captions you will want to teach the GTN how to pronounce these words by editing <code class=\"language-plaintext highlighter-rouge\">bin/ari-map.yml</code> to provide your definition.</p>\n\n<p>E.g.</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Word</th>\n      <th>Pronunciation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>SQLAlchemy</td>\n      <td>SQL alchemy</td>\n    </tr>\n    <tr>\n      <td>FastQC</td>\n      <td>fast QC</td>\n    </tr>\n    <tr>\n      <td>nginx</td>\n      <td>engine X</td>\n    </tr>\n    <tr>\n      <td>gxadmin</td>\n      <td>GX admin</td>\n    </tr>\n    <tr>\n      <td>/etc</td>\n      <td>/ E T C</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>The same applies to the many terms we read differently from how they are written, e.g. ‘src’ vs ‘source’. Most of us would pronounce it like the latter, even though it isn’t spelt that way. Our speaking robot doesn’t know what we mean, so we need to spell it out properly.</p>\n\n<p>So we write the definition in the <a href=\"https://github.com/galaxyproject/training-material/blob/master/bin/ari-map.yml\"><code class=\"language-plaintext highlighter-rouge\">bin/ari-map.yml</code></a> file.</p>\n\n<h3 id=\"other-considerations\">Other Considerations</h3>\n\n<p>(<em>Written 2020-12-16, things may have changed since.</em>)</p>\n\n<p>Be sure to check the pronunciation of the slides. There are known issues with <a href=\"https://en.wikipedia.org/wiki/Heteronym_(linguistics)\">heteronyms</a>, words spelt the same but having different pronunciation and meaning. Consider “read” for a classic example, or <a href=\"https://en.wiktionary.org/wiki/analyses#English\">“analyses”</a> for one that comes up often in the GTN. “She analyses data” and “Multiple analyses” are pronounced quite differently based on their usage in sentences. See the <a href=\"https://en.wiktionary.org/wiki/analyses#English\">wiktionary</a> page for more information, or the <a href=\"https://en.wiktionary.org/wiki/Category:English_heteronyms\">list of English heteronyms</a> you might want to be aware of.</p>\n\n<p>This becomes an issue for AWS Polly and Mozilla’s TTS which both don’t have sufficient context sometimes to choose between the two pronunciations. You’ll find that “many analyses” is pronounced correctly while “multiple analyses” isn’t.</p>\n\n<p>Oftentimes the services don’t understand part of speech, so by adding adjectives to analyses, you confuse the engine in to thinking it should be the third person singular pronunciation. This is probably because it only has one or two words of context ahead of the word to be pronounced.</p>\n\n<h2 id=\"enable-the-video\">Enable the Video</h2>\n\n<p>Lastly, we need to tell the GTN framework we would like videos to be generated.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Enable video</hands-on-title>\n\n  <ol>\n    <li>Edit the <code class=\"language-plaintext highlighter-rouge\">slides.html</code> for your tutorial</li>\n    <li>Add <code class=\"language-plaintext highlighter-rouge\">video: true</code> to the top</li>\n  </ol>\n</blockquote>\n\n<p>That’s it! With this, videos can be automatically generated.</p>\n\n<h1 id=\"voices\">Voices</h1>\n\n<p>There are multiple voices available, see the following list:</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Name</th>\n      <th>Region</th>\n      <th>Neural</th>\n      <th>Audio Clip</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Amy</td>\n      <td>en-GB</td>\n      <td>True</td>\n      <td><audio controls=\"\" src=\"/training-material/assets/audio/amy.mp3\"></audio></td>\n    </tr>\n    <tr>\n      <td>Aria</td>\n      <td>en-NZ</td>\n      <td>True</td>\n      <td><audio controls=\"\" src=\"/training-material/assets/audio/aria.mp3\"></audio></td>\n    </tr>\n    <tr>\n      <td>Brian</td>\n      <td>en-GB</td>\n      <td>True</td>\n      <td><audio controls=\"\" src=\"/training-material/assets/audio/brian.mp3\"></audio></td>\n    </tr>\n    <tr>\n      <td>Emma</td>\n      <td>en-GB</td>\n      <td>True</td>\n      <td><audio controls=\"\" src=\"/training-material/assets/audio/emma.mp3\"></audio></td>\n    </tr>\n    <tr>\n      <td>Joanna</td>\n      <td>en-US</td>\n      <td>True</td>\n      <td><audio controls=\"\" src=\"/training-material/assets/audio/joanna.mp3\"></audio></td>\n    </tr>\n    <tr>\n      <td>Joey</td>\n      <td>en-US</td>\n      <td>True</td>\n      <td><audio controls=\"\" src=\"/training-material/assets/audio/joey.mp3\"></audio></td>\n    </tr>\n    <tr>\n      <td>Kendra</td>\n      <td>en-US</td>\n      <td>True</td>\n      <td><audio controls=\"\" src=\"/training-material/assets/audio/kendra.mp3\"></audio></td>\n    </tr>\n    <tr>\n      <td>Matthew</td>\n      <td>en-US</td>\n      <td>True</td>\n      <td><audio controls=\"\" src=\"/training-material/assets/audio/matthew.mp3\"></audio></td>\n    </tr>\n    <tr>\n      <td>Nicole</td>\n      <td>en-AU</td>\n      <td>False</td>\n      <td><audio controls=\"\" src=\"/training-material/assets/audio/nicole.mp3\"></audio></td>\n    </tr>\n    <tr>\n      <td>Olivia</td>\n      <td>en-AU</td>\n      <td>True</td>\n      <td><audio controls=\"\" src=\"/training-material/assets/audio/olivia.mp3\"></audio></td>\n    </tr>\n    <tr>\n      <td>Raveena</td>\n      <td>en-IN</td>\n      <td>False</td>\n      <td><audio controls=\"\" src=\"/training-material/assets/audio/raveena.mp3\"></audio></td>\n    </tr>\n    <tr>\n      <td>Salli</td>\n      <td>en-US</td>\n      <td>True</td>\n      <td><audio controls=\"\" src=\"/training-material/assets/audio/salli.mp3\"></audio></td>\n    </tr>\n    <tr>\n      <td>Ayanda</td>\n      <td>en-ZA</td>\n      <td>True</td>\n      <td><audio controls=\"\" src=\"/training-material/assets/audio/ayanda.mp3\"></audio></td>\n    </tr>\n    <tr>\n      <td>Geraint</td>\n      <td>en-GB-WLS</td>\n      <td>True</td>\n      <td><audio controls=\"\" src=\"/training-material/assets/audio/geraint.mp3\"></audio></td>\n    </tr>\n  </tbody>\n</table>\n\n<p>By default a random voice is chosen every time the video is rebuilt (only\nwhenever a change is made to that slide deck.) We do this to ensure a good\ndiversity of genders and nationalities in the audio samples.</p>\n\n<p>However, if you have a preferred voice, you can set that permanently for that\nvideo, add the following metadata to the top of your slide deck:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>voice:\n  id: Lupe\n  lang: es-US\n  neural: true\n</code></pre></div></div>\n\n<p>The above voice example is specific to Spanish language content, hence not being represented in the first list.</p>\n\n<h1 id=\"how-it-works-in-detail\">How it works: In Detail</h1>\n\n<ol>\n  <li>We take our markdown slides, e.g. <a href=\"https://github.com/galaxyproject/training-material/blob/main/topics/introduction/tutorials/galaxy-intro-short/slides.html\"><code class=\"language-plaintext highlighter-rouge\">topics/introduction/tutorials/galaxy-intro-short/slides.html</code></a></li>\n  <li>In order for them to be processed, slides must have an annotation saying <code class=\"language-plaintext highlighter-rouge\">video: true</code> in the header metadata, and then ‘speaker notes’ (everything after the ??? before the —)</li>\n  <li>This is turned into our ‘plain text slides’ which just renders the markdown a bit more nicely (<a href=\"/training-material/topics/introduction/tutorials/galaxy-intro-short/slides-plain.html\">example</a>)</li>\n  <li>\n    <p>Then we run ari.sh which does the following:</p>\n\n    <ul>\n      <li><code class=\"language-plaintext highlighter-rouge\">make video</code> is run which runs <a href=\"https://github.com/galaxyproject/training-material/blob/main/bin/ari-make.sh\"><code class=\"language-plaintext highlighter-rouge\">bin/ari-make.sh</code></a></li>\n      <li>This builds PDFs for any slides which have changed</li>\n      <li>And runs <code class=\"language-plaintext highlighter-rouge\">./bin/ari.sh</code> with the PDF, the original Slides, and where the mp4 should be saved.\n        <ul>\n          <li>In <a href=\"https://github.com/galaxyproject/training-material/blob/main/bin/ari.sh\"><code class=\"language-plaintext highlighter-rouge\">./bin/ari.sh</code></a></li>\n          <li>It <a href=\"https://github.com/galaxyproject/training-material/blob/main/bin/ari.sh#L38\">extracts metadata</a> from the tutorial (title, authors, etc.)</li>\n          <li>It <a href=\"https://github.com/galaxyproject/training-material/blob/main/bin/ari.sh#L51\">builds a ‘script’</a>, a json document with blocks for every line of the speaker notes that were in the slides.</li>\n          <li><a href=\"https://github.com/galaxyproject/training-material/blob/main/bin/ari.sh#L55\">Those get converted into mp3 files</a> by AWS Polly (or MozillaTTS), one per slide.</li>\n          <li>The PDFs get turned into <a href=\"https://github.com/galaxyproject/training-material/blob/main/bin/ari.sh#L60\">a series of PNG images</a></li>\n          <li>We take the timings of the mp3 files together with the json ‘script’ to <a href=\"https://github.com/galaxyproject/training-material/blob/main/bin/ari.sh#L69\">write out webvtt / srt subtitles</a> which get embedded into the video, and supplied next to it.</li>\n          <li><a href=\"https://github.com/mifi/editly\">editly is used</a> to knit together the PNGs + mp3s with appropriate delay</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ol>\n\n<p>All of this is run on cron by <a href=\"https://github.com/galaxyproject/training-material/blob/main/.github/workflows/video.yml\"><code class=\"language-plaintext highlighter-rouge\">.github/workflows/video.yml</code></a> which handles building all of these videos and then later uploading them to s3.</p>\n\n<p>Many of the scripts internally are prefixed with <code class=\"language-plaintext highlighter-rouge\">ari</code>, we named our internal version after <a href=\"https://github.com/jhudsl/ari/\">github.com/jhudsl/ari/</a> which inspired it, but we wanted a version that would be more closely tied to the GTN and integrate with our infrastructure nicely, so we ended up writing our own.</p>\n\n<h1 id=\"conclusion\">Conclusion</h1>\n"],"ref_slides":[],"hands_on":true,"slides":false,"mod_date":"2023-11-09 16:40:43 +0000","pub_date":"2020-10-20 11:32:49 +0000","version":19,"api":"https://training.galaxyproject.org/training-material/api/topics/contributing/tutorials/slides-with-video/tutorial.json","tools":[],"supported_servers":[],"topic_name_human":"Contributing to the Galaxy Training Material","admin_install":{"install_tool_dependencies":true,"install_repository_dependencies":true,"install_resolver_dependencies":true,"tools":[]},"admin_install_yaml":"---\ninstall_tool_dependencies: true\ninstall_repository_dependencies: true\ninstall_resolver_dependencies: true\ntools: []\n","tours":false,"video":false,"slides_recordings":false,"translations":{"tutorial":[],"slides":[],"video":false},"license":"CC-BY-4.0","type":"tutorial"}