{"layout":"tutorial_hands_on","title":"Classification in Machine Learning","zenodo_link":"https://zenodo.org/record/3738729","questions":["What is classification and how we can use classification techniques?"],"objectives":["Learn classification background","Learn what a quantitative structure-analysis relationship (QSAR) model is and how it can be constructed in Galaxy","Learn to apply logistic regression, k-nearest neighbors, support verctor machines, random forests and bagging algorithms","Learn how visualizations can be used to analyze the classification results"],"key_points":["Classification is a supervised approach in machine learning.","For classification tasks, data is divided into training and test sets.","Using classification, the samples are learned using the training set and predicted using the test set.","For each classification algorithm, it parameters should be optimised based on the dataset.","Machine learning algorithms can be applied to chemical datasets to predict important properties."],"time_estimation":"2H","contributors":[{"name":"Alireza Khanteymoori","email":"khanteymoori@gmail.com","orcid":"0000-0001-6811-9196","joined":"2019-07","former_affiliations":["uni-freiburg","elixir-europe"],"id":"khanteymoori","url":"https://training.galaxyproject.org/training-material/api/contributors/khanteymoori.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/khanteymoori/"},{"name":"Anup Kumar","email":"anup.rulez@gmail.com","twitter":"musafirtweetsz","joined":"2018-08","elixir_node":"de","affiliations":["uni-freiburg","eurosciencegateway","elixir-europe"],"id":"anuprulez","url":"https://training.galaxyproject.org/training-material/api/contributors/anuprulez.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/"},{"name":"Simon Bray","joined":"2019-05","elixir_node":"de","former_affiliations":["uni-freiburg","elixir-europe"],"id":"simonbray","url":"https://training.galaxyproject.org/training-material/api/contributors/simonbray.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/simonbray/"}],"recordings":[{"captioners":["anuprulez"],"date":"2021-02-15","galaxy_version":"21.01","length":"1H50M","youtube_id":"Gz2OdRPS2Nk","speakers":["anuprulez"]}],"js_requirements":{"mathjax":null,"mermaid":false},"short_id":"T00262","url":"/topics/statistics/tutorials/classification_machinelearning/tutorial.html","topic_name":"statistics","tutorial_name":"classification_machinelearning","dir":"topics/statistics/tutorials/classification_machinelearning","symlink":null,"id":"statistics/classification_machinelearning","ref_tutorials":["<p>In this tutorial you will learn how to apply Galaxy tools to solve <a href=\"https://en.wikipedia.org/wiki/Statistical_classification\">classification</a> problems. First, we will introduce classification briefly, and then examine logistic regression, which is an example of a linear classifier. Next, we will discuss the nearest neighbor classifier, which is a simple but nonlinear classifier. Then advanced classifiers, such as support vector machines, random forest and ensemble classifiers will be introduced and applied. Furthermore, we will show how to visualize the results in each step.</p>\n\n<p>Finally, we will discuss how to train the classifiers by finding the values of their parameters that minimize a cost function. We will work through a real problem in the field of cheminformatics to learn how the classifiers and learning algorithms work.</p>\n\n<p>Classification is a <a href=\"https://en.wikipedia.org/wiki/Supervised_learning\">supervised learning</a> method in machine learning and the algorithm which is used for this learning task is called a classifier. In this tutorial we will build a classifier which can predict whether a chemical substance is biodegradable or not. Substances which degrade quickly are preferable to those which degrade slowly, as they do not accumulate and pose a risk to the environment. Therefore, it is useful to be able to predict easily in advance whether a substance is biodegradable prior to production and usage in consumer products.</p>\n\n<blockquote class=\"agenda\">\n  <agenda-title></agenda-title>\n\n  <p>In this tutorial, we will cover:</p>\n\n<ol id=\"markdown-toc\">\n  <li><a href=\"#classification\" id=\"markdown-toc-classification\">Classification</a></li>\n  <li><a href=\"#quantitative-structure---activity-relationship-biodegradation\" id=\"markdown-toc-quantitative-structure---activity-relationship-biodegradation\">Quantitative structure - activity relationship biodegradation</a>    <ol>\n      <li><a href=\"#get-train-and-test-datasets\" id=\"markdown-toc-get-train-and-test-datasets\">Get train and test datasets</a></li>\n    </ol>\n  </li>\n  <li><a href=\"#learn-the-logistic-regression-classifier\" id=\"markdown-toc-learn-the-logistic-regression-classifier\">Learn the logistic regression classifier</a>    <ol>\n      <li><a href=\"#predict-class-using-test-dataset\" id=\"markdown-toc-predict-class-using-test-dataset\">Predict class using test dataset</a></li>\n      <li><a href=\"#visualize-the-logistic-regression-classification-results\" id=\"markdown-toc-visualize-the-logistic-regression-classification-results\">Visualize the logistic regression classification results</a></li>\n    </ol>\n  </li>\n  <li><a href=\"#k-nearest-neighbor-knn\" id=\"markdown-toc-k-nearest-neighbor-knn\">K-Nearest Neighbor (KNN)</a></li>\n  <li><a href=\"#support-vector-machines-svm\" id=\"markdown-toc-support-vector-machines-svm\">Support Vector Machines (SVM)</a></li>\n  <li><a href=\"#random-forest\" id=\"markdown-toc-random-forest\">Random Forest</a></li>\n  <li><a href=\"#create-data-processing-pipeline\" id=\"markdown-toc-create-data-processing-pipeline\">Create data processing pipeline</a>    <ol>\n      <li><a href=\"#search-for-the-best-values-of-hyperparameters\" id=\"markdown-toc-search-for-the-best-values-of-hyperparameters\">Search for the best values of hyperparameters</a></li>\n    </ol>\n  </li>\n  <li><a href=\"#conclusion\" id=\"markdown-toc-conclusion\">Conclusion</a></li>\n</ol>\n\n</blockquote>\n\n<h1 id=\"classification\">Classification</h1>\n\n<p>Classification is the process of assigning every object from a collection to exactly one class from a known set of classes by learning a “decision boundary” in a dataset. This dataset is called a training dataset and contains multiple samples, together with a desired class for each sample. The training dataset contains “features” as columns and a mapping between these features and the class label is learned for each sample.</p>\n\n<p>The performance of mapping is evaluated using a test dataset, which is separate from the training dataset. The test dataset contains only the feature columns, but not the class column. The class column is predicted using the mapping learned on the training dataset. An example of a classification task is assigning a patient (the object) to a group of healthy or ill (the classes) people on the basis of his or her medical record. In this tutorial, we will use a classifier to train a model using a training dataset, predict the targets for test dataset and visualize the results using plots.</p>\n\n<figure id=\"figure-1\" style=\"max-width: 90%;\"><img src=\"images/classification.png\" alt=\"classification. \" width=\"286\" height=\"245\" loading=\"lazy\" /><a target=\"_blank\" href=\"images/classification.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 1</strong>:</span> Classification of samples belonging to different classes.</figcaption></figure>\n\n<p>In figure <a href=\"#figure-1\">1</a>, the line is a boundary which separates a class from another class (for example from tumor to no tumor). The task of a classifier is to learn this boundary, which can be used to classify or categorize an unseen/new sample. The line is the decision boundary; there are different ways to learn it, which correspond to different classification algorithms. If the dataset is linearly separable, linear classifiers can produce good classification results. However, when the dataset is complex and requires non-linear decision boundaries, more powerful classifiers like <code class=\"language-plaintext highlighter-rouge\">support vector machine</code> or <code class=\"language-plaintext highlighter-rouge\">ensemble</code> based classifiers may prove to be beneficial.</p>\n\n<p>The data classification process includes two steps:</p>\n<ol>\n  <li>\n    <p>Building the classifier or model: This step is the learning step, in which the classification algorithms build the classifier. The classifier is built from the training set made up of database samples and their associated class labels. Each sample that constitutes the training set is referred to as a class.</p>\n  </li>\n  <li>\n    <p>Applying the classifier to a classification task: In this step, the classifier is used for classification. Here the test data is used to estimate the accuracy of classification rules. The classification rules can be applied to the new data samples if the accuracy is considered acceptable.</p>\n  </li>\n</ol>\n\n<h1 id=\"quantitative-structure---activity-relationship-biodegradation\">Quantitative structure - activity relationship biodegradation</h1>\n\n<p>The classification problem we will study in this tutorial is related to biodegradation. Chemical substances which decay slowly will accumulate over time, which poses a threat to the environment. Therefore, it is useful to be able to predict in advance whether a substance will break down quickly or not.</p>\n\n<p>Quantitative structure-activity relationship (QSAR) and quantitative structure-property relationship (QSPR) models attempt to predict the activity or property of chemicals based on their chemical structure. To achieve this, a database of compounds is collected for which the property of interest is known. For each compound, molecular descriptors are collected which describe the structure (for example: molecular weight, number of nitrogen atoms, number of carbon-carbon double bonds). Using these descriptors, a model is constructed which is capable of predicting the property of interest for a new, unknown molecule. In this tutorial we will use a database assembled from experimental data of the Japanese Ministry of International Trade and Industry to create a classification model for biodegradation. We then will be able to use this model to classify new molecules into one of two classes: biodegradable or non-biodegradable.</p>\n\n<p>As a benchmark, we will use the <a href=\"https://pubs.acs.org/doi/10.1021/ci4000213\">dataset</a> assembled by Mansouri et al. using data from the National Institute of Technology and Evaluation of Japan. This database contains 1055 molecules, together with precalculated molecular descriptors.</p>\n\n<p>In this tutorial, we will apply a couple of <a href=\"https://scikit-learn.org/stable/\">scikit-learn</a> machine learning tools to the dataset provided by Mansouri et al. to predict whether a molecule is biodegradable or not.\nIn the following part, we will perform classification on the biodegradability dataset using a linear classifier and then will create some plots to analyze the results.</p>\n\n<h2 id=\"get-train-and-test-datasets\">Get train and test datasets</h2>\n\n<p>We have two datasets available; the training dataset contains 837 molecules, while the test dataset contains 218 molecules.</p>\n\n<p>Let’s begin by uploading the necessary datasets.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Data upload</hands-on-title>\n\n  <ol>\n    <li>Create a new history for this tutorial</li>\n    <li>\n      <p>Import the files from <a href=\"https://zenodo.org/record/3738729\">Zenodo</a></p>\n\n      <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>https://zenodo.org/record/3738729/files/train_rows.csv\nhttps://zenodo.org/record/3738729/files/test_rows_labels.csv\nhttps://zenodo.org/record/3738729/files/test_rows.csv\n</code></pre></div>      </div>\n\n      <!--SNIPPET-->\n      <blockquote class=\"tip\">   <div class=\"box-title tip-title\" id=\"tip-importing-via-links\"><button class=\"gtn-boxify-button tip\" type=\"button\" aria-controls=\"tip-importing-via-links\" aria-expanded=\"true\"><i class=\"far fa-lightbulb\" aria-hidden=\"true\"></i> <span>Tip: Importing via links</span><span class=\"fold-unfold fa fa-minus-square\"></span></button></div>   <ul>   <li>Copy the link location</li>   <li>     <p>Click <i class=\"fas fa-upload\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-upload</span> <strong>Upload Data</strong> at the top of the tool panel</p>   </li>   <li>Select <i class=\"fa fa-edit\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-wf-edit</span> <strong>Paste/Fetch Data</strong></li>   <li>     <p>Paste the link(s) into the text field</p>   </li>   <li>     <p>Press <strong>Start</strong></p>   </li>   <li><strong>Close</strong> the window</li> </ul> </blockquote>\n      <p><!--END_SNIPPET--></p>\n    </li>\n    <li>\n      <p>Rename the datasets as <code class=\"language-plaintext highlighter-rouge\">train_rows</code>, <code class=\"language-plaintext highlighter-rouge\">test_rows_labels</code> and <code class=\"language-plaintext highlighter-rouge\">test_rows</code> respectively.</p>\n\n      <!--SNIPPET-->\n      <blockquote class=\"tip\">   <div class=\"box-title tip-title\" id=\"tip-renaming-a-dataset\"><button class=\"gtn-boxify-button tip\" type=\"button\" aria-controls=\"tip-renaming-a-dataset\" aria-expanded=\"true\"><i class=\"far fa-lightbulb\" aria-hidden=\"true\"></i> <span>Tip: Renaming a dataset</span><span class=\"fold-unfold fa fa-minus-square\"></span></button></div>   <ul>   <li>Click on the <i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-pencil</span> <strong>pencil icon</strong> for the dataset to edit its attributes</li>   <li>In the central panel, change the <strong>Name</strong> field</li>   <li>Click the <strong>Save</strong> button</li> </ul> </blockquote>\n      <p><!--END_SNIPPET--></p>\n    </li>\n  </ol>\n\n</blockquote>\n\n<p class=\"comment\">The <code class=\"language-plaintext highlighter-rouge\">train_rows</code> contains a column <code class=\"language-plaintext highlighter-rouge\">Class</code> which is the class label or target. We will evaluate our model on <code class=\"language-plaintext highlighter-rouge\">test_rows</code> and compare the predicted class with the true class value in <code class=\"language-plaintext highlighter-rouge\">test_rows_labels</code></p>\n\n<blockquote class=\"details\">\n  <details-title>Preparing the data for classification</details-title>\n\n  <p>Preparing the data involves these following major tasks:</p>\n  <ol>\n    <li>Data cleaning: involves removing noise and treatment of missing values. The noise is removed by applying noise filtering techniques and the problem of missing values is solved by replacing a missing value with different techniques, for example substitution, mean imputation and regression imputation.</li>\n    <li>Relevance analysis: the database may also have attributes which are irrelevant for classification. Correlation analysis is used to know whether any two given attributes are related - e.g. one of the features and the target variable.</li>\n    <li>Normalization: the data is transformed using normalization. Normalization involves scaling all values for q given attribute in order to make them fall within a small specified range. Normalization is used when in the learning step, neural networks or the methods involving measurements are used.</li>\n  </ol>\n\n</blockquote>\n\n<h1 id=\"learn-the-logistic-regression-classifier\">Learn the logistic regression classifier</h1>\n\n<p>As the first step, to learn the mapping between several features and the classes, we will apply the linear classifier. It learns features from the training dataset and maps all the rows to their respective class. The process of mapping gives a trained model. <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\">Logistic regression</a> is named for the function used at the core of the method, the logistic function, and it is an instance of supervised classification in which we know the correct label of the class for each sample and the algorithm estimate of the true class. We want to learn parameters (weight and bias for the line) that make the estimated class for each training observation as close as possible to the true class label. This requires two components; the first is a metric for how close the current class label is to the true label. Rather than measure similarity, we usually talk about the opposite of this, the distance between the classifier output and the desired output, and we call this distance, the loss function or the cost function.</p>\n\n<p>The second thing we need is an optimization algorithm for iteratively updating the weights so as to minimize this loss function. The standard algorithm for this is gradient descent. So, the dataset is divided into two parts - training and test sets. The training set is used to train a classifier and the test set is used to evaluate the performance of the trained model.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Train logistic regression classifier</hands-on-title>\n\n  <ol>\n    <li><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_generalized_linear/sklearn_generalized_linear/1.0.11.0\" title=\"Generalized linear models for classification and regression tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Generalized linear models for classification and regression</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 1.0.11.0)</span>:\n      <ul>\n        <li><em>“Select a Classification Task”</em>: <code class=\"language-plaintext highlighter-rouge\">Train a model</code>\n          <ul>\n            <li><em>“Select a linear method”</em>: <code class=\"language-plaintext highlighter-rouge\">Logistic Regression</code>\n              <ul>\n                <li><em>“Select input type”</em>: <code class=\"language-plaintext highlighter-rouge\">tabular data</code>\n                  <ul>\n                    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Training samples dataset”</em>: <code class=\"language-plaintext highlighter-rouge\">train_rows</code></li>\n                    <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n                    <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>“Choose how to select data by column”</em>: <code class=\"language-plaintext highlighter-rouge\">All columns EXCLUDING some by column header name(s)</code>\n                      <ul>\n                        <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>“Type header name(s)”</em>: <code class=\"language-plaintext highlighter-rouge\">Class</code></li>\n                      </ul>\n                    </li>\n                    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Dataset containing class labels”</em>: <code class=\"language-plaintext highlighter-rouge\">train_rows</code></li>\n                    <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n                    <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>“Choose how to select data by column”</em>: <code class=\"language-plaintext highlighter-rouge\">Select columns by column header name(s)</code>\n                      <ul>\n                        <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>“Select target column(s)”</em>: <code class=\"language-plaintext highlighter-rouge\">Class</code></li>\n                      </ul>\n                    </li>\n                  </ul>\n                </li>\n              </ul>\n            </li>\n          </ul>\n        </li>\n      </ul>\n    </li>\n    <li>Rename the generated file to <code class=\"language-plaintext highlighter-rouge\">LogisticRegression_model</code></li>\n  </ol>\n</blockquote>\n\n<blockquote class=\"question\">\n  <question-title></question-title>\n\n  <p>What is learned by the logistic regression model?</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <p>In the logistic regressoion model, the coefficients of the logistic regression algorithm have be estimated from our training data. This is done using <a href=\"https://en.wikipedia.org/wiki/Maximum_likelihood_estimation\">maximum-likelihood estimation</a>.</p>\n\n  </blockquote>\n\n</blockquote>\n\n<h2 id=\"predict-class-using-test-dataset\">Predict class using test dataset</h2>\n\n<p>After learning on the training dataset, we should evaluate the performance on the test dataset to know whether the learning algorithm learned a good classifier from the training dataset or not. This classifier is used to predict a new sample and a similar accuracy is expected.</p>\n\n<p>Now, we will predict the class in the test dataset using this classifier in order to see if it has learned important features which can be generalized on a new dataset. The test dataset (<code class=\"language-plaintext highlighter-rouge\">test_rows</code>) contains the same number of features but does not contain the <code class=\"language-plaintext highlighter-rouge\">Class</code> column. This is predicted using the trained classifier.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Predict class using the logistic regression classifier</hands-on-title>\n\n  <ol>\n    <li><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_generalized_linear/sklearn_generalized_linear/1.0.11.0\" title=\"Generalized linear models for classification and regression tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Generalized linear models for classification and regression</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 1.0.11.0)</span>:\n      <ul>\n        <li><em>“Select a Classification Task”</em>: <code class=\"language-plaintext highlighter-rouge\">Load a model and predict</code>\n          <ul>\n            <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Models”</em>: <code class=\"language-plaintext highlighter-rouge\">LogisticRegression_model</code></li>\n            <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Data (tabular)”</em>: <code class=\"language-plaintext highlighter-rouge\">test_rows</code></li>\n            <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n            <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>“Select the type of prediction”</em>: <code class=\"language-plaintext highlighter-rouge\">Predict class labels</code></li>\n          </ul>\n        </li>\n      </ul>\n    </li>\n    <li>Rename the generated file to <code class=\"language-plaintext highlighter-rouge\">LogisticRegression_result</code></li>\n  </ol>\n</blockquote>\n\n<h2 id=\"visualize-the-logistic-regression-classification-results\">Visualize the logistic regression classification results</h2>\n\n<p>We will evaluate the classification by comparing the predicted with the expected classes. In the previous step, we classified the test dataset (<code class=\"language-plaintext highlighter-rouge\">LogisticRegression_result</code>). We have one more dataset (<code class=\"language-plaintext highlighter-rouge\">test_rows_labels</code>) which contains the true class label of the test set. Using the true and predicted class labels in the test set, we will verify the performance by analyzing the plots. As you can see, <code class=\"language-plaintext highlighter-rouge\">LogisticRegression_result</code> has no header, so first we should remove the header from <code class=\"language-plaintext highlighter-rouge\">test_rows_labels</code> to compare.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Remove the header</hands-on-title>\n\n  <ol>\n    <li><strong>Remove beginning</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> with the following parameters:\n      <ul>\n        <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Remove first”</em>: <code class=\"language-plaintext highlighter-rouge\">1</code></li>\n        <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“from”</em>: <code class=\"language-plaintext highlighter-rouge\">test_rows_labels</code></li>\n      </ul>\n    </li>\n    <li>Rename the generated file to <code class=\"language-plaintext highlighter-rouge\">test_rows_labels_noheader</code></li>\n  </ol>\n</blockquote>\n\n<p>Now we visualize and analyze the classification using the “Plot confusion matrix, precision, recall and ROC and AUC curves” tool.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Check and visualize the classification</hands-on-title>\n  <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/bgruening/plotly_ml_performance_plots/plotly_ml_performance_plots/0.3\" title=\"Plot confusion matrix, precision, recall and ROC and AUC curves tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Plot confusion matrix, precision, recall and ROC and AUC curves</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 0.3)</span>:</p>\n  <ul>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Select input data file”</em>: <code class=\"language-plaintext highlighter-rouge\">test_rows_labels_noheader</code></li>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Select predicted data file”</em>: <code class=\"language-plaintext highlighter-rouge\">LogisticRegression_result</code></li>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Select trained model”</em>: <code class=\"language-plaintext highlighter-rouge\">LogisticRegression_model</code></li>\n  </ul>\n</blockquote>\n\n<p>The visualization tool creates the following plots:</p>\n\n<ol>\n  <li>\n    <p><a href=\"https://en.wikipedia.org/wiki/Confusion_matrix\">Confusion matrix</a>: The confusion matrix summarizes the classification performance of a classifier with respect to the test data. It is a two-dimensional matrix; the horizontal axis (x-axis) shows the predicted labels and the vertical axis (y-axis) shows the true labels. Each rectangular box shows a count of samples falling into the four output combinations (true class, predicted class) - (1, 0), (1, 1), (0, 1) and (0, 0). In Figure 2, the confusion matrix of the predictions is a colour-coded heatmap. For a good prediction, the diagonal running from top-left to bottom-right should contain a smaller number of samples, because it shows the counts of incorrectly predicted samples. Hovering over each box in Galaxy shows the true and predicted class labels and the count of samples.</p>\n\n    <figure id=\"figure-2\" style=\"max-width: 90%;\"><img src=\"images/confusion_matrix_linear.png\" alt=\"confusion_matrix. \" width=\"700\" height=\"450\" loading=\"lazy\" /><a target=\"_blank\" href=\"images/confusion_matrix_linear.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 2</strong>:</span> Confusion matrix for the logistic regression classifier.</figcaption></figure>\n  </li>\n  <li>\n    <p><a href=\"https://en.wikipedia.org/wiki/Precision_and_recall\">Precision, recall and F1 score</a>: Precision, recall and F1 score. These scores determine the robustness of classification. It is important to analyze the plot for any classification task to verify the accuracy across different classes which provides more information about the balanced or imbalanced accuracy across multiple classes present in the dataset.</p>\n\n    <figure id=\"figure-3\" style=\"max-width: 90%;\"><img src=\"images/precision_recall_linear.png\" alt=\"prf1_scores. \" width=\"700\" height=\"450\" loading=\"lazy\" /><a target=\"_blank\" href=\"images/precision_recall_linear.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 3</strong>:</span> Precision, recall and F1 score for the logistic regression classifier.</figcaption></figure>\n  </li>\n  <li>\n    <p><a href=\"https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5\">Receiver operator characteristics (ROC) and area under ROC (AUC)</a>: Receiver operator characteristics (ROC) and area under ROC (AUC). The ROC curve is shown in blue. For a good prediction, it should be more towards the top-left of this plot, which results in a high AUC value. For a bad prediction, it is close to the orange line (y = x), resulting in a low AUC value (closer to 0.5). An AUC value of exactly 0.5 means the prediction is doing no better than a random number generator at predicting the classes.</p>\n\n    <figure id=\"figure-4\" style=\"max-width: 90%;\"><img src=\"images/roc_linear.png\" alt=\"roc_scores. \" width=\"700\" height=\"450\" loading=\"lazy\" /><a target=\"_blank\" href=\"images/roc_linear.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 4</strong>:</span> Receiver operator characteristics (ROC) and area under ROC (AUC) for the logistic regression classifier.</figcaption></figure>\n  </li>\n</ol>\n\n<p>These plots are important to visualize the quality of the classifier and the true and predicted classes.</p>\n\n<blockquote class=\"question\">\n  <question-title></question-title>\n\n  <p>Inspect the plots. What can you say about the classification?</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <p>Figures 2,3 and 4 show that the classification is acceptable, but as you will see in the next steps, the results can be improved.</p>\n\n  </blockquote>\n</blockquote>\n\n<h1 id=\"k-nearest-neighbor-knn\">K-Nearest Neighbor (KNN)</h1>\n\n<p>At the second step, we will use k-nearest neighbor classifier. In the <a href=\"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\">k-nearest neighbor</a> classifier, a sample is classified by a majority vote of its neighbors.  The sample is assigned to the class which is most common among its k nearest neighbors.  k is a positive integer and typically it is small. For example, if k = 1, then the sample is simply assigned to the class of that single nearest neighbor. Surprisingly, when the number of data points is large, this classifier is not that bad. Choosing the best value of k is very important. If k is too small, the classifier will be sensitive to noise points and if k is too large, the neighborhood may include points from other classes and causes errors. To select the k that is right for your data, we recommend running the KNN algorithm several times with different values of k and choosing the k that reduces the number of errors the most.</p>\n\n<blockquote class=\"question\">\n  <question-title></question-title>\n\n  <p>What are advantages and disadvantages about this model?</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n    <p>Advantages:</p>\n    <ul>\n      <li>\n        <p>It is a very simple algorithm to understand and interpret.</p>\n      </li>\n      <li>\n        <p>It is very useful for nonlinear data because there is no assumption of linearity in this algorithm.</p>\n      </li>\n      <li>\n        <p>It is a versatile algorithm, as we can use it for classification as well as regression.</p>\n      </li>\n      <li>\n        <p>It has relatively high accuracy, but there are much better supervised learning models than KNN.</p>\n      </li>\n      <li>\n        <p>It works very well in low dimensions for complex decision surfaces.</p>\n      </li>\n    </ul>\n\n    <p>Disadvantages:</p>\n\n    <ul>\n      <li>\n        <p>Classification is slow, because it stores all the training data.</p>\n      </li>\n      <li>\n        <p>High memory storage required as compared to other supervised learning algorithms.</p>\n      </li>\n      <li>\n        <p>Prediction is slow in case of big training samples.</p>\n      </li>\n      <li>\n        <p>It is very sensitive to the scale of data as well as irrelevant features.</p>\n      </li>\n      <li>\n        <p>It suffers a lot from the curse of dimensionality.</p>\n      </li>\n    </ul>\n\n  </blockquote>\n</blockquote>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Train k-nearest neighbor classifier</hands-on-title>\n\n  <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_nn_classifier/sklearn_nn_classifier/1.0.11.0\" title=\"Nearest Neighbors Classification tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Nearest Neighbors Classification</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 1.0.11.0)</span>:</p>\n  <ul>\n    <li><em>“Select a Classification Task”</em>: <code class=\"language-plaintext highlighter-rouge\">Train a model</code>\n      <ul>\n        <li><em>“Classifier type”</em>: <code class=\"language-plaintext highlighter-rouge\">Nearest Neighbors</code>\n          <ul>\n            <li><em>“Select input type”</em>: <code class=\"language-plaintext highlighter-rouge\">tabular data</code>\n              <ul>\n                <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Training samples dataset”</em>: <code class=\"language-plaintext highlighter-rouge\">train_rows</code></li>\n                <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n                <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>“Choose how to select data by column”</em>: <code class=\"language-plaintext highlighter-rouge\">All columns EXCLUDING some by column header name(s)</code>\n                  <ul>\n                    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>“Type header name(s)”</em>: <code class=\"language-plaintext highlighter-rouge\">Class</code></li>\n                  </ul>\n                </li>\n                <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Dataset containing class labels”</em>: <code class=\"language-plaintext highlighter-rouge\">train_rows</code></li>\n                <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n                <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>“Choose how to select data by column”</em>: <code class=\"language-plaintext highlighter-rouge\">Select columns by column header name(s)</code>\n                  <ul>\n                    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>“Select target column(s)”</em>: <code class=\"language-plaintext highlighter-rouge\">Class</code></li>\n                  </ul>\n                </li>\n                <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>“Neighbor selection method”</em>: <code class=\"language-plaintext highlighter-rouge\">k-nearest neighbors</code>\n                  <ol>\n                    <li>Rename the generated file to <code class=\"language-plaintext highlighter-rouge\">NearestNeighbors_model</code></li>\n                  </ol>\n                </li>\n              </ul>\n            </li>\n          </ul>\n        </li>\n      </ul>\n    </li>\n  </ul>\n</blockquote>\n\n<blockquote class=\"question\">\n  <question-title></question-title>\n\n  <p>What is the value of k (number of neighbors) for the model?</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n    <p>As you can see in the Advanced Options, the default value for the number of neighbors is 5, and we used the default value. You can set this parameter based on your problem and data.</p>\n\n  </blockquote>\n</blockquote>\n\n<p>Now, we should evaluate the performance on the test dataset to find out whether the KNN classifier is a good model from the training dataset or not.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Predict class using the k-nearest neighbor classifier</hands-on-title>\n\n  <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_nn_classifier/sklearn_nn_classifier/1.0.11.0\" title=\"Nearest Neighbors Classification tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Nearest Neighbors Classification</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 1.0.11.0)</span>:</p>\n  <ul>\n    <li><em>“Select a Classification Task”</em>: <code class=\"language-plaintext highlighter-rouge\">Load a model and predict</code>\n      <ul>\n        <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Models”</em>: <code class=\"language-plaintext highlighter-rouge\">NearestNeighbors_model</code></li>\n        <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Data (tabular)”</em>: <code class=\"language-plaintext highlighter-rouge\">test_rows</code></li>\n        <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n        <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>“Select the type of prediction”</em>: <code class=\"language-plaintext highlighter-rouge\">Predict class labels</code>\n      2. Rename the generated file to <code class=\"language-plaintext highlighter-rouge\">NearestNeighbors_result</code></li>\n      </ul>\n    </li>\n  </ul>\n</blockquote>\n\n<p>Now we visualize and analyze the classification. As you can see, <code class=\"language-plaintext highlighter-rouge\">NearestNeighbors_result</code> has a header, so use <code class=\"language-plaintext highlighter-rouge\">test_rows_labels</code> to compare.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Check and visualize the classification</hands-on-title>\n  <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/bgruening/plotly_ml_performance_plots/plotly_ml_performance_plots/0.3\" title=\"Plot confusion matrix, precision, recall and ROC and AUC curves tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Plot confusion matrix, precision, recall and ROC and AUC curves</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 0.3)</span>:</p>\n  <ul>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Select input data file”</em>: <code class=\"language-plaintext highlighter-rouge\">test_rows_labels</code></li>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Select predicted data file”</em>: <code class=\"language-plaintext highlighter-rouge\">NearestNeighbors_result</code></li>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Select trained model”</em>: <code class=\"language-plaintext highlighter-rouge\">NearestNeighbors_model</code></li>\n  </ul>\n</blockquote>\n\n<p>The visualization tool creates diagrams for the Confusion matrix, Precision, recall and F1 score, Receiver operator characteristics (ROC) and area under ROC (AUC) as follows:</p>\n\n<figure id=\"figure-5\" style=\"max-width: 90%;\"><img src=\"images/confusion_matrix_NN.png\" alt=\"confusion_matrix. \" width=\"700\" height=\"450\" loading=\"lazy\" /><a target=\"_blank\" href=\"images/confusion_matrix_NN.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 5</strong>:</span> Confusion matrix for the k-nearest neighbor classifier.</figcaption></figure>\n\n<figure id=\"figure-6\" style=\"max-width: 90%;\"><img src=\"images/precision_recall_NN.png\" alt=\"prf1_scores. \" width=\"700\" height=\"450\" loading=\"lazy\" /><a target=\"_blank\" href=\"images/precision_recall_NN.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 6</strong>:</span> Precision, recall and F1 score for the k-nearest neighbor classifier.</figcaption></figure>\n\n<figure id=\"figure-7\" style=\"max-width: 90%;\"><img src=\"images/roc_NN.png\" alt=\"roc_scores. \" width=\"700\" height=\"450\" loading=\"lazy\" /><a target=\"_blank\" href=\"images/roc_NN.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 7</strong>:</span> Receiver operator characteristics (ROC) and area under ROC (AUC) for the k-nearest neighbor classifier.</figcaption></figure>\n\n<h1 id=\"support-vector-machines-svm\">Support Vector Machines (SVM)</h1>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Support-vector_machine\">Support Vector Machines</a> (SVMs) have been extensively researched in the machine learning community for the last decade and actively applied to applications in various domains such as bioinformatics. SVM is a generalization of a classifier called maximal margin classifier and is introduced as a binary classifier intended to separate two classes when obtaining the optimal hyperplane and decision boundary. SVMs are based on the assumption that the input data can be linearly separable in a geometric space. The maximal margin classifier is simple, but it cannot be applied to the majority of datasets, since the classes must be separated by a linear boundary and this is often not the case when working with real world data. That is why the support vector classifier was introduced as an extension of the maximal margin classifier, which can be applied in a broader range of cases.</p>\n\n<p>To solve this problem, SVM uses kernel functions to map the input to a high dimension feature space, i.e hyperplane, where a linear decision boundary is constructed in such a manner that the boundary maximises the margin between two classes. The kernel approach is simply an efficient computational approach for accommodating a non-linear boundary between classes.</p>\n\n<p>Without going into technical details, a kernel is a function that quantifies the similarity of two observations. Two special properties of SVMs are that SVMs achieve (1) high generalization by maximizing the margin and (2) support an efficient learning of nonlinear functions by\nkernel trick. In the next step, we will build a SVM classifier with our data.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Train a SVM classifier</hands-on-title>\n\n  <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.11.0\" title=\"Support vector machines (SVMs) tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Support vector machines (SVMs)</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 1.0.11.0)</span>:</p>\n  <ul>\n    <li><em>“Select a Classification Task”</em>: <code class=\"language-plaintext highlighter-rouge\">Train a model</code>\n      <ul>\n        <li><em>“Select a linear method”</em>: <code class=\"language-plaintext highlighter-rouge\">Linear Support Vector Classification</code>\n          <ul>\n            <li><em>“Select input type”</em>: <code class=\"language-plaintext highlighter-rouge\">tabular data</code>\n              <ul>\n                <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Training samples dataset”</em>: <code class=\"language-plaintext highlighter-rouge\">train_rows</code></li>\n                <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n                <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>“Choose how to select data by column”</em>: <code class=\"language-plaintext highlighter-rouge\">All columns EXCLUDING some by column header name(s)</code>\n                  <ul>\n                    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>“Type header name(s)”</em>: <code class=\"language-plaintext highlighter-rouge\">Class</code></li>\n                  </ul>\n                </li>\n                <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Dataset containing class labels”</em>: <code class=\"language-plaintext highlighter-rouge\">train_rows</code></li>\n                <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n                <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>“Choose how to select data by column”</em>: <code class=\"language-plaintext highlighter-rouge\">Select columns by column header name(s)</code>\n                  <ul>\n                    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>“Select target column(s)”</em>: <code class=\"language-plaintext highlighter-rouge\">Class</code>\n                      <ol>\n                        <li>Rename the generated file to <code class=\"language-plaintext highlighter-rouge\">SVM_model</code></li>\n                      </ol>\n                    </li>\n                  </ul>\n                </li>\n              </ul>\n            </li>\n          </ul>\n        </li>\n      </ul>\n    </li>\n  </ul>\n</blockquote>\n\n<blockquote class=\"question\">\n  <question-title></question-title>\n\n  <p>What is learned by the support vector machines?</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <p>The coefficients of the line with the maximal margin in the kernel space is learned in the training phase.</p>\n\n  </blockquote>\n\n</blockquote>\n\n<p>Now we will evaluate the performance of the SVM classifier:</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Predict class SVM classifier</hands-on-title>\n\n  <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.11.0\" title=\"Support vector machines (SVMs) tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Support vector machines (SVMs)</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 1.0.11.0)</span>:</p>\n  <ul>\n    <li><em>“Select a Classification Task”</em>: <code class=\"language-plaintext highlighter-rouge\">Load a model and predict</code>\n      <ul>\n        <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Models”</em>: <code class=\"language-plaintext highlighter-rouge\">SVM_model</code></li>\n        <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Data (tabular)”</em>: <code class=\"language-plaintext highlighter-rouge\">test_rows</code></li>\n        <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n        <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>“Select the type of prediction”</em>: <code class=\"language-plaintext highlighter-rouge\">Predict class labels</code>\n      2. Rename the generated file to <code class=\"language-plaintext highlighter-rouge\">SVM_result</code></li>\n      </ul>\n    </li>\n  </ul>\n</blockquote>\n\n<p>Now let’s visualize the results:</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Check and visualize the classification</hands-on-title>\n  <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/bgruening/plotly_ml_performance_plots/plotly_ml_performance_plots/0.3\" title=\"Plot confusion matrix, precision, recall and ROC and AUC curves tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Plot confusion matrix, precision, recall and ROC and AUC curves</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 0.3)</span>:</p>\n  <ul>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Select input data file”</em>: <code class=\"language-plaintext highlighter-rouge\">test_rows_labels</code></li>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Select predicted data file”</em>: <code class=\"language-plaintext highlighter-rouge\">SVM_result</code></li>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Select trained model”</em>: <code class=\"language-plaintext highlighter-rouge\">SVM_model</code></li>\n  </ul>\n</blockquote>\n\n<p>The visualization tool creates the following ROC plot:</p>\n\n<figure id=\"figure-8\" style=\"max-width: 90%;\"><img src=\"images/roc_svm.png\" alt=\"roc_scores. \" width=\"700\" height=\"450\" loading=\"lazy\" /><a target=\"_blank\" href=\"images/roc_svm.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 8</strong>:</span> Receiver operator characteristics (ROC) and area under ROC (AUC) for the SVM classifier.</figcaption></figure>\n\n<h1 id=\"random-forest\">Random Forest</h1>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Random_forest\">Random forest</a> is an ensemble of decision trees, and usually trained with the “bagging” method. The <a href=\"https://scikit-learn.org/stable/modules/ensemble.html#ensemble\">Ensemble</a> method uses multiple learning models internally for better predictions and the general idea of the bagging method is that a combination of learning models increases the overall result. It uses multiple decision tree regressors internally and predicts by taking the collective performances of the predictions by multiple decision trees. It has a good predictive power and is robust to outliers. It creates an ensemble of weak learners (decision trees) and iteratively minimizes error.</p>\n\n<p>One big advantage of random forest is that it can be used for both classification and regression problems. The main idea behind the random forest is adding additional randomness to the model, while growing the trees and instead of searching for the most important feature while splitting a node, it searches for the best feature among a random subset of features. This results in a better model because of wide diversity. Generally, the more trees in the forest, the more robust the model. Therefore, when using the random forest classifier, a larger number of trees in the forest gives higher accuracy results. Similarly there are two stages in the random forest algorithm: one is random forest creation, the other is to make a prediction from the random forest classifier created in the first stage.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Train random forest</hands-on-title>\n\n  <ol>\n    <li><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_ensemble/sklearn_ensemble/1.0.11.0\" title=\"Ensemble methods for classification and regression tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Ensemble methods for classification and regression</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 1.0.11.0)</span>:\n      <ul>\n        <li><em>“Select a Classification Task”</em>: <code class=\"language-plaintext highlighter-rouge\">Train a model</code>\n          <ul>\n            <li><em>“Select an ensemble method”</em>: <code class=\"language-plaintext highlighter-rouge\">Random forest classifier</code>\n              <ul>\n                <li><em>“Select input type”</em>: <code class=\"language-plaintext highlighter-rouge\">tabular data</code>\n                  <ul>\n                    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Training samples dataset”</em>: <code class=\"language-plaintext highlighter-rouge\">train_rows</code></li>\n                    <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n                    <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>“Choose how to select data by column”</em>: <code class=\"language-plaintext highlighter-rouge\">All columns EXCLUDING some by column header name(s)</code>\n                      <ul>\n                        <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>“Type header name(s)”</em>: <code class=\"language-plaintext highlighter-rouge\">Class</code></li>\n                      </ul>\n                    </li>\n                    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Dataset containing class labels”</em>: <code class=\"language-plaintext highlighter-rouge\">train_rows</code></li>\n                    <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n                    <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>“Choose how to select data by column”</em>: <code class=\"language-plaintext highlighter-rouge\">Select columns by column header name(s)</code>\n                      <ul>\n                        <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>“Select target column(s)”</em>: <code class=\"language-plaintext highlighter-rouge\">Class</code></li>\n                      </ul>\n                    </li>\n                  </ul>\n                </li>\n              </ul>\n            </li>\n          </ul>\n        </li>\n      </ul>\n    </li>\n    <li>Rename the generated file to <code class=\"language-plaintext highlighter-rouge\">RandomForest_model</code></li>\n  </ol>\n</blockquote>\n\n<blockquote class=\"question\">\n  <question-title></question-title>\n\n  <p>What are the advantages of random forest classifier compared with KNN and SVM?</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n    <ol>\n      <li>The overfitting problem will never arise when we use the random forest algorithm in any classification problem.</li>\n      <li>The same random forest algorithm can be used for both classification and regression task.</li>\n      <li>The random forest algorithm can be used for feature engineering, which means identifying the most important features out of the available features from the training dataset.</li>\n    </ol>\n  </blockquote>\n\n</blockquote>\n\n<p>After learning on the training dataset, we should evaluate the performance on the test dataset.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Predict targets using the random forest</hands-on-title>\n\n  <ol>\n    <li><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_ensemble/sklearn_ensemble/1.0.11.0\" title=\"Ensemble methods for classification and regression tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Ensemble methods for classification and regression</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 1.0.11.0)</span>:\n      <ul>\n        <li><em>“Select a Classification Task”</em>: <code class=\"language-plaintext highlighter-rouge\">Load a model and predict</code>\n          <ul>\n            <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Models”</em>: <code class=\"language-plaintext highlighter-rouge\">RandomForest_model</code></li>\n            <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>“Data (tabular)”</em>: <code class=\"language-plaintext highlighter-rouge\">test_rows</code></li>\n            <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n            <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>“Select the type of prediction”</em>: <code class=\"language-plaintext highlighter-rouge\">Predict class labels</code></li>\n          </ul>\n        </li>\n      </ul>\n    </li>\n    <li>Rename the generated file to <code class=\"language-plaintext highlighter-rouge\">RandomForest_result</code></li>\n  </ol>\n</blockquote>\n\n<p>The visualization tool creates the following ROC plot:</p>\n\n<figure id=\"figure-9\" style=\"max-width: 90%;\"><img src=\"images/roc_rf.png\" alt=\"roc_scores. \" width=\"700\" height=\"450\" loading=\"lazy\" /><a target=\"_blank\" href=\"images/roc_rf.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 9</strong>:</span> Receiver operator characteristics (ROC) and area under ROC (AUC) for the random forest classifier.</figcaption></figure>\n\n<blockquote class=\"question\">\n  <question-title></question-title>\n\n  <p>Inspect the plots. What can you say about the classification?</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <p>Figures show that we achieved an AUC score of <code class=\"language-plaintext highlighter-rouge\">1.0</code>  for the test set using random forest. It means the prediction is very good, in fact it has no error at all. Unfortunately, this is not usually the case when dealing with chemical data.</p>\n  </blockquote>\n</blockquote>\n\n<h1 id=\"create-data-processing-pipeline\">Create data processing pipeline</h1>\n\n<p>At the last step, we will create a bagging classifier by using  the <strong>Pipeline builder</strong> tool. Bagging or Bootstrap Aggregating is a widely used ensemble learning algorithm in machine learning. The bagging algorithm creates multiple models from randomly taken subsets of the training dataset and then aggregates learners to build overall stronger classifiers that combine the predictions to produce a final prediction. The <strong>Pipeline builder</strong> tool builds the classifier and returns a <code class=\"language-plaintext highlighter-rouge\">h5mlm</code> file. This tool creates another file which is tabular and contains a list of all the different hyperparameters of the preprocessors and estimators. This tabular file will be used in the <strong>Hyperparameter search</strong> tool to populate the list of hyperparameters with their respective (default) values.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Create pipeline</hands-on-title>\n\n  <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_build_pipeline/sklearn_build_pipeline/1.0.11.0\" title=\"Pipeline builder tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Pipeline builder</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 1.0.11.0)</span>:</p>\n  <ul>\n    <li>In <em>“Final Estimator”</em>:\n      <ul>\n        <li><em>“Choose the module that contains target estimator”</em>: <code class=\"language-plaintext highlighter-rouge\">sklearn.ensemble</code>\n          <ul>\n            <li><em>“Choose estimator class”</em>: <code class=\"language-plaintext highlighter-rouge\">BaggingClassifier</code>\nWe choose <code class=\"language-plaintext highlighter-rouge\">Final Estimator</code> as we have only the estimator and no preprocessor and need the parameters of only the estimator.</li>\n          </ul>\n        </li>\n      </ul>\n    </li>\n  </ul>\n\n</blockquote>\n\n<h2 id=\"search-for-the-best-values-of-hyperparameters\">Search for the best values of hyperparameters</h2>\n\n<p>After extracting the parameter names from the <strong>Pipeline builder</strong> file, we will use the <strong>Hyperparameter search</strong> tool to find the best values for each hyperparameter. These values will lead us to create the best model based on the search space chosen for each hyperparameter. We use only one parameter <code class=\"language-plaintext highlighter-rouge\">n_estimators</code> of <code class=\"language-plaintext highlighter-rouge\">BaggingClassifier</code> for this task. This parameter specifies the number of bagging stages the learning process has to go through. The default value of <code class=\"language-plaintext highlighter-rouge\">n_estimators</code> for this regressor is <code class=\"language-plaintext highlighter-rouge\">10</code>. However, we are not sure if this gives the best accuracy. Therefore, it is important to set this parameter to different values to find the optimal one. We choose a value which is less than <code class=\"language-plaintext highlighter-rouge\">10</code> and a few which are more than <code class=\"language-plaintext highlighter-rouge\">10</code>. The hyperparameter search will look for the optimal number of estimators and gives the best-trained model as one of the outputs. This model is used in the next step to classify the test dataset.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Hyperparameter search</hands-on-title>\n\n  <p><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_searchcv/sklearn_searchcv/1.0.11.0\" title=\"Hyperparameter search tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Hyperparameter search</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 1.0.11.0)</span>:</p>\n  <ul>\n    <li><em>“Select a model selection search scheme”</em>: <code class=\"language-plaintext highlighter-rouge\">GridSearchCV - Exhaustive search over specified parameter values for an estimator </code>\n      <ul>\n        <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Choose the dataset containing pipeline/estimator object”</em>: <code class=\"language-plaintext highlighter-rouge\">h5mlm</code> file (output of <strong>Pipeline builder</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span>)</li>\n        <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Is the estimator a deep learning model?”</em>: <code class=\"language-plaintext highlighter-rouge\">NO</code> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span>)</li>\n        <li>In <em>“Search parameters Builder”</em>:\n          <ul>\n            <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Choose the dataset containing parameter names”</em>: <code class=\"language-plaintext highlighter-rouge\">tabular</code> file (output of <strong>Estimator attributes</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span>)</li>\n            <li>In <em>“Parameter settings for search”</em>:\n              <ul>\n                <li><i class=\"far fa-plus-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-repeat</span> <em>“1: Parameter settings for search”</em>\n                  <ul>\n                    <li><em>“Choose a parameter name (with current value)”</em>: <code class=\"language-plaintext highlighter-rouge\">n_estimators: 10</code></li>\n                    <li><em>“Search list”</em>: <code class=\"language-plaintext highlighter-rouge\">[5,10,20,50]</code></li>\n                  </ul>\n                </li>\n              </ul>\n            </li>\n          </ul>\n        </li>\n      </ul>\n    </li>\n    <li><em>“Select input type”</em>: <code class=\"language-plaintext highlighter-rouge\">tabular data</code>\n      <ul>\n        <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Training samples dataset”</em>: <code class=\"language-plaintext highlighter-rouge\">train_rows</code> tabular file</li>\n        <li><em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n        <li><em>“Choose how to select data by column”</em>: <code class=\"language-plaintext highlighter-rouge\">All columns BUT by column header name(s)</code>\n          <ul>\n            <li><em>“Type header name(s)”</em>: <code class=\"language-plaintext highlighter-rouge\">Class</code></li>\n          </ul>\n        </li>\n        <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Dataset containing class labels or target values”</em>: <code class=\"language-plaintext highlighter-rouge\">train_rows</code> tabular file</li>\n        <li><em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n        <li><em>“Choose how to select data by column”</em>: <code class=\"language-plaintext highlighter-rouge\">Select columns by column header name(s)</code>\n          <ul>\n            <li><em>“Type header name(s)”</em>: <code class=\"language-plaintext highlighter-rouge\">Class</code></li>\n          </ul>\n        </li>\n      </ul>\n    </li>\n    <li><em>“Whether to hold a portion of samples for test exclusively?”</em>: <code class=\"language-plaintext highlighter-rouge\">Nope</code></li>\n    <li><em>“Save best estimator?”</em>: <code class=\"language-plaintext highlighter-rouge\">Fitted best estimator or Detailed cv_results_from nested CV</code></li>\n  </ul>\n\n</blockquote>\n\n<blockquote class=\"question\">\n  <question-title></question-title>\n\n  <p>What is the optimal number of estimators for the given dataset?</p>\n\n  <p>Hint: Please look at the <code class=\"language-plaintext highlighter-rouge\">mean_test_score</code> column in the tabular result from the <strong>Hyperparameter search</strong> tool.</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <p>20 - even though the default value of the number of estimators for Bagging Classifier is <code class=\"language-plaintext highlighter-rouge\">10</code>, <code class=\"language-plaintext highlighter-rouge\">20</code> gives the best accuracy. That’s why it is important to perform hyperparameter search to tune these parameters for any dataset.</p>\n\n  </blockquote>\n\n</blockquote>\n\n<p>Using the <strong>Hyperparameter search</strong> tool, we found the best model, based on the training data. Now, we will predict age in the test dataset using this model.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Predict age</hands-on-title>\n\n  <ol>\n    <li><span class=\"tool\" data-tool=\"toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_ensemble/sklearn_ensemble/1.0.11.0\" title=\"Ensemble methods for classification and regression tool\" aria-role=\"button\"><i class=\"fas fa-wrench\" aria-hidden=\"true\"></i> <strong>Ensemble methods for classification and regression</strong> (<i class=\"fas fa-cubes\" aria-hidden=\"true\"></i> Galaxy version 1.0.11.0)</span>:\n      <ul>\n        <li><em>“Select a Classification Task”</em>: <code class=\"language-plaintext highlighter-rouge\">Load a model and predict</code>\n          <ul>\n            <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Models”</em>: <code class=\"language-plaintext highlighter-rouge\">h5mlm</code> file (output of <strong>Hyperparameter search</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span>)</li>\n            <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Data (tabular)”</em>: <code class=\"language-plaintext highlighter-rouge\">test_rows</code> tabular file</li>\n            <li><em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n          </ul>\n        </li>\n      </ul>\n    </li>\n  </ol>\n\n</blockquote>\n\n<p>Now we will verify the performance by creating and inspecting the plots:</p>\n\n<figure id=\"figure-10\" style=\"max-width: 90%;\"><img src=\"images/confusion_matrix_bagging.png\" alt=\"confusion_matrix. \" width=\"700\" height=\"450\" loading=\"lazy\" /><a target=\"_blank\" href=\"images/confusion_matrix_bagging.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 10</strong>:</span> Confusion matrix for the bagging classifier.</figcaption></figure>\n\n<figure id=\"figure-11\" style=\"max-width: 90%;\"><img src=\"images/precision_recall_bagging.png\" alt=\"prf1_scores. \" width=\"700\" height=\"450\" loading=\"lazy\" /><a target=\"_blank\" href=\"images/precision_recall_bagging.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 11</strong>:</span> Precision, recall and F1 score for the bagging classifier.</figcaption></figure>\n\n<figure id=\"figure-12\" style=\"max-width: 90%;\"><img src=\"images/roc_bagging.png\" alt=\"roc_scores. \" width=\"700\" height=\"450\" loading=\"lazy\" /><a target=\"_blank\" href=\"images/roc_bagging.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 12</strong>:</span> Residual plot between residual (predicted - true) and predicted targets. The plot shows a random pattern of points.</figcaption></figure>\n\n<p>Figure 13 shows that we again achieved an AUC value of <code class=\"language-plaintext highlighter-rouge\">1.00</code>, which shows that our model is highly effective at predicting whether or not a molecule is biodegradable.</p>\n\n<h1 id=\"conclusion\">Conclusion</h1>\n<p>By following these steps, we learned how to build classifiers and visualize the classification results using Galaxy’s machine learning and plotting tools. The features of the training dataset are mapped to the classes. This mapping is used to make predictions on an unseen (test) dataset. The quality of classifiers is visualized using a plotting tool.</p>\n\n<p>There are multiple other classification algorithms, a few are simpler to use (with fewer parameters) and some are more powerful, which can be tried out on this dataset and on other datasets as well. Different datasets can also be analyzed using these classifiers. The classifiers have many parameters which can be altered while performing the analyses to see if they affect the classification accuracy. It may be beneficial to perform a hyperparameter search to tune these parameters for different datasets. In addition, we learned the relevance of machine algorithms for QSAR analyses and constructed a model which successfully predicted an important chemical property - the biodegradability of a substance.</p>\n"],"ref_slides":[],"hands_on":true,"slides":false,"mod_date":"2024-05-29 14:28:52 +0000","pub_date":"2020-04-30 14:15:23 +0000","version":21,"workflows":[{"workflow":"ml_classification.ga","tests":true,"url":"https://training.galaxyproject.org/training-material/topics/statistics/tutorials/classification_machinelearning/workflows/ml_classification.ga","path":"topics/statistics/tutorials/classification_machinelearning/workflows/ml_classification.ga","wfid":"statistics-classification_machinelearning","wfname":"ml_classification","trs_endpoint":"https://training.galaxyproject.org/training-material/api/ga4gh/trs/v2/tools/statistics-classification_machinelearning/versions/ml_classification","license":"MIT","creators":[{"class":"Organization","identifier":"https://orcid.org/0000-0002-2068-4695","name":"Anup Kumar"}],"name":"ml_classification","title":"ml_classification","test_results":null,"modified":"2024-06-24 07:44:31 +0000","mermaid":"flowchart TD\n  0[\"ℹ️ Input Dataset\\ntrain_rows.csv\"];\n  style 0 stroke:#2c3143,stroke-width:4px;\n  1[\"ℹ️ Input Dataset\\ntest_rows_labels.csv\"];\n  style 1 stroke:#2c3143,stroke-width:4px;\n  2[\"ℹ️ Input Dataset\\ntest_rows.csv\"];\n  style 2 stroke:#2c3143,stroke-width:4px;\n  3[\"Pipeline Builder\"];\n  4[\"Generalized linear models\"];\n  0 -->|output| 4;\n  0 -->|output| 4;\n  5[\"Nearest Neighbors Classification\"];\n  0 -->|output| 5;\n  0 -->|output| 5;\n  6[\"Support vector machines SVMs\"];\n  0 -->|output| 6;\n  0 -->|output| 6;\n  7[\"Ensemble methods\"];\n  0 -->|output| 7;\n  0 -->|output| 7;\n  8[\"Remove beginning\"];\n  1 -->|output| 8;\n  9[\"Hyperparameter Search\"];\n  3 -->|outfile| 9;\n  0 -->|output| 9;\n  0 -->|output| 9;\n  10[\"Generalized linear models\"];\n  2 -->|output| 10;\n  4 -->|outfile_fit| 10;\n  11[\"Nearest Neighbors Classification\"];\n  2 -->|output| 11;\n  5 -->|outfile_fit| 11;\n  12[\"Support vector machines SVMs\"];\n  2 -->|output| 12;\n  6 -->|outfile_fit| 12;\n  13[\"Ensemble methods\"];\n  2 -->|output| 13;\n  7 -->|outfile_fit| 13;\n  14[\"Ensemble methods\"];\n  2 -->|output| 14;\n  9 -->|outfile_object| 14;\n  15[\"Plot confusion matrix, precision, recall and ROC and AUC curves\"];\n  8 -->|out_file1| 15;\n  10 -->|outfile_predict| 15;\n  4 -->|outfile_fit| 15;\n  16[\"Plot confusion matrix, precision, recall and ROC and AUC curves\"];\n  1 -->|output| 16;\n  11 -->|outfile_predict| 16;\n  5 -->|outfile_fit| 16;\n  17[\"Plot confusion matrix, precision, recall and ROC and AUC curves\"];\n  1 -->|output| 17;\n  12 -->|outfile_predict| 17;\n  6 -->|outfile_fit| 17;\n  18[\"Plot confusion matrix, precision, recall and ROC and AUC curves\"];\n  1 -->|output| 18;\n  13 -->|outfile_predict| 18;\n  7 -->|outfile_fit| 18;\n  19[\"Plot confusion matrix, precision, recall and ROC and AUC curves\"];\n  1 -->|output| 19;\n  14 -->|outfile_predict| 19;\n  9 -->|outfile_object| 19;"}],"api":"https://training.galaxyproject.org/training-material/api/topics/statistics/tutorials/classification_machinelearning/tutorial.json","tools":["Remove beginning1","toolshed.g2.bx.psu.edu/repos/bgruening/plotly_ml_performance_plots/plotly_ml_performance_plots/0.3","toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_build_pipeline/sklearn_build_pipeline/1.0.11.0","toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_ensemble/sklearn_ensemble/1.0.11.0","toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_generalized_linear/sklearn_generalized_linear/1.0.11.0","toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_nn_classifier/sklearn_nn_classifier/1.0.11.0","toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_searchcv/sklearn_searchcv/1.0.11.0","toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.11.0"],"supported_servers":{"exact":[{"url":"https://usegalaxy.eu","name":"UseGalaxy.eu","usegalaxy":true},{"url":"https://usegalaxy.org","name":"UseGalaxy.org (Main)","usegalaxy":true},{"url":"https://usegalaxy.org.au","name":"UseGalaxy.org.au","usegalaxy":true}],"inexact":[{"url":"https://usegalaxy.cz/","name":"UseGalaxy.cz","usegalaxy":false},{"url":"https://usegalaxy.no/","name":"UseGalaxy.no","usegalaxy":false}]},"topic_name_human":"Statistics and machine learning","admin_install":{"install_tool_dependencies":true,"install_repository_dependencies":true,"install_resolver_dependencies":true,"tools":[{"name":"plotly_ml_performance_plots","owner":"bgruening","revisions":"1c5dcef5ce0f","tool_panel_section_label":"Graph/Display Data","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"sklearn_build_pipeline","owner":"bgruening","revisions":"4c4ec859c31a","tool_panel_section_label":"Machine Learning","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"sklearn_ensemble","owner":"bgruening","revisions":"060ca94ac049","tool_panel_section_label":"Machine Learning","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"sklearn_generalized_linear","owner":"bgruening","revisions":"d4808d5b83da","tool_panel_section_label":"Machine Learning","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"sklearn_nn_classifier","owner":"bgruening","revisions":"8b1b2b91f8d0","tool_panel_section_label":"Machine Learning","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"sklearn_searchcv","owner":"bgruening","revisions":"7626ea9c2e1b","tool_panel_section_label":"Machine Learning","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"sklearn_svm_classifier","owner":"bgruening","revisions":"80852884053f","tool_panel_section_label":"Machine Learning","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"}]},"admin_install_yaml":"---\ninstall_tool_dependencies: true\ninstall_repository_dependencies: true\ninstall_resolver_dependencies: true\ntools:\n- name: plotly_ml_performance_plots\n  owner: bgruening\n  revisions: 1c5dcef5ce0f\n  tool_panel_section_label: Graph/Display Data\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: sklearn_build_pipeline\n  owner: bgruening\n  revisions: 4c4ec859c31a\n  tool_panel_section_label: Machine Learning\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: sklearn_ensemble\n  owner: bgruening\n  revisions: 060ca94ac049\n  tool_panel_section_label: Machine Learning\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: sklearn_generalized_linear\n  owner: bgruening\n  revisions: d4808d5b83da\n  tool_panel_section_label: Machine Learning\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: sklearn_nn_classifier\n  owner: bgruening\n  revisions: 8b1b2b91f8d0\n  tool_panel_section_label: Machine Learning\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: sklearn_searchcv\n  owner: bgruening\n  revisions: 7626ea9c2e1b\n  tool_panel_section_label: Machine Learning\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: sklearn_svm_classifier\n  owner: bgruening\n  revisions: 80852884053f\n  tool_panel_section_label: Machine Learning\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n","tours":false,"video":false,"slides_recordings":false,"translations":{"tutorial":[],"slides":[],"video":false},"license":"CC-BY-4.0","type":"tutorial"}