{"layout":"tutorial_hands_on","title":"Age prediction using machine learning","zenodo_link":"https://zenodo.org/record/2545213","questions":["How to use machine learning to create predictive models from biological datasets (RNA-seq and DNA methylation)?"],"objectives":["Learn ageing biomarkers from RNA-seq and DNA methylation datasets","Apply regression based machine learning algorithms","Learn feature selection and hyperparameter optimisation"],"key_points":["Various machine learning algorithms should be used to find the best ones","For each machine learning algorithm, it hyperparameters should be optimised based on the dataset","Feature selection should be done for high-dimensional datasets"],"time_estimation":"2H","contributors":[{"name":"Ekaterina Polkh","joined":"2017-09","affiliations":["uni-freiburg"],"id":"polkhe","url":"https://training.galaxyproject.org/training-material/api/contributors/polkhe.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/polkhe/"},{"name":"Anup Kumar","email":"anup.rulez@gmail.com","twitter":"musafirtweetsz","joined":"2018-08","elixir_node":"de","affiliations":["uni-freiburg","eurosciencegateway","elixir-europe"],"id":"anuprulez","url":"https://training.galaxyproject.org/training-material/api/contributors/anuprulez.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/"}],"js_requirements":{"mathjax":null,"mermaid":false},"short_id":"T00261","url":"/topics/statistics/tutorials/age-prediction-with-ml/tutorial.html","topic_name":"statistics","tutorial_name":"age-prediction-with-ml","dir":"topics/statistics/tutorials/age-prediction-with-ml","symlink":null,"id":"statistics/age-prediction-with-ml","ref_tutorials":["<p><a href=\"https://en.wikipedia.org/wiki/Machine_learning\">Machine Learning</a> is used to create predictive models by learning features from datasets. In the studies performed by <a href=\"https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1599-6#Sec9\">Jason G. Fleischer et al. 2018</a> and <a href=\"https://www.sciencedirect.com/science/article/pii/S1872497317301643?via%3Dihub\">Jana Naue et al. 2017</a>, biomarkers are examined to predict the chronological age of humans by analysing the RNA-seq gene expression levels and DNA methylation pattern respectively. Different machine learning algorithms are used in these studies to select specific biomarkers to make age prediction. The RNA-seq gene expression (<a href=\"https://www.ebi.ac.uk/training/online/glossary/fpkm\">FPKM</a>) dataset is generated using fibroblast cell lines of humans. The skin fibroblasts cells keep damage that happens with age. Epigenomic and phenotypic changes which are age-dependent are also contained in these cells. Within each individual, <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3174260/\">DNA methylation</a> changes with age. This knowledge is used to select useful biomarkers from DNA methylation dataset. The <a href=\"https://en.wikipedia.org/wiki/CpG_site\">CpGs sites</a> with the highest correlation to age are selected as the biomarkers/features. In both these studies, specific biomarkers are analysed by machine learning algorithms to create an age prediction model.</p>\n\n<p>The datasets from these studies contain features (present as columns). The last column in both the datasets refers to <code class=\"language-plaintext highlighter-rouge\">age</code> which is used as labels/targets. Since the targets are real numbers, the machine learning task becomes <a href=\"https://en.wikipedia.org/wiki/Regression_analysis\">regression</a>. Using these features and targets, a model is learned using machine learning (regression) which learns a mapping between these features and targets. Using machine learning tools in Galaxy, we can achieve comparable prediction scores to those achieved by published analyses. In this tutorial, we will apply a couple of (<a href=\"https://scikit-learn.org/stable/\">scikit-learn</a>) machine learning tools to <a href=\"https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1599-6#Sec9\">RNA-seq</a> and <a href=\"https://www.sciencedirect.com/science/article/pii/S1872497317301643?via%3Dihub\">DNA methylation</a> datasets to predict the chronological age of humans. This tutorial is divided into two parts - one with an RNA-seq dataset and another with a DNA methylation dataset.</p>\n\n<blockquote class=\"comment\">\n  <comment-title></comment-title>\n  <p>In cross-validation, a dataset is divided into <code class=\"language-plaintext highlighter-rouge\">k</code> equal parts (<code class=\"language-plaintext highlighter-rouge\">k</code> should be at least <code class=\"language-plaintext highlighter-rouge\">2</code>). One part is used as the validation set to evaluate the performance of any machine learning algorithm and the remaining parts are used for learning/training.</p>\n</blockquote>\n\n<h4 id=\"r2-coefficient-of-determination\">R2 (coefficient of determination)</h4>\n<p>In both the parts, learning on datasets is done using cross-validation and the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\">R2</a> scoring metric is used to evaluate the performance of the trained model. The closer it is to 1.0, the better it is. If it is negative, then the trained model is not good. To infer how its values exhibit model performance, we can compare the figures <a href=\"#figure-1\">1</a> and <a href=\"#figure-2\">2</a>. In both the plots, the true and predicted targets are plotted in a scatter plot. For a good model, most of the points should lie along the <code class=\"language-plaintext highlighter-rouge\">x = y</code> line as the true and predicted targets are close to each other. In figure <a href=\"#figure-1\">1</a>, we can see that the points are scattered and do not show any pattern. Therefore, the R2 score is <code class=\"language-plaintext highlighter-rouge\">-0.06</code>. But, figure <a href=\"#figure-2\">2</a> shows a better pattern as most of the points lie along the line and the R2 score is almost <code class=\"language-plaintext highlighter-rouge\">1.0</code>. For RNA-seq dataset, we will compute the cross-validated R2 score using the training set and for DNA methylation dataset, we will compute the R2 score for the test set.</p>\n\n<figure id=\"figure-1\" style=\"max-width: 90%;\"><img src=\"../../images/age-prediction-with-ml/model_bad.png\" alt=\"model_bad. \" width=\"800\" height=\"500\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/age-prediction-with-ml/model_bad.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 1</strong>:</span> This shows an example of a bad model as most of the points are scattered. For a model to be good, most of the points should lie along the x = y  line. It means that the predicted target on the y (vertical) axis is close to the true targets on the x (horizontal) axis.</figcaption></figure>\n\n<figure id=\"figure-2\" style=\"max-width: 90%;\"><img src=\"../../images/age-prediction-with-ml/model_good.png\" alt=\"model_good. \" width=\"800\" height=\"500\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/age-prediction-with-ml/model_good.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 2</strong>:</span> This shows an example of a good model as most of the points lie along the x = y line. Because most of the points lie along the x = y line, R2 score is 0.99 very close to the best score of 1.0</figcaption></figure>\n\n<blockquote class=\"agenda\">\n  <agenda-title></agenda-title>\n\n  <p>In this tutorial, we will cover:</p>\n\n<ol id=\"markdown-toc\">\n  <li><a href=\"#analyze-rna-seq-dataset\" id=\"markdown-toc-analyze-rna-seq-dataset\">Analyze RNA-seq dataset</a>    <ol>\n      <li><a href=\"#get-dataset\" id=\"markdown-toc-get-dataset\">Get dataset</a></li>\n      <li><a href=\"#create-data-processing-pipeline\" id=\"markdown-toc-create-data-processing-pipeline\">Create data processing pipeline</a></li>\n      <li><a href=\"#optimise-hyperparameters\" id=\"markdown-toc-optimise-hyperparameters\">Optimise hyperparameters</a></li>\n      <li><a href=\"#create-parallel-coordinates-plot\" id=\"markdown-toc-create-parallel-coordinates-plot\">Create parallel coordinates plot</a></li>\n      <li><a href=\"#compare-results-with-original-paper\" id=\"markdown-toc-compare-results-with-original-paper\">Compare results with original paper</a></li>\n      <li><a href=\"#summary\" id=\"markdown-toc-summary\">Summary</a></li>\n    </ol>\n  </li>\n  <li><a href=\"#analyze-dna-methylation-dataset\" id=\"markdown-toc-analyze-dna-methylation-dataset\">Analyze DNA methylation dataset</a>    <ol>\n      <li><a href=\"#get-train-and-test-datasets\" id=\"markdown-toc-get-train-and-test-datasets\">Get train and test datasets</a></li>\n      <li><a href=\"#create-data-processing-pipeline-1\" id=\"markdown-toc-create-data-processing-pipeline-1\">Create data processing pipeline</a></li>\n      <li><a href=\"#optimise-hyperparameters-1\" id=\"markdown-toc-optimise-hyperparameters-1\">Optimise hyperparameters</a></li>\n      <li><a href=\"#predict-age\" id=\"markdown-toc-predict-age\">Predict age</a></li>\n      <li><a href=\"#create-plots\" id=\"markdown-toc-create-plots\">Create plots</a></li>\n      <li><a href=\"#compare-results-with-original-paper-1\" id=\"markdown-toc-compare-results-with-original-paper-1\">Compare results with original paper</a></li>\n      <li><a href=\"#summary-1\" id=\"markdown-toc-summary-1\">Summary</a></li>\n    </ol>\n  </li>\n  <li><a href=\"#conclusion\" id=\"markdown-toc-conclusion\">Conclusion</a></li>\n</ol>\n\n</blockquote>\n\n<h1 id=\"analyze-rna-seq-dataset\">Analyze RNA-seq dataset</h1>\n\n<p>The RNA-seq dataset is collected from fibroblast cell lines belonging to 133 healthy patients with age ranging from 1 to 94 years. The skin fibroblasts cells dataset is conducive for age prediction related studies for multiple reasons - these skin fibroblasts hold age-related damage, contain phenotypic, epigenomic and transcriptomic changes which are age-dependent and it is easy to collect this dataset using non-invasive techniques. Using this dataset, we perform an <a href=\"https://en.wikipedia.org/wiki/Hyperparameter_optimization\">exhaustive search</a> (also known as grid search) for finding the best features and then apply <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet\">ElasticNet regressor</a> with 5-fold cross-validation. The R2 score achieved is comparable to the predictions found in the study performed by <a href=\"https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1599-6#Sec9\">Jason G. Fleischer et al. 2018</a>.</p>\n\n<blockquote class=\"details\">\n  <details-title>5-fold cross-validation</details-title>\n\n  <p>It is a model validation technique which estimates the performance of a predictive model on an unseen data. A dataset is divided into <code class=\"language-plaintext highlighter-rouge\">5</code> folds and these folds are categorised into training and validation sets. The idea of cross-validation is shown in figure <a href=\"#figure-3\">3</a>. The complete dataset is divided into <code class=\"language-plaintext highlighter-rouge\">5</code> equal parts. 80% of the dataset is used for training and the remaining 20% is used for validating the performance of training. This is done for <code class=\"language-plaintext highlighter-rouge\">5</code> folds/iterations, each time the validation set (20% of the dataset) is different. In all five folds, the complete dataset is used for training and validation. The final validation performance is averaged over <code class=\"language-plaintext highlighter-rouge\">5</code> folds.</p>\n\n  <figure id=\"figure-3\" style=\"max-width: 90%;\"><img src=\"../../images/age-prediction-with-ml/5fold_cv.png\" alt=\"5fold_cv. \" width=\"622\" height=\"347\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/age-prediction-with-ml/5fold_cv.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 3</strong>:</span> The image shows how the 5-fold cross-validation works. The complete dataset is divided into 5 equal parts/folds. 4 parts (80%) of the data (training set shown in yellow) are used for training the model and the remaining one part is used for evaluating (validation set shown in blue) the trained model. This is repeated for 5 times till every part/fold is used as the validation set. The accuracies computed for different validation folds are averaged to give 5-fold cross-validation accuracy.</figcaption></figure>\n\n</blockquote>\n\n<h2 id=\"get-dataset\">Get dataset</h2>\n\n<p>We proceed to the analysis by uploading the RNA-seq dataset. The dataset has <code class=\"language-plaintext highlighter-rouge\">133</code> rows corresponding to human patients and over <code class=\"language-plaintext highlighter-rouge\">27,000</code> columns specifying genes. The last column <code class=\"language-plaintext highlighter-rouge\">age</code> contains the chronological age. For the validation set, this <code class=\"language-plaintext highlighter-rouge\">age</code> column is predicted and the R2 metric is computed.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Data upload</hands-on-title>\n\n  <ol>\n    <li>\n      <p>Create a new history for this tutorial</p>\n\n      <!--SNIPPET-->\n      <blockquote class=\"tip\">   <div class=\"box-title tip-title\" id=\"tip-creating-a-new-history\"><button class=\"gtn-boxify-button tip\" type=\"button\" aria-controls=\"tip-creating-a-new-history\" aria-expanded=\"true\"><i class=\"far fa-lightbulb\" aria-hidden=\"true\"></i> <span>Tip: Creating a new history</span><span class=\"fold-unfold fa fa-minus-square\"></span></button></div>   <p>Click the <i class=\"fas fa-plus\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">new-history</span> icon at the top of the history panel:</p>   <p><img src=\"/training-material/shared/images/history_create_new.svg\" alt=\"UI for creating new history\" /></p>   <!-- the original drawing can be found here https://docs.google.com/drawings/d/1cCBrLAo4kDGic5QyB70rRiWJAKTenTU8STsKDaLcVU8/edit?usp=sharing --> </blockquote>\n      <p><!--END_SNIPPET--></p>\n    </li>\n    <li>\n      <p>Import the files from <a href=\"https://zenodo.org/record/2545213\">Zenodo</a></p>\n\n      <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>https://zenodo.org/record/2545213/files/training_data_normal.tsv\n</code></pre></div>      </div>\n\n      <!--SNIPPET-->\n      <blockquote class=\"tip\">   <div class=\"box-title tip-title\" id=\"tip-importing-via-links\"><button class=\"gtn-boxify-button tip\" type=\"button\" aria-controls=\"tip-importing-via-links\" aria-expanded=\"true\"><i class=\"far fa-lightbulb\" aria-hidden=\"true\"></i> <span>Tip: Importing via links</span><span class=\"fold-unfold fa fa-minus-square\"></span></button></div>   <ul>   <li>Copy the link location</li>   <li>     <p>Click <i class=\"fas fa-upload\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-upload</span> <strong>Upload Data</strong> at the top of the tool panel</p>   </li>   <li>Select <i class=\"fa fa-edit\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-wf-edit</span> <strong>Paste/Fetch Data</strong></li>   <li>     <p>Paste the link(s) into the text field</p>   </li>   <li>     <p>Press <strong>Start</strong></p>   </li>   <li><strong>Close</strong> the window</li> </ul> </blockquote>\n      <p><!--END_SNIPPET--></p>\n    </li>\n    <li>\n      <p>Rename the dataset to <code class=\"language-plaintext highlighter-rouge\">training_data_normal</code>.</p>\n\n      <!--SNIPPET-->\n      <blockquote class=\"tip\">   <div class=\"box-title tip-title\" id=\"tip-renaming-a-dataset\"><button class=\"gtn-boxify-button tip\" type=\"button\" aria-controls=\"tip-renaming-a-dataset\" aria-expanded=\"true\"><i class=\"far fa-lightbulb\" aria-hidden=\"true\"></i> <span>Tip: Renaming a dataset</span><span class=\"fold-unfold fa fa-minus-square\"></span></button></div>   <ul>   <li>Click on the <i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-pencil</span> <strong>pencil icon</strong> for the dataset to edit its attributes</li>   <li>In the central panel, change the <strong>Name</strong> field</li>   <li>Click the <strong>Save</strong> button</li> </ul> </blockquote>\n      <p><!--END_SNIPPET--></p>\n    </li>\n    <li>\n      <p>Check that the datatype is <code class=\"language-plaintext highlighter-rouge\">tabular</code>.</p>\n\n      <!--SNIPPET-->\n      <blockquote class=\"tip\">   <div class=\"box-title tip-title\" id=\"tip-changing-the-datatype\"><button class=\"gtn-boxify-button tip\" type=\"button\" aria-controls=\"tip-changing-the-datatype\" aria-expanded=\"true\"><i class=\"far fa-lightbulb\" aria-hidden=\"true\"></i> <span>Tip: Changing the datatype</span><span class=\"fold-unfold fa fa-minus-square\"></span></button></div>   <ul>   <li>Click on the <i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-pencil</span> <strong>pencil icon</strong> for the dataset to edit its attributes</li>   <li>In the central panel, click <i class=\"fas fa-database\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-chart-select-data</span> <strong>Datatypes</strong> tab on the top</li>   <li>In the <i class=\"fas fa-database\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-chart-select-data</span> <strong>Assign Datatype</strong>, select <code class=\"language-plaintext highlighter-rouge\">datatypes</code> from “<em>New type</em>” dropdown     <ul>       <li>Tip: you can start typing the datatype into the field to filter the dropdown menu</li>     </ul>   </li>   <li>Click the <strong>Save</strong> button</li> </ul> </blockquote>\n      <p><!--END_SNIPPET--></p>\n    </li>\n  </ol>\n\n</blockquote>\n\n<blockquote class=\"comment\">\n  <comment-title></comment-title>\n  <p>In the <code class=\"language-plaintext highlighter-rouge\">training_data_normal</code> dataset, you might have noticed that it showed <code class=\"language-plaintext highlighter-rouge\">134</code> rows instead of <code class=\"language-plaintext highlighter-rouge\">133</code> rows. The first row contains the header information i.e. the description of each column.</p>\n</blockquote>\n\n<h2 id=\"create-data-processing-pipeline\">Create data processing pipeline</h2>\n\n<p>We can see that this RNA-seq dataset is high-dimensional. There are over <code class=\"language-plaintext highlighter-rouge\">27,000</code> columns/features. Generally, not all the features in the dataset are useful for prediction. We need only those features which increase the predictive ability of the model. To filter these features, we perform feature selection and retain only those which are useful. To do that, we use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest\">SelectKBest</a> module. This approach involves extracting those features which are most correlated to the target (<code class=\"language-plaintext highlighter-rouge\">age</code> in our dataset). <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression\">F-regression</a> is used for the extraction of features. Moreover, we are not sure of how many of these features we will need. To find the right number of features, we do a hyperparameter search (to find the best combination of values of different parameters). It works by setting many different numbers of features to determine to number which gives the highest accuracy. To wrap this feature selector with a regressor, we will use the <strong>Pipeline builder</strong> tool. This tool creates a sequential flow of algorithms to execute on datasets. Since the hyperparameters will be tuned, we choose to output the parameters for searchCV. The tool does not take any dataset as input. Rather, the outputs will be used as inputs to the <strong>Hyperparameter search</strong> tool (explained in the following step). We will use ElasticNet as a regressor which creates an age prediction model. It is a linear regressor with <code class=\"language-plaintext highlighter-rouge\">l1</code> (also called lasso) and <code class=\"language-plaintext highlighter-rouge\">l2</code> (also called ridge) as regularisers. Regularisation is a technique used in machine learning to prevent overfitting. Overfitting happens when a machine learning algorithm starts memorising the dataset it is trained upon, rather than learning general features. The consequence of overfitting is that the accuracy on the training set is good, but results on the unseen set (test set) are poor, which happens because the algorithm has not learned general features from the dataset. To prevent overfitting, regularisers like <code class=\"language-plaintext highlighter-rouge\">l1</code> and <code class=\"language-plaintext highlighter-rouge\">l2</code> are used. <code class=\"language-plaintext highlighter-rouge\">L1</code> is a linear term added to the error function of a machine learning algorithm and <code class=\"language-plaintext highlighter-rouge\">l2</code> adds a squared term to the error function. More details about <code class=\"language-plaintext highlighter-rouge\">l1</code> and <code class=\"language-plaintext highlighter-rouge\">l2</code> can found <a href=\"https://www.kaggle.com/residentmario/l1-norms-versus-l2-norms\">here</a>.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Create pipeline</hands-on-title>\n\n  <ol>\n    <li><strong>Pipeline builder</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> with the following parameters:\n      <ul>\n        <li>In <em>“1: Pre-processing step”</em>:\n          <ul>\n            <li><em>“Choose the type of transformation”</em>: <code class=\"language-plaintext highlighter-rouge\">Feature Selection</code>\n              <ul>\n                <li><em>“Select a feature selection algorithm”</em>: <code class=\"language-plaintext highlighter-rouge\">SelectKBest - Select features according to the k highest scores</code>\n                  <ul>\n                    <li><em>“Select a score function”</em>: <code class=\"language-plaintext highlighter-rouge\">f_regression - Univariate linear regression tests</code></li>\n                  </ul>\n                </li>\n              </ul>\n            </li>\n          </ul>\n        </li>\n        <li>In <em>“Final Estimator”</em>:\n          <ul>\n            <li><em>“Choose the module that contains target estimator”</em>: <code class=\"language-plaintext highlighter-rouge\">sklearn.linear_model</code>\n              <ul>\n                <li><em>“Choose estimator class”</em>: <code class=\"language-plaintext highlighter-rouge\">ElasticNet</code></li>\n                <li><em>“Type in parameter settings if different from default”</em>: <code class=\"language-plaintext highlighter-rouge\">random_state=42</code></li>\n              </ul>\n            </li>\n          </ul>\n        </li>\n        <li>In <em>“Output parameters for searchCV?”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n      </ul>\n    </li>\n  </ol>\n\n</blockquote>\n\n<h2 id=\"optimise-hyperparameters\">Optimise hyperparameters</h2>\n\n<p>In any machine learning algorithm, there are many parameters (hyperparameters). We are not sure which values of these parameters will give an optimal prediction. The default values given for these parameters may not be optimal for different datasets. To find the best combination of the values of different parameters for a dataset, <a href=\"https://en.wikipedia.org/wiki/Hyperparameter_optimization\">hyperparameter optimisation</a> is performed. There are different techniques to optimise the hyperparameters of any algorithm given a dataset:</p>\n<ul>\n  <li><a href=\"https://scikit-learn.org/0.16/modules/generated/sklearn.grid_search.GridSearchCV.html\">Grid search</a></li>\n  <li><a href=\"https://scikit-learn.org/0.16/modules/generated/sklearn.grid_search.RandomizedSearchCV.html#sklearn.grid_search.RandomizedSearchCV\">Random search</a></li>\n</ul>\n\n<p>For our analyses, we will use the grid search approach. It is an exhaustive search which tries out all the combinations of different hyperparameters and ranks these combinations based on a scoring metric. In the random search, the values of a parameter are selected randomly from a given range and the best one is found. Grid search works well for parameters taking categorical as well as numerical values but for the random search, it becomes difficult for parameters which take categorical values.</p>\n\n<p>In the <strong>Pipeline builder</strong> tool, we added two steps - preprocessing (feature selection) and an estimator (regressor). There are different hyperparameters for these two steps and their best combination needs to be found. We will perform grid search to estimate the best values for these parameters: <strong>k</strong> (number of features), <strong>normalize</strong> (subtract the mean and divide by the l2-norm of the dataset) and <strong>alpha</strong> (a constant which is multiplied by the regularisation term). For each parameter, we need to specify a set of values to choose from:</p>\n\n<ul>\n  <li>\n    <p><strong>k</strong>: [5880, 5890, 5895, 5900]</p>\n\n    <p>These values of <code class=\"language-plaintext highlighter-rouge\">k</code> are chosen to get the best accuracy. We can choose any number (integers) between <code class=\"language-plaintext highlighter-rouge\">1</code> and <code class=\"language-plaintext highlighter-rouge\">27,000</code> (maximum number of features in the dataset). We will use only these values (shown above) for <code class=\"language-plaintext highlighter-rouge\">k</code> as the accuracy remains the best around these numbers. However, it may vary for a different RNA-seq dataset. That’s the reason why we perform hyperparameter search to find the best values of parameters for any dataset.</p>\n  </li>\n  <li>\n    <p><strong>normalize</strong>: [True, False]</p>\n\n    <p>The default value of <code class=\"language-plaintext highlighter-rouge\">normalize</code> is <code class=\"language-plaintext highlighter-rouge\">False</code>. We will check both, <code class=\"language-plaintext highlighter-rouge\">True</code> and <code class=\"language-plaintext highlighter-rouge\">False</code>.</p>\n  </li>\n  <li>\n    <p><strong>alpha</strong>: [0.00001, 0.0001, 0.001]</p>\n\n    <p>The parameter <code class=\"language-plaintext highlighter-rouge\">alpha</code> takes a positive real number and its default value is <code class=\"language-plaintext highlighter-rouge\">1.0</code>.</p>\n  </li>\n</ul>\n\n<p>For these three parameters, we have 24 different combinations (4 x 2 x 3) of values and we will verify the performance of each combination. The parameter <strong>k</strong> is used for feature selection and parameters <strong>normalize</strong> and <strong>alpha</strong> are used for the regressor. There are many more hyperparameters of the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet\">ElasticNet</a> regressor which are explained in the official documentation of scikit-learn. However, the combination of the above three parameters already gives a comparable accuracy published in the study <a href=\"https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1599-6#Sec9\">Jason G. Fleischer et al. 2018</a>. Therefore, we will stick to these parameters.</p>\n\n<blockquote class=\"comment\">\n  <comment-title></comment-title>\n  <p>It is advisable to tune all the parameters of a machine learning algorithm for a dataset if no prior information is available about the subset of parameters which works best for the dataset.</p>\n</blockquote>\n\n<blockquote class=\"comment\">\n  <comment-title></comment-title>\n  <p>These parameters have the same description and values in the second part of the tutorial where we will again use the <strong>Hyperparameter search</strong> tool.</p>\n</blockquote>\n\n<h3 id=\"search-for-the-best-values-of-hyperparameters\">Search for the best values of hyperparameters</h3>\n\n<p>We will use the <strong>Hyperparameter search</strong> tool to find the best values for each hyperparameter. These values will lead us to create the best model based on the search space chosen for each hyperparameter.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Hyperparameter search</hands-on-title>\n\n  <ol>\n    <li><strong>Hyperparameter search</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> with the following parameters:\n      <ul>\n        <li><em>“Select a model selection search scheme”</em>: <code class=\"language-plaintext highlighter-rouge\">GridSearchCV - Exhaustive search over specified parameter values for an estimator </code>\n          <ul>\n            <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Choose the dataset containing pipeline/estimator object”</em>: <code class=\"language-plaintext highlighter-rouge\">zipped</code> file (one of the outputs of <strong>Pipeline builder</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span>)</li>\n            <li>In <em>“Search parameters Builder”</em>:\n              <ul>\n                <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Choose the dataset containing parameter names”</em>: <code class=\"language-plaintext highlighter-rouge\">tabular</code> file (the other output of <strong>Pipeline builder</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span>)</li>\n                <li>In <em>“Parameter settings for search”</em>:\n                  <ul>\n                    <li><i class=\"far fa-plus-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-repeat</span> <em>“1: Parameter settings for search”</em>\n                      <ul>\n                        <li><em>“Choose a parameter name (with current value)”</em>: <code class=\"language-plaintext highlighter-rouge\">selectkbest__k: 10</code></li>\n                        <li><em>“Search list”</em>: <code class=\"language-plaintext highlighter-rouge\">[5880, 5890, 5895, 5900]</code></li>\n                      </ul>\n                    </li>\n                    <li><i class=\"far fa-plus-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-repeat</span> <em>“2: Parameter settings for search”</em>\n                      <ul>\n                        <li><em>“Choose a parameter name (with current value)”</em>: <code class=\"language-plaintext highlighter-rouge\">elasticnet__normalize: False</code></li>\n                        <li><em>“Search list”</em>: <code class=\"language-plaintext highlighter-rouge\">[True, False]</code></li>\n                      </ul>\n                    </li>\n                    <li><i class=\"far fa-plus-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-repeat</span> <em>“3: Parameter settings for search”</em>\n                      <ul>\n                        <li><em>“Choose a parameter name (with current value)”</em>: <code class=\"language-plaintext highlighter-rouge\">elasticnet__alpha: 1.0</code></li>\n                        <li><em>“Search list”</em>: <code class=\"language-plaintext highlighter-rouge\">[0.00001, 0.0001, 0.001]</code></li>\n                      </ul>\n                    </li>\n                  </ul>\n                </li>\n              </ul>\n            </li>\n            <li>In <em>“Advanced Options for SearchCV”</em>:\n              <ul>\n                <li>\n                  <p><em>“Select the primary metric (scoring)”</em>: <code class=\"language-plaintext highlighter-rouge\">Regression -- 'r2'</code></p>\n\n                  <p>A scoring metric can be set. In this tutorial, we use <code class=\"language-plaintext highlighter-rouge\">Regression -- 'r2'</code></p>\n                </li>\n                <li>\n                  <p><em>“Select the cv splitter”</em>: <code class=\"language-plaintext highlighter-rouge\">KFold</code></p>\n\n                  <p>There are different ways to split the dataset into training and validation sets. In our tutorial, we will use <code class=\"language-plaintext highlighter-rouge\">KFold</code> which splits the dataset into <code class=\"language-plaintext highlighter-rouge\">K</code> consecutive parts. It is used for cross-validation. It is set to <code class=\"language-plaintext highlighter-rouge\">5</code> using another parameter <code class=\"language-plaintext highlighter-rouge\">n_splits</code>.</p>\n\n                  <ul>\n                    <li><em>“n_splits”</em>: <code class=\"language-plaintext highlighter-rouge\">5</code></li>\n                    <li><em>“Whether to shuffle data before splitting”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n                    <li>\n                      <p><em>“Random seed number”</em>: <code class=\"language-plaintext highlighter-rouge\">3111696</code></p>\n\n                      <p>It is set to an integer and used to retain the randomness/accuracy when <em>“Whether to shuffle data before splitting”</em> is <code class=\"language-plaintext highlighter-rouge\">Yes</code> across successive experiments.</p>\n                    </li>\n                  </ul>\n                </li>\n                <li>\n                  <p><em>“Raise fit error”</em>: <code class=\"language-plaintext highlighter-rouge\">No</code></p>\n\n                  <p>While setting different values for a parameter during hyperparameter search, it can happen that wrong values are set which may generate exceptions. To avoid stopping the execution of a regressor, it is set to <code class=\"language-plaintext highlighter-rouge\">No</code> which means even if a wrong parameter value is encountered, the regressor does not stop running and skips that value.</p>\n                </li>\n              </ul>\n            </li>\n          </ul>\n        </li>\n        <li><em>“Select input type”</em>: <code class=\"language-plaintext highlighter-rouge\">tabular data</code>\n          <ul>\n            <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Training samples dataset”</em>: <code class=\"language-plaintext highlighter-rouge\">training_data_normal</code> tabular file</li>\n            <li><em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n            <li><em>“Choose how to select data by column”</em>: <code class=\"language-plaintext highlighter-rouge\">All columns EXCLUDING some by column header name(s)</code>\n              <ul>\n                <li><em>“Type header name(s)”</em>: <code class=\"language-plaintext highlighter-rouge\">age</code></li>\n              </ul>\n            </li>\n            <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Dataset containing class labels or target values”</em>: <code class=\"language-plaintext highlighter-rouge\">training_data_normal</code> tabular file</li>\n            <li><em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n            <li><em>“Choose how to select data by column”</em>: <code class=\"language-plaintext highlighter-rouge\">Select columns by column header name(s)</code>\n              <ul>\n                <li><em>“Type header name(s)”</em>: <code class=\"language-plaintext highlighter-rouge\">age</code></li>\n              </ul>\n            </li>\n          </ul>\n        </li>\n        <li><em>“Whether to hold a portion of samples for test exclusively?”</em>: <code class=\"language-plaintext highlighter-rouge\">Nope</code></li>\n      </ul>\n    </li>\n  </ol>\n\n</blockquote>\n\n<p>The tool returns two outputs, one of which is a table with numerical results. Please inspect it carefully: the <code class=\"language-plaintext highlighter-rouge\">rank_test_score</code> column shows the ranking of different combinations based on the values in the <code class=\"language-plaintext highlighter-rouge\">mean_test_score</code> column.</p>\n\n<blockquote class=\"question\">\n  <question-title></question-title>\n\n  <ol>\n    <li>What is the best <code class=\"language-plaintext highlighter-rouge\">mean_test_score</code> value estimated by the <strong>Hyperparameter search</strong> tool?</li>\n    <li>Which combination of parameters gives the best result?</li>\n    <li>How many possible combinations of parameters the <strong>Hyperparameter search</strong> tool estimated?</li>\n  </ol>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <ol>\n      <li>0.73 (it is close to the best R2 score (0.81) achieved by a customised ensemble algorithm explained by <a href=\"https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1599-6#Sec9\">Jason G. Fleischer et al. 2018</a>)</li>\n      <li>alpha: 0.001, normalize: True, k: 5880</li>\n      <li>24 (it is equal to the number of rows in the tabular output of <strong>Hyperparameter search</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span>)</li>\n    </ol>\n\n  </blockquote>\n\n</blockquote>\n\n<h2 id=\"create-parallel-coordinates-plot\">Create parallel coordinates plot</h2>\n\n<p>We will visualize the tabular output of <strong>Hyperparameter search</strong> tool from the previous step using the <strong>Parallel coordinates plot of tabular data</strong> tool. There are multiple columns in the tabular output, but we will focus on only a few of them.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Create parallel coordinates plot</hands-on-title>\n\n  <ol>\n    <li><strong>Parallel coordinates plot</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> with the following parameters:\n      <ul>\n        <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Select data file”</em>: <code class=\"language-plaintext highlighter-rouge\">tabular</code> file (output of <strong>Hyperparameter search</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span>)</li>\n        <li><em>“Select the columns for dimensions”</em>: <code class=\"language-plaintext highlighter-rouge\">c4, c5, c6</code></li>\n        <li><em>“Select a column containing the values for coloring”</em>: <code class=\"language-plaintext highlighter-rouge\">c3</code></li>\n      </ul>\n    </li>\n  </ol>\n\n</blockquote>\n\n<p>The output plot has the following legend: the colour-coding is based on the <code class=\"language-plaintext highlighter-rouge\">mean_test_score</code> (<code class=\"language-plaintext highlighter-rouge\">c3</code>) column. You can follow the line leading to the score along every column with the parameters’ settings. The columns <code class=\"language-plaintext highlighter-rouge\">c4, c5</code> and <code class=\"language-plaintext highlighter-rouge\">c6</code> are the parameters we chose and <code class=\"language-plaintext highlighter-rouge\">c3</code> is the accuracy column present in the <code class=\"language-plaintext highlighter-rouge\">tabular</code> output of <strong>Hyperparameter search</strong> tool.</p>\n\n<figure id=\"figure-4\" style=\"max-width: 90%;\"><img src=\"../../images/age-prediction-with-ml/parallel_coor_plot.png\" alt=\"data. \" width=\"700\" height=\"450\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/age-prediction-with-ml/parallel_coor_plot.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 4</strong>:</span> The visualization of the hyperparameter optimisation tool output. We optimised the values of 3 hyperparameters (alpha, normalize and k). These can be seen as the columns (first three from left to right) in the plot. The rightmost column contains the accuracy values (mean_test_score).</figcaption></figure>\n\n<blockquote class=\"question\">\n  <question-title></question-title>\n\n  <p>What are the worst performing combinations of hyperparameters (name four)?</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <p>Worst four:</p>\n    <ul>\n      <li>alpha: 0.00001, normalize: False, k: 5880</li>\n      <li>alpha: 0.00001, normalize: False, k: 5890</li>\n      <li>alpha: 0.00001, normalize: False, k: 5895</li>\n      <li>alpha: 0.00001, normalize: False, k: 5900</li>\n    </ul>\n\n  </blockquote>\n\n</blockquote>\n\n<h2 id=\"compare-results-with-original-paper\">Compare results with original paper</h2>\n\n<figure id=\"figure-5\" style=\"max-width: 90%;\"><img src=\"../../images/age-prediction-with-ml/rna_seq_age.png\" alt=\"rna_seq_age_paper. \" width=\"378\" height=\"321\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/age-prediction-with-ml/rna_seq_age.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 5</strong>:</span> The plot shows accuracy obtained in the paper from Jason G. Fleischer et al. 2018 (Predicting age from the transcriptome of human dermal fibroblasts) using ElasticNet regressor. The R2 scores achieved in the tutorial and mentioned in the paper using the same regressor are comparable.</figcaption></figure>\n\n<h2 id=\"summary\">Summary</h2>\n\n<p>Figure <a href=\"#figure-4\">4</a> shows that we achieved an R2 score of <code class=\"language-plaintext highlighter-rouge\">0.73</code> (last column) with 5-fold cross-validation on the training set. In the study <a href=\"https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1599-6#Sec9\">Jason G. Fleischer et al. 2018</a> as well, a similar R2 score is mentioned for linear regressors (Linear regression and ElasticNet). Moreover, the study also included a customised ensemble regressor which achieved better performance (<code class=\"language-plaintext highlighter-rouge\">R2 = 0.81</code>). However, our analysis showcases the use of machine learning tools in Galaxy to reproduce the results published in the paper.</p>\n\n<h1 id=\"analyze-dna-methylation-dataset\">Analyze DNA methylation dataset</h1>\n\n<p>In the second part of the analysis, we will use the <a href=\"https://www.sciencedirect.com/science/article/pii/S1872497317301643?via%3Dihub\">DNA methylation dataset</a> to predict chronological age. One important reason to choose this dataset for an age prediction task is that DNA methylation changes with age and this change occurs at specific CpG sites in humans. Whole blood samples are collected from humans with their ages falling in the range 18-69 and the best age-correlated CpG sites in the genome are chosen as features. The dataset is divided into two parts - training and test sets. The training set is used to train a regressor and the test set is used to evaluate the performance of the trained model using the R2 scoring metric. 5-fold cross-validation is used for training.</p>\n\n<h2 id=\"get-train-and-test-datasets\">Get train and test datasets</h2>\n\n<p>We proceed with the analysis by uploading new datasets. You might want to create a new history first. The training set contains <code class=\"language-plaintext highlighter-rouge\">208</code> rows corresponding to humans and <code class=\"language-plaintext highlighter-rouge\">13</code> features (age-correlated CpG sites in DNA methylation dataset). The last column is <code class=\"language-plaintext highlighter-rouge\">age</code>. The test set contains <code class=\"language-plaintext highlighter-rouge\">104</code> rows and the same number of features as the training set. The <code class=\"language-plaintext highlighter-rouge\">age</code> column in the test set is predicted after training on the training set. Another dataset <code class=\"language-plaintext highlighter-rouge\">test_rows_labels</code> contains the true age values of the test set which is used to compute R2 scores between true and predicted age.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Data upload</hands-on-title>\n\n  <ol>\n    <li>Create a new history for this tutorial</li>\n    <li>\n      <p>Import the files from <a href=\"https://zenodo.org/record/2545213#.XEWTJ9-YVa0\">Zenodo</a></p>\n\n      <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>https://zenodo.org/record/2545213/files/train_rows.csv\nhttps://zenodo.org/record/2545213/files/test_rows_labels.csv\nhttps://zenodo.org/record/2545213/files/test_rows.csv\n</code></pre></div>      </div>\n\n      <!--SNIPPET-->\n      <blockquote class=\"tip\">   <div class=\"box-title tip-title\" id=\"tip-importing-via-links-1\"><button class=\"gtn-boxify-button tip\" type=\"button\" aria-controls=\"tip-importing-via-links-1\" aria-expanded=\"true\"><i class=\"far fa-lightbulb\" aria-hidden=\"true\"></i> <span>Tip: Importing via links</span><span class=\"fold-unfold fa fa-minus-square\"></span></button></div>   <ul>   <li>Copy the link location</li>   <li>     <p>Click <i class=\"fas fa-upload\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-upload</span> <strong>Upload Data</strong> at the top of the tool panel</p>   </li>   <li>Select <i class=\"fa fa-edit\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-wf-edit</span> <strong>Paste/Fetch Data</strong></li>   <li>     <p>Paste the link(s) into the text field</p>   </li>   <li>     <p>Press <strong>Start</strong></p>   </li>   <li><strong>Close</strong> the window</li> </ul> </blockquote>\n      <p><!--END_SNIPPET--></p>\n    </li>\n    <li>\n      <p>Rename the datasets as <code class=\"language-plaintext highlighter-rouge\">train_rows</code>, <code class=\"language-plaintext highlighter-rouge\">test_rows_labels</code> and <code class=\"language-plaintext highlighter-rouge\">test_rows</code> respectively.</p>\n\n      <!--SNIPPET-->\n      <blockquote class=\"tip\">   <div class=\"box-title tip-title\" id=\"tip-renaming-a-dataset-1\"><button class=\"gtn-boxify-button tip\" type=\"button\" aria-controls=\"tip-renaming-a-dataset-1\" aria-expanded=\"true\"><i class=\"far fa-lightbulb\" aria-hidden=\"true\"></i> <span>Tip: Renaming a dataset</span><span class=\"fold-unfold fa fa-minus-square\"></span></button></div>   <ul>   <li>Click on the <i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-pencil</span> <strong>pencil icon</strong> for the dataset to edit its attributes</li>   <li>In the central panel, change the <strong>Name</strong> field</li>   <li>Click the <strong>Save</strong> button</li> </ul> </blockquote>\n      <p><!--END_SNIPPET--></p>\n    </li>\n    <li>\n      <p>Check that the datatype of all the three datasets is <code class=\"language-plaintext highlighter-rouge\">tabular</code>.</p>\n\n      <!--SNIPPET-->\n      <blockquote class=\"tip\">   <div class=\"box-title tip-title\" id=\"tip-changing-the-datatype-1\"><button class=\"gtn-boxify-button tip\" type=\"button\" aria-controls=\"tip-changing-the-datatype-1\" aria-expanded=\"true\"><i class=\"far fa-lightbulb\" aria-hidden=\"true\"></i> <span>Tip: Changing the datatype</span><span class=\"fold-unfold fa fa-minus-square\"></span></button></div>   <ul>   <li>Click on the <i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-pencil</span> <strong>pencil icon</strong> for the dataset to edit its attributes</li>   <li>In the central panel, click <i class=\"fas fa-database\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-chart-select-data</span> <strong>Datatypes</strong> tab on the top</li>   <li>In the <i class=\"fas fa-database\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">galaxy-chart-select-data</span> <strong>Assign Datatype</strong>, select <code class=\"language-plaintext highlighter-rouge\">datatypes</code> from “<em>New type</em>” dropdown     <ul>       <li>Tip: you can start typing the datatype into the field to filter the dropdown menu</li>     </ul>   </li>   <li>Click the <strong>Save</strong> button</li> </ul> </blockquote>\n      <p><!--END_SNIPPET--></p>\n    </li>\n  </ol>\n\n</blockquote>\n\n<p class=\"comment\">The <code class=\"language-plaintext highlighter-rouge\">train_rows</code> contains a column <code class=\"language-plaintext highlighter-rouge\">Age</code> which is the label or target. We will evaluate our model on <code class=\"language-plaintext highlighter-rouge\">test_rows</code> and compare the predicted age with the true age in <code class=\"language-plaintext highlighter-rouge\">test_rows_labels</code></p>\n\n<h2 id=\"create-data-processing-pipeline-1\">Create data processing pipeline</h2>\n\n<p>We will create a pipeline with <strong>Pipeline builder</strong> tool, but this time, we just specify the regressor. <a href=\"https://www.sciencedirect.com/science/article/pii/S1872497317301643?via%3Dihub\">Jana Naue et al. 2017</a> has used <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\">Random Forest</a> as the regressor and we can conclude from this study that the ensemble-based regressor works well on this DNA methylation dataset. Therefore, we will use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor\">Gradient boosting</a> which is an ensemble-based regressor because it uses multiple decision tree regressors internally and predicts by taking the collective performances of the predictions (by multiple decision trees). It has a good predictive power and is robust to outliers. It creates an ensemble of weak learners (decision trees) and iteratively minimises error. One disadvantage, which comes from its basic principle of boosting, is that it cannot be parallelised. The <strong>Pipeline builder</strong> tool will wrap this regressor and return a zipped file and a tabular file containing all tunable hyperparameters.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Create pipeline</hands-on-title>\n\n  <ol>\n    <li><strong>Pipeline builder</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> with the following parameters:\n      <ul>\n        <li>In <em>“Final Estimator”</em>:\n          <ul>\n            <li><em>“Choose the module that contains target estimator”</em>: <code class=\"language-plaintext highlighter-rouge\">sklearn.ensemble</code>\n              <ul>\n                <li><em>“Choose estimator class”</em>: <code class=\"language-plaintext highlighter-rouge\">GradientBoostingRegressor</code></li>\n                <li><em>“Type in parameter settings if different from default”</em>: <code class=\"language-plaintext highlighter-rouge\">random_state=42</code></li>\n              </ul>\n            </li>\n          </ul>\n        </li>\n        <li>In <em>“Output parameters for searchCV?”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n      </ul>\n    </li>\n  </ol>\n\n</blockquote>\n\n<blockquote class=\"comment\">\n  <comment-title></comment-title>\n  <p>The <a href=\"https://scikit-learn.org/stable/modules/ensemble.html#ensemble\"><em>ensemble</em></a> method uses multiple learning models internally for better predictions.</p>\n</blockquote>\n\n<h2 id=\"optimise-hyperparameters-1\">Optimise hyperparameters</h2>\n\n<p>For this analysis, we will also use the <strong>Hyperparameter search</strong> tool to estimate the best values of parameters for the given dataset.\nWe use only one parameter <code class=\"language-plaintext highlighter-rouge\">n_estimators</code> of the <code class=\"language-plaintext highlighter-rouge\">Gradient boosting</code> regressor for this task. This parameter specifies the number of boosting stages the learning process has to go through. The default value of <code class=\"language-plaintext highlighter-rouge\">n_estimators</code> for this regressor is <code class=\"language-plaintext highlighter-rouge\">100</code>. However, we are not sure if this gives the best accuracy. Therefore, it is important to set this parameter to different values to find the optimal one. We choose some values which are less than <code class=\"language-plaintext highlighter-rouge\">100</code> and a few more than <code class=\"language-plaintext highlighter-rouge\">100</code>. The hyperparameter search will look for the optimal number of estimators and gives the best-trained model as one of the outputs. This model is used in the next step to predict age in the test dataset.</p>\n\n<h3 id=\"search-for-the-best-values-of-hyperparameters-1\">Search for the best values of hyperparameters</h3>\n\n<p>We will use the <strong>Hyperparameter search</strong> tool to find the best values for each hyperparameter. These values will lead us to create the best model based on the search space chosen for each hyperparameter.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Hyperparameter search</hands-on-title>\n\n  <ol>\n    <li><strong>Hyperparameter search</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> with the following parameters:\n      <ul>\n        <li><em>“Select a model selection search scheme”</em>: <code class=\"language-plaintext highlighter-rouge\">GridSearchCV - Exhaustive search over specified parameter values for an estimator </code>\n          <ul>\n            <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Choose the dataset containing pipeline/estimator object”</em>: <code class=\"language-plaintext highlighter-rouge\">zipped</code> file (one of the outputs of <strong>Pipeline builder</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span>)</li>\n            <li>In <em>“Search parameters Builder”</em>:\n              <ul>\n                <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Choose the dataset containing parameter names”</em>: <code class=\"language-plaintext highlighter-rouge\">tabular</code> file (the other output of <strong>Pipeline builder</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span>)</li>\n                <li>In <em>“Parameter settings for search”</em>:\n                  <ul>\n                    <li><i class=\"far fa-plus-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-repeat</span> <em>“1: Parameter settings for search”</em>\n                      <ul>\n                        <li><em>“Choose a parameter name (with current value)”</em>: <code class=\"language-plaintext highlighter-rouge\">n_estimators: 100</code></li>\n                        <li><em>“Search list”</em>: <code class=\"language-plaintext highlighter-rouge\">[25, 50, 75, 100, 200]</code></li>\n                      </ul>\n                    </li>\n                  </ul>\n                </li>\n              </ul>\n            </li>\n            <li>In <em>“Advanced Options for SearchCV”</em>:\n              <ul>\n                <li>\n                  <p><em>“Select the primary metric (scoring)”</em>: <code class=\"language-plaintext highlighter-rouge\">Regression -- 'r2'</code></p>\n\n                  <p>A scoring metric can be set. In this tutorial, we use <code class=\"language-plaintext highlighter-rouge\">Regression -- 'r2'</code></p>\n                </li>\n                <li>\n                  <p><em>“Select the cv splitter”</em>: <code class=\"language-plaintext highlighter-rouge\">KFold</code></p>\n\n                  <p>There are different ways to split the dataset into training and validation sets. In our tutorial, we will use <code class=\"language-plaintext highlighter-rouge\">KFold</code> which splits the dataset into <code class=\"language-plaintext highlighter-rouge\">K</code> consecutive parts. It is used for cross-validation. It is set to <code class=\"language-plaintext highlighter-rouge\">5</code> using another parameter <code class=\"language-plaintext highlighter-rouge\">n_splits</code>.</p>\n\n                  <ul>\n                    <li><em>“n_splits”</em>: <code class=\"language-plaintext highlighter-rouge\">5</code></li>\n                    <li><em>“Whether to shuffle data before splitting”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n                    <li>\n                      <p><em>“Random seed number”</em>: <code class=\"language-plaintext highlighter-rouge\">3111696</code></p>\n\n                      <p>It is set to an integer and used to retain the randomness/accuracy when <em>“Whether to shuffle data before splitting”</em> is <code class=\"language-plaintext highlighter-rouge\">Yes</code> across successive experiments.</p>\n                    </li>\n                  </ul>\n                </li>\n                <li>\n                  <p><em>“Raise fit error”</em>: <code class=\"language-plaintext highlighter-rouge\">No</code></p>\n\n                  <p>While setting different values for a parameter during hyperparameter search, it can happen that wrong values are set which may generate exceptions. To avoid stopping the execution of a regressor, it is set to <code class=\"language-plaintext highlighter-rouge\">No</code> which means even if a wrong parameter value is encountered, the regressor does not stop running and skips that value.</p>\n                </li>\n              </ul>\n            </li>\n          </ul>\n        </li>\n        <li><em>“Select input type”</em>: <code class=\"language-plaintext highlighter-rouge\">tabular data</code>\n          <ul>\n            <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Training samples dataset”</em>: <code class=\"language-plaintext highlighter-rouge\">train_rows</code> tabular file</li>\n            <li><em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n            <li><em>“Choose how to select data by column”</em>: <code class=\"language-plaintext highlighter-rouge\">All columns EXCLUDING some by column header name(s)</code>\n              <ul>\n                <li><em>“Type header name(s)”</em>: <code class=\"language-plaintext highlighter-rouge\">Age</code></li>\n              </ul>\n            </li>\n            <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Dataset containing class labels or target values”</em>: <code class=\"language-plaintext highlighter-rouge\">train_rows</code> tabular file</li>\n            <li><em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n            <li><em>“Choose how to select data by column”</em>: <code class=\"language-plaintext highlighter-rouge\">Select columns by column header name(s)</code>\n              <ul>\n                <li><em>“Type header name(s)”</em>: <code class=\"language-plaintext highlighter-rouge\">Age</code></li>\n              </ul>\n            </li>\n          </ul>\n        </li>\n        <li><em>“Whether to hold a portion of samples for test exclusively?”</em>: <code class=\"language-plaintext highlighter-rouge\">Nope</code></li>\n      </ul>\n    </li>\n  </ol>\n\n</blockquote>\n\n<blockquote class=\"question\">\n  <question-title></question-title>\n\n  <p>What is the optimal number of estimators for the given dataset?</p>\n\n  <p>Hint: Please look at the <code class=\"language-plaintext highlighter-rouge\">mean_test_score</code> column in the tabular result from the <strong>Hyperparameter search</strong> tool.</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <ol>\n      <li>(Even though the default value of the number of estimators for Gradient boosting regressor is <code class=\"language-plaintext highlighter-rouge\">100</code>, <code class=\"language-plaintext highlighter-rouge\">75</code> gives the best accuracy. That’s why it is important to perform hyperparameter search to tune these parameters for any dataset). 50 estimators also give almost the same accuracy.</li>\n    </ol>\n\n  </blockquote>\n\n</blockquote>\n\n<h2 id=\"predict-age\">Predict age</h2>\n\n<p>Using the <strong>Hyperparameter search</strong> tool, we found the best model based on the training data. Now, we will predict age in the test dataset using this model in order to see if the model has learned important features which can be generalised on a new dataset. The test dataset (<code class=\"language-plaintext highlighter-rouge\">test_rows</code>) contains the same number of features, but does not contain the <code class=\"language-plaintext highlighter-rouge\">age</code> column. This is predicted using the trained model.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Predict age</hands-on-title>\n\n  <ol>\n    <li><strong>Ensemble methods for classification and regression</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> with the following parameters:\n      <ul>\n        <li><em>“Select a Classification Task”</em>: <code class=\"language-plaintext highlighter-rouge\">Load a model and predict</code>\n          <ul>\n            <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Models”</em>: <code class=\"language-plaintext highlighter-rouge\">zipped</code> file (output of <strong>Hyperparameter search</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span>)</li>\n            <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Data (tabular)”</em>: <code class=\"language-plaintext highlighter-rouge\">test_rows</code> tabular file</li>\n            <li><em>“Does the dataset contain header”</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n          </ul>\n        </li>\n      </ul>\n    </li>\n  </ol>\n\n</blockquote>\n\n<h2 id=\"create-plots\">Create plots</h2>\n\n<p>In the previous step, we generated predictions for the test dataset. We have one more dataset (<code class=\"language-plaintext highlighter-rouge\">test_rows_labels</code>) which contains the true age values of the test set. Using the true and predicted values of age in the test set, we will verify the performance by analysing the plots.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Create regression plots</hands-on-title>\n\n  <ol>\n    <li><strong>Plot actual vs predicted curves and residual plots of tabular data</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> with the following parameters:\n      <ul>\n        <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Select input data file”</em>: <code class=\"language-plaintext highlighter-rouge\">test_rows_labels</code> tabular file</li>\n        <li><i class=\"far fa-copy\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-files</span> <em>“Select predicted data file”</em>: <code class=\"language-plaintext highlighter-rouge\">tabular</code> file (output of <strong>Ensemble methods for classification and regression</strong> <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span>)</li>\n      </ul>\n    </li>\n  </ol>\n\n</blockquote>\n\n<p>The tool outputs three HTML files which contain the interactive plots.</p>\n\n<blockquote class=\"question\">\n  <question-title></question-title>\n\n  <p>Inspect the plots. What can you say about the predictions?</p>\n\n  <blockquote class=\"solution\">\n    <solution-title></solution-title>\n\n    <p>Figures <a href=\"#figure-6\">6</a> and <a href=\"#figure-8\">8</a> show that the prediction is good because the predicted age lies close to the true age.</p>\n\n  </blockquote>\n</blockquote>\n\n<figure id=\"figure-6\" style=\"max-width: 90%;\"><img src=\"../../images/age-prediction-with-ml/scatter_plot.png\" alt=\"Scatter plot. \" width=\"700\" height=\"450\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/age-prediction-with-ml/scatter_plot.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 6</strong>:</span> Scatter plot for true and predicted age for test set. It is evident from the plot that most of the points lie along the x = y line, which means that true and predicted ages are close to each other. The root mean squared error in predicting age is 3.76 years and R2 score (0.94) is close to the best score of 1.0.</figcaption></figure>\n\n<p>We can see in the scatter plot (figure <a href=\"#figure-6\">6</a>) that most of the points lie along the x=y curve. It means that the true and predicted ages are close to each other. The root mean square error (<code class=\"language-plaintext highlighter-rouge\">RMSE</code>) is <code class=\"language-plaintext highlighter-rouge\">3.76</code> and the R2 score is <code class=\"language-plaintext highlighter-rouge\">0.94</code>.</p>\n\n<figure id=\"figure-7\" style=\"max-width: 90%;\"><img src=\"../../images/age-prediction-with-ml/residual_plot.png\" alt=\"Residuals. \" width=\"700\" height=\"450\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/age-prediction-with-ml/residual_plot.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 7</strong>:</span> The plot shows the residuals (predicted age - true) age against the predicted age. For a good learning/training, this plot should not show any distinct pattern and the points should be symmetrically distributed along the y = 0 line.</figcaption></figure>\n\n<p>The <a href=\"http://docs.statwing.com/interpreting-residual-plots-to-improve-your-regression/\">residual plot</a> shown in figure <a href=\"#figure-7\">7</a> is generated to see if there is any visible pattern between residual (predicted age - true age) and predicted age. For a good model, there should not be any visible pattern with the plotted points.</p>\n\n<figure id=\"figure-8\" style=\"max-width: 90%;\"><img src=\"../../images/age-prediction-with-ml/true_vs_predicted_plot.png\" alt=\"True vs predicted age. \" width=\"700\" height=\"450\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/age-prediction-with-ml/true_vs_predicted_plot.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 8</strong>:</span> The plot shows the true vs predicted age for all the samples in the test set. We can see that the predicted values are close to the true values.</figcaption></figure>\n\n<h2 id=\"compare-results-with-original-paper-1\">Compare results with original paper</h2>\n\n<figure id=\"figure-9\" style=\"max-width: 90%;\"><img src=\"../../images/age-prediction-with-ml/dnam_age_paper.png\" alt=\"dnam_image_paper. \" width=\"459\" height=\"466\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/age-prediction-with-ml/dnam_age_paper.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 9</strong>:</span> The plot is from Jana Naue et al. 2017 (Chronological age prediction based on DNA methylation) and shows a scatter plot with the predicted age on the vertical axis and the true age on the horizontal axis. The plot is comparable to the scatter plot shown in figure 6. The RMSE score is also comparable. The paper used Random forest as the regressor and we used Gradient boosting as the regressor.</figcaption></figure>\n\n<h2 id=\"summary-1\">Summary</h2>\n\n<p>Figure <a href=\"#figure-6\">6</a> shows that we achieved an R2 score of <code class=\"language-plaintext highlighter-rouge\">0.94</code> and root mean square score of <code class=\"language-plaintext highlighter-rouge\">3.76</code> for the test set using the Gradient boosting regressor. The study of <a href=\"https://www.sciencedirect.com/science/article/pii/S1872497317301643?via%3Dihub\">Jana Naue et al. 2017</a> also mentions a similar root mean square score (<code class=\"language-plaintext highlighter-rouge\">3.93</code>), derived using the random forest regressor. The root mean square score shows the difference in the true and predicted age of humans. The R2 score (<code class=\"language-plaintext highlighter-rouge\">0.94</code>) is close to the best achievable score of <code class=\"language-plaintext highlighter-rouge\">1.0</code> which shows that the trained model is good. Overall, the second part of the analysis also shows that using the machine learning tools in Galaxy, we can achieve state-of-the-art predictions mentioned in the recent scientific studies.</p>\n\n<h1 id=\"conclusion\">Conclusion</h1>\n\n<p>In our tutorial, we were able to use machine learning tools in Galaxy to reproduce the results reported in these scientific studies - <a href=\"https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1599-6#Sec9\">Jason G. Fleischer et al. 2018</a> and <a href=\"https://www.sciencedirect.com/science/article/pii/S1872497317301643?via%3Dihub\">Jana Naue et al. 2017</a>. We also learned how to work with high-dimensional datasets, perform a hyperparameter search and cross-validation. Further, we can reuse the trained models to make predictions on a new dataset provided that this new dataset has the same features. There are numerous other machine learning algorithms available in Galaxy which can also be tried out on these datasets to verify whether the accuracy can be improved.</p>\n"],"ref_slides":[],"hands_on":true,"slides":false,"mod_date":"2024-03-05 11:50:50 +0000","pub_date":"2019-01-25 11:10:10 +0000","version":24,"workflows":[{"workflow":"age-prediction-dnam.ga","tests":false,"url":"https://training.galaxyproject.org/training-material/topics/statistics/tutorials/age-prediction-with-ml/workflows/age-prediction-dnam.ga","path":"topics/statistics/tutorials/age-prediction-with-ml/workflows/age-prediction-dnam.ga","wfid":"statistics-age-prediction-with-ml","wfname":"age-prediction-dnam","trs_endpoint":"https://training.galaxyproject.org/training-material/api/ga4gh/trs/v2/tools/statistics-age-prediction-with-ml/versions/age-prediction-dnam","license":null,"creators":[],"name":"Age Prediction DNA Methylation","title":"Age Prediction DNA Methylation","test_results":null,"modified":"2024-06-24 07:46:43 +0000","mermaid":"flowchart TD\n  0[\"Pipeline Builder\"];\n  1[\"ℹ️ Input Dataset\\ntrain_dataset\"];\n  style 1 stroke:#2c3143,stroke-width:4px;\n  2[\"ℹ️ Input Dataset\\ntest_dataset\"];\n  style 2 stroke:#2c3143,stroke-width:4px;\n  3[\"ℹ️ Input Dataset\\ntest_labels_dataset\"];\n  style 3 stroke:#2c3143,stroke-width:4px;\n  4[\"Hyperparameter Search\"];\n  0 -->|outfile_params| 4;\n  0 -->|outfile| 4;\n  1 -->|output| 4;\n  1 -->|output| 4;\n  5[\"Ensemble methods\"];\n  2 -->|output| 5;\n  4 -->|outfile_object| 5;\n  6[\"Plot actual vs predicted curves and residual plots\"];\n  5 -->|outfile_predict| 6;\n  3 -->|output| 6;"},{"workflow":"age-prediction-rna.ga","tests":false,"url":"https://training.galaxyproject.org/training-material/topics/statistics/tutorials/age-prediction-with-ml/workflows/age-prediction-rna.ga","path":"topics/statistics/tutorials/age-prediction-with-ml/workflows/age-prediction-rna.ga","wfid":"statistics-age-prediction-with-ml","wfname":"age-prediction-rna","trs_endpoint":"https://training.galaxyproject.org/training-material/api/ga4gh/trs/v2/tools/statistics-age-prediction-with-ml/versions/age-prediction-rna","license":null,"creators":[],"name":"Age Prediction RNA-Seq","title":"Age Prediction RNA-Seq","test_results":null,"modified":"2024-06-24 07:46:43 +0000","mermaid":"flowchart TD\n  0[\"Pipeline Builder\"];\n  1[\"ℹ️ Input Dataset\\nInput dataset\"];\n  style 1 stroke:#2c3143,stroke-width:4px;\n  2[\"Hyperparameter Search\"];\n  0 -->|outfile_params| 2;\n  0 -->|outfile| 2;\n  1 -->|output| 2;\n  1 -->|output| 2;\n  3[\"Parallel Coordinates Plot\"];\n  2 -->|outfile_result| 3;"}],"api":"https://training.galaxyproject.org/training-material/api/topics/statistics/tutorials/age-prediction-with-ml/tutorial.json","tools":["toolshed.g2.bx.psu.edu/repos/bgruening/plotly_parallel_coordinates_plot/plotly_parallel_coordinates_plot/0.1","toolshed.g2.bx.psu.edu/repos/bgruening/plotly_regression_performance_plots/plotly_regression_performance_plots/0.1","toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_build_pipeline/sklearn_build_pipeline/1.0.8.1","toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_ensemble/sklearn_ensemble/1.0.8.1","toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_searchcv/sklearn_searchcv/1.0.8.1"],"supported_servers":{"exact":[{"url":"https://usegalaxy.cz/","name":"UseGalaxy.cz","usegalaxy":false},{"url":"https://usegalaxy.eu","name":"UseGalaxy.eu","usegalaxy":true},{"url":"https://usegalaxy.org","name":"UseGalaxy.org (Main)","usegalaxy":true},{"url":"https://usegalaxy.org.au","name":"UseGalaxy.org.au","usegalaxy":true}],"inexact":[{"url":"https://usegalaxy.no/","name":"UseGalaxy.no","usegalaxy":false}]},"topic_name_human":"Statistics and machine learning","admin_install":{"install_tool_dependencies":true,"install_repository_dependencies":true,"install_resolver_dependencies":true,"tools":[{"name":"plotly_parallel_coordinates_plot","owner":"bgruening","revisions":"7b21a9b5922f","tool_panel_section_label":"Graph/Display Data","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"plotly_regression_performance_plots","owner":"bgruening","revisions":"389227fa1864","tool_panel_section_label":"Graph/Display Data","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"sklearn_build_pipeline","owner":"bgruening","revisions":"840f29aad145","tool_panel_section_label":"Machine Learning","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"sklearn_ensemble","owner":"bgruening","revisions":"1a53edc4b438","tool_panel_section_label":"Machine Learning","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"sklearn_searchcv","owner":"bgruening","revisions":"25ab6b4e376e","tool_panel_section_label":"Machine Learning","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"}]},"admin_install_yaml":"---\ninstall_tool_dependencies: true\ninstall_repository_dependencies: true\ninstall_resolver_dependencies: true\ntools:\n- name: plotly_parallel_coordinates_plot\n  owner: bgruening\n  revisions: 7b21a9b5922f\n  tool_panel_section_label: Graph/Display Data\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: plotly_regression_performance_plots\n  owner: bgruening\n  revisions: 389227fa1864\n  tool_panel_section_label: Graph/Display Data\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: sklearn_build_pipeline\n  owner: bgruening\n  revisions: 840f29aad145\n  tool_panel_section_label: Machine Learning\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: sklearn_ensemble\n  owner: bgruening\n  revisions: 1a53edc4b438\n  tool_panel_section_label: Machine Learning\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: sklearn_searchcv\n  owner: bgruening\n  revisions: 25ab6b4e376e\n  tool_panel_section_label: Machine Learning\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n","tours":false,"video":false,"slides_recordings":false,"translations":{"tutorial":[],"slides":[],"video":false},"license":"CC-BY-4.0","type":"tutorial"}