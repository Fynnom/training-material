{"layout":"tutorial_hands_on","title":"Calling very rare variants","subtopic":"introduction","zenodo_link":"","draft":true,"questions":["What frequency of variants is so low that it is obscured by sequencing error rate?","What are the different types of consensus sequences produced from duplex sequencing?"],"objectives":["Processing raw duplex sequencing data into consensus sequences","Find rare variants without relying on diploid assumptions"],"time_estimation":"3h","key_points":["Diploid variant calling relies on assumptions that rare variant calling cannot make","Duplex consensus sequences are usually most accurate, but sometimes you must rely on single-strand consensus sequences instead."],"contributors":[{"name":"Anton Nekrutenko","email":"anton@nekrut.org","joined":"2017-09","id":"nekrut","url":"https://training.galaxyproject.org/training-material/api/contributors/nekrut.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/nekrut/"},{"name":"Nick Stoler","twitter":"NickStoler","joined":"2018-07","id":"NickSto","url":"https://training.galaxyproject.org/training-material/api/contributors/NickSto.json","page":"https://training.galaxyproject.org/training-material/hall-of-fame/NickSto/"}],"js_requirements":{"mathjax":null,"mermaid":false},"short_id":"T00310","url":"/topics/variant-analysis/tutorials/dunovo/tutorial.html","topic_name":"variant-analysis","tutorial_name":"dunovo","dir":"topics/variant-analysis/tutorials/dunovo","symlink":null,"id":"variant-analysis/dunovo","ref_tutorials":["<p>This page explains how to perform discovery of low frequency variants from duplex sequencing data. As an example we use the <em>ABL1</em> dataset published by <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/25849638\">Schmitt and colleagues</a> (SRA accession <a href=\"https://www.ncbi.nlm.nih.gov/sra/?term=SRR1799908\">SRR1799908</a>).</p>\n\n<blockquote class=\"agenda\">\n  <agenda-title></agenda-title>\n\n<ol id=\"markdown-toc\">\n  <li><a href=\"#background\" id=\"markdown-toc-background\">Background</a></li>\n  <li><a href=\"#how-to-use-this-tutorial\" id=\"markdown-toc-how-to-use-this-tutorial\">How to use this tutorial</a></li>\n  <li><a href=\"#generating-consensus-sequences\" id=\"markdown-toc-generating-consensus-sequences\">Generating consensus sequences</a>    <ol>\n      <li><a href=\"#getting-data-in-and-assessing-quality\" id=\"markdown-toc-getting-data-in-and-assessing-quality\">Getting data in and assessing quality</a></li>\n      <li><a href=\"#processing-reads-into-duplex-consensus-sequences-with-du-novo\" id=\"markdown-toc-processing-reads-into-duplex-consensus-sequences-with-du-novo\">Processing reads into duplex consensus sequences with Du Novo</a></li>\n      <li><a href=\"#filtering-consensuses\" id=\"markdown-toc-filtering-consensuses\">Filtering consensuses</a></li>\n    </ol>\n  </li>\n  <li><a href=\"#calling-variants-with-duplex-consensus-sequences\" id=\"markdown-toc-calling-variants-with-duplex-consensus-sequences\">Calling variants with duplex consensus sequences</a>    <ol>\n      <li><a href=\"#mapping-the-reads\" id=\"markdown-toc-mapping-the-reads\">Mapping the reads</a></li>\n      <li><a href=\"#calling-the-variants\" id=\"markdown-toc-calling-the-variants\">Calling the variants</a></li>\n      <li><a href=\"#results\" id=\"markdown-toc-results\">Results</a></li>\n    </ol>\n  </li>\n  <li><a href=\"#calling-variants-with-single-strand-consensus-sequences\" id=\"markdown-toc-calling-variants-with-single-strand-consensus-sequences\">Calling variants with single strand consensus sequences</a>    <ol>\n      <li><a href=\"#re-running-analyses-with-workflows\" id=\"markdown-toc-re-running-analyses-with-workflows\">Re-running analyses with workflows</a></li>\n    </ol>\n  </li>\n  <li><a href=\"#conclusion\" id=\"markdown-toc-conclusion\">Conclusion</a></li>\n</ol>\n\n</blockquote>\n\n<h2 id=\"background\">Background</h2>\n\n<h3 id=\"finding-rare-variants\">Finding rare variants</h3>\n\n<p>Most popular variant callers focus on the common case of sequencing a diploid individual to find heterozygous and homozygous variants. This is a well-studied problem with its own challenges, but at least you can expect your variants to be present in either 100%, 50%, or 0% of your sample DNA. If you observe a variant present in 99%, 56%, or 2% of the reads at a site, you can probably assume the allele is actually present at 100%, 50%, or 0%, respectively, in your sample.</p>\n\n<p>But in this tutorial, we’re looking for <strong>rare variants</strong>. So our true frequency might actually be 13%, 1%, or even 0.4%. The challenge then becomes distinguishing these situations from sequencing errors. Next-generation sequencers produce noise at this level, making it challenging to make this distinction in data produced with standard resequencing methods.</p>\n\n<h3 id=\"duplex-sequencing\">Duplex sequencing</h3>\n\n<p><a href=\"http://www.pnas.org/content/109/36/14508.short\">Duplex sequencing</a> is a method that addresses the problem of distinguishing sequencing signal from noise. It can increase sequencing accuracy by over four orders of magnitude. Duplex sequencing uses randomly generated oligomers to uniquely tag each fragment in a sample after random shearing. The tagged fragments are then PCR amplified prior to sequencing, so that many reads can be obtained from each original molecule. The tags in each read can then be used to identify which original fragment the read came from. Identifying multiple reads from each fragment allows building a consensus of the original sequence of the fragment, eliminating errors.</p>\n\n<p>The key to duplex sequencing, as opposed to other types of consensus-based methods (<a href=\"https://www.nature.com/articles/nrg.2017.117\">review here</a>), is that both ends of the original fragment are tagged such that its strands can be distinguished. Knowing which strand each read comes from allows us to recognize errors even in the first round of PCR.</p>\n\n<p>Processing the raw reads into consensus sequences consists of four main steps:</p>\n<ol>\n  <li>Group reads by their tags.</li>\n  <li>Align reads in the same tag group.</li>\n  <li>Build single-strand consensus sequences (<strong>SSCS</strong>) of reads coming from the same original strand.</li>\n  <li>Build duplex consensus sequences (<strong>DCS</strong>) from pairs of SSCS.</li>\n</ol>\n\n<p>Du Novo is a tool which can carry out these steps. Unlike most other such tools, it can do so without the use of a reference sequence, and it can correct for errors in the tags which can contribute to data loss.</p>\n\n<blockquote class=\"comment\">\n  <comment-title>Terminology</comment-title>\n\n  <p>Du Novo processes the tags from each fragment by concatenating them into a single <strong>barcode</strong>.</p>\n\n  <ul>\n    <li>For a standard protocol with two 12bp tags, this results in a 24bp barcode which identifies each family.</li>\n  </ul>\n\n</blockquote>\n\n<p><a href=\"http://www.pnas.org/content/109/36/14508.short\">Schmitt <em>et al.</em> 2012</a> provides this overview of the whole method:\n<a href=\"../../images/ds.png\" rel=\"noopener noreferrer\"><img src=\"../../images/ds.png\" alt=\"duplex. \" width=\"1280\" height=\"576\" loading=\"lazy\" /></a></p>\n\n<p><strong>Figure 1:</strong> The logic of duplex sequencing. The computational process is shown in part <strong>C</strong>.</p>\n\n<h3 id=\"the-value-of-single-strand-consensus-sequences\">The value of single-strand consensus sequences</h3>\n\n<p>The DCSs have the ultimate accuracy, yet the SSCSs can also be very useful when ampliconic DNA is used as an input to a duplex experiment. Let us illustrate the utility of SSCSs with the following example. Suppose one is interested in quantifying variants in a virus that has a very low titer in body fluids. Since the duplex procedure requires a substantial amount of starting DNA (between <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4271547/\">between 0.2 and 3 micrograms</a>) the virus needs to be enriched. This can be done, for example, with a PCR designed to amplify the entire genome of the virus. Yet the problem is that during the amplification heterologous strands will almost certainly realign to some extent forming heteroduplex molecules:</p>\n\n<p><a href=\"../../images/het.png\" rel=\"noopener noreferrer\"><img src=\"../../images/het.png\" alt=\"hd. \" height=\"888\" width=\"1210\" loading=\"lazy\" /></a></p>\n\n<p><strong>Figure 2:</strong> Heteroduplex formation in ampliconic templates. Image by Barbara Arbeithuber from <a href=\"https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-1039-4\">Stoler <em>et al.</em> 2016</a>. Here there are two distinct types of viral genomes: carrying <code class=\"language-plaintext highlighter-rouge\">A</code> and <code class=\"language-plaintext highlighter-rouge\">G</code>. Because the population of genomes is enriched via PCR, heteroduplex formation takes place, skewing frequency estimates performed using DCSs.</p>\n\n<p>In the image above there are two alleles: green (<code class=\"language-plaintext highlighter-rouge\">A</code>) and red (<code class=\"language-plaintext highlighter-rouge\">G</code>). After PCR a fraction of molecules are in heteroduplex state. If this PCR-derived DNA is now used as the starting material for a DS experiment, the heteroduplex molecules will manifest themselves as having an <code class=\"language-plaintext highlighter-rouge\">N</code> base at this site (because Du Novo interprets disagreements as <code class=\"language-plaintext highlighter-rouge\">N</code>s during consensus generation). So, DSCs produced from this dataset will have <code class=\"language-plaintext highlighter-rouge\">A</code>, <code class=\"language-plaintext highlighter-rouge\">G</code>, and <code class=\"language-plaintext highlighter-rouge\">N</code> at the polymorphic site. Yet, SSCSs will only have <code class=\"language-plaintext highlighter-rouge\">A</code> and <code class=\"language-plaintext highlighter-rouge\">G</code>. Thus SSCS will give a more accurate estimate of the allele frequency at this site in this particular case. In Du Novo SSCSs are generated when the <i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>Output single-strand consensus sequences</em> option of <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Du Novo: Make consensus reads</strong> tool is set to <code class=\"language-plaintext highlighter-rouge\">Yes</code> (see <a href=\"#making-consensus-sequences\">below</a>).</p>\n\n<h2 id=\"how-to-use-this-tutorial\">How to use this tutorial</h2>\n\n<p>The entire analysis described here is accessible as a <a href=\"https://usegalaxy.org/u/nstoler/h/du-novo-gtn-tutorial\">Galaxy history</a> that you can copy and play with.</p>\n\n<blockquote class=\"comment\">\n  <comment-title>Running the tools</comment-title>\n  <ul>\n    <li>Leave all parameters on their default settings, unless instructed otherwise.\n      <blockquote class=\"comment\">\n        <comment-title>Helping Du Novo</comment-title>\n        <p>But if you’d like to help improve Du Novo, consider checking <code class=\"language-plaintext highlighter-rouge\">Yes</code> under <i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>Send usage data</em>.</p>\n      </blockquote>\n    </li>\n  </ul>\n</blockquote>\n\n<p>This analysis can be divided into three parts:</p>\n<ol>\n  <li><a href=\"#generating-consensus-sequences\">Generating consensus sequences</a></li>\n  <li><a href=\"#calling-variants-with-duplex-consensus-sequences\">Calling variants with duplex consensus sequences</a></li>\n  <li><a href=\"#calling-variants-with-single-strand-consensus-sequences\">Calling variants with single strand consensus sequences</a></li>\n</ol>\n\n<p>Here are the steps, displayed as the Galaxy history you’ll end up with if you follow the instructions:</p>\n<ul>\n  <li>Note: Galaxy histories show the first step at the bottom!</li>\n</ul>\n\n<p><a href=\"../../images/history-dunovo.png\" rel=\"noopener noreferrer\"><img src=\"../../images/history-dunovo.png\" alt=\"steps. \" width=\"831\" height=\"1467\" loading=\"lazy\" /></a></p>\n\n<p><strong>Figure 3:</strong> Analysis outline</p>\n\n<h1 id=\"generating-consensus-sequences\">Generating consensus sequences</h1>\n\n<p>The starting point of the analysis is sequencing reads (in <a href=\"https://en.wikipedia.org/wiki/FASTQ_format\">FASTQ</a> format) produced from a duplex sequencing library.</p>\n\n<h2 id=\"getting-data-in-and-assessing-quality\">Getting data in and assessing quality</h2>\n\n<p>We uploaded the <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4414912/\">Schmitt <em>et al.</em> 2015</a> data directly from SRA as shown in <a href=\"https://vimeo.com/121187220\">this screencast</a>.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Importing the raw data</hands-on-title>\n\n  <p>You can obtain the reads from this dataset by copying <a href=\"https://usegalaxy.org/u/nstoler/h/srr1799908---schmitt-2015\">this history</a>.</p>\n  <ol>\n    <li>Make sure you’re logged into <a href=\"https://usegalaxy.org\">Galaxy</a>.</li>\n    <li>Go to <a href=\"https://usegalaxy.org/u/nstoler/h/srr1799908---schmitt-2015\">the history</a>.</li>\n    <li>Click on <strong>Import history</strong> in the upper right.</li>\n  </ol>\n\n  <p>Or, if you’d like to use a different Galaxy instance, you can import it:</p>\n  <ol>\n    <li>Click on the gear icon at the top of the <strong>History</strong> pane.</li>\n    <li>Click on “Import from File” at the bottom of the menu.</li>\n    <li>Enter this link in the box under <strong>Archived History URL</strong>:\n<code class=\"language-plaintext highlighter-rouge\">https://usegalaxy.org/history/export_archive?id=7ac09d1db287dbba</code></li>\n  </ol>\n</blockquote>\n\n<p>This created two datasets in our galaxy history: one for forward reads and one for reverse. We then evaluated the quality of the data by running FastQC on both datasets (forward and reverse). You can read about using <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>FastQC</strong> in the dedicated <a href=\"/training-material/topics/sequence-analysis/tutorials/quality-control/tutorial.html#assess-quality-with-fastqc---short--long-reads\">quality-control tutorial</a>.</p>\n\n<p>This gave us the following plots:</p>\n\n<table>\n  <tbody>\n    <tr>\n      <td><a href=\"../../images/abl1-f-qc.png\" rel=\"noopener noreferrer\"><img src=\"../../images/abl1-f-qc.png\" alt=\"Quality scores across all bases: foward. \" width=\"825\" height=\"600\" loading=\"lazy\" /></a></td>\n      <td><a href=\"../../images/abl1-r-qc.png\" rel=\"noopener noreferrer\"><img src=\"../../images/abl1-r-qc.png\" alt=\"Quality scores across all bases: reverse. \" width=\"825\" height=\"600\" loading=\"lazy\" /></a></td>\n    </tr>\n  </tbody>\n</table>\n\n<p><strong>Figure 4:</strong> FastQC assessment of the quality of the raw reads. <strong>Left:</strong> Forward reads. <strong>Right:</strong> Reverse reads.</p>\n\n<p>One can see that these data are of excellent quality and no additional processing is required before we can start the actual analysis.</p>\n\n<h2 id=\"processing-reads-into-duplex-consensus-sequences-with-du-novo\">Processing reads into duplex consensus sequences with Du Novo</h2>\n\n<p>Now we are ready to collapse the raw reads into duplex consensus sequences.</p>\n\n<blockquote class=\"comment\">\n  <comment-title>Finding Du Novo</comment-title>\n  <ul>\n    <li>The tools in this portion of the tutorial can all be found in the <strong>NGS: Du Novo</strong> section.</li>\n  </ul>\n</blockquote>\n\n<h3 id=\"sorting-reads-into-families\">Sorting reads into families</h3>\n\n<p>The <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Du Novo: Make families</strong> tool will separate the 12bp tags from each read pair and concatenate them into a 24bp barcode. Then it will use the barcodes to sort the reads into families that all descend from the same original fragment.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Sorting reads into families</hands-on-title>\n\n  <p>Run <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Du Novo: Make families</strong> with the following parameters:</p>\n  <ul>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>Sequencing reads, mate 1</em>: <code class=\"language-plaintext highlighter-rouge\">1: SRR1799908_forward</code></li>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>Sequencing reads, mate 2</em>: <code class=\"language-plaintext highlighter-rouge\">2: SRR1799908_reverse</code></li>\n    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>Tag length</em>: <code class=\"language-plaintext highlighter-rouge\">12</code></li>\n  </ul>\n\n  <p>Output: <code class=\"language-plaintext highlighter-rouge\">7: Du Novo: Make families on data 2 and data 1</code></p>\n</blockquote>\n\n<h3 id=\"correcting-barcodes\">Correcting barcodes</h3>\n\n<p>The grouping reads based on barcode relies on exact barcode matches. Any PCR or sequencing error in the barcode sequence will prevent the affected reads from being joined with their other family members.</p>\n\n<p>Du Novo includes a tool which can correct most of these errors and recover the affected reads. This can increase the final yield of duplex consensus reads by up to 11% (Stoler <em>et al.</em> 2018, in preparation).</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Correcting barcodes</hands-on-title>\n\n  <p>Run <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Du Novo: Correct barcodes</strong> with the following parameters:</p>\n  <ul>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>Input reads</em>: <code class=\"language-plaintext highlighter-rouge\">7: Du Novo: Make families on data 2 and data 1</code></li>\n    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>Maximum differences</em>: <code class=\"language-plaintext highlighter-rouge\">3</code></li>\n  </ul>\n\n  <p>Output: <code class=\"language-plaintext highlighter-rouge\">8: Du Novo: Correct barcodes on data 7</code></p>\n</blockquote>\n\n<h3 id=\"aligning-families\">Aligning families</h3>\n\n<p>After grouping reads that came from the same original fragment, we need to align them with each other. This next tool will perform a multiple sequence alignment on each family.</p>\n\n<blockquote class=\"comment\">\n  <comment-title>Analysis bottleneck</comment-title>\n  <p>This is by far the most time-consuming step.</p>\n\n  <p>On this dataset, it took 2 hours to complete when run on <a href=\"https://usegalaxy.org/\">Galaxy Main</a>.</p>\n  <ul>\n    <li>At the time, Galaxy allocated 6 cores to the job.</li>\n  </ul>\n</blockquote>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Aligning families</hands-on-title>\n\n  <p>Run <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Du Novo: Align families</strong> with the following parameters:</p>\n  <ul>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>Input reads</em>: <code class=\"language-plaintext highlighter-rouge\">8: Du Novo: Correct barcodes on data 7</code></li>\n    <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>Multiple sequence aligner</em>: <code class=\"language-plaintext highlighter-rouge\">Kalign2</code></li>\n  </ul>\n\n  <p>Output: <code class=\"language-plaintext highlighter-rouge\">9: Du Novo: Align families on data 8</code></p>\n</blockquote>\n\n<h3 id=\"making-consensus-sequences\">Making consensus sequences</h3>\n\n<p>Now, we need to collapse the aligned reads into consensus sequences. This next tool will process each group of aligned reads that came from the same single-stranded family into a consensus. Then it will align the consensus sequences from the two strands of each original molecule, and call a consensus between them.</p>\n\n<p>Normally, the tool only produces the final double-stranded consensus sequences. But we will make use of the single-stranded consensus sequences <a href=\"#calling-variants-with-single-strand-consensus-sequences\">later</a>, so we’ll tell it to keep those as well.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Making consensus sequences</hands-on-title>\n\n  <p>Run <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Du Novo: Make consensus reads</strong> with the following parameters:</p>\n  <ul>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>Aligned input reads</em>: <code class=\"language-plaintext highlighter-rouge\">9: Du Novo: Align families on data 8</code></li>\n    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>Minimum reads for a consensus sequence</em>: <code class=\"language-plaintext highlighter-rouge\">3</code></li>\n    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>Consensus % threshold</em>: <code class=\"language-plaintext highlighter-rouge\">0.7</code></li>\n    <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>Output format</em>: <code class=\"language-plaintext highlighter-rouge\">FASTQ</code></li>\n    <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>Output single-strand consensus sequences as well</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n  </ul>\n\n  <p>Outputs:</p>\n  <ul>\n    <li><code class=\"language-plaintext highlighter-rouge\">10: Du Novo: Make consensus reads on data 9 (mate 1)</code></li>\n    <li><code class=\"language-plaintext highlighter-rouge\">11: Du Novo: Make consensus reads on data 9 (mate 2)</code></li>\n    <li><code class=\"language-plaintext highlighter-rouge\">12: Du Novo: Make consensus reads on data 9 (SSCS mate 1)</code></li>\n    <li><code class=\"language-plaintext highlighter-rouge\">13: Du Novo: Make consensus reads on data 9 (SSCS mate 2)</code></li>\n  </ul>\n</blockquote>\n\n<blockquote class=\"comment\">\n  <comment-title>Setting output formats</comment-title>\n\n  <p>You may have to set the datatype of the outputs from <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Du Novo: Make consensus reads</strong> tool.</p>\n\n  <p>Versions below 2.16 only set the datatype to <code class=\"language-plaintext highlighter-rouge\">fastq</code>, not the more specific <code class=\"language-plaintext highlighter-rouge\">fastqsanger</code>. Many tools (like <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Map with BWA-MEM</strong>) won’t accept FASTQ input without it specifying what subtype it is.</p>\n\n  <ol>\n    <li>In your history, click on the pencil icon next to the dataset name.</li>\n    <li>Click on the <strong>Datatypes</strong> tab.</li>\n    <li>In the <strong>Change datatype</strong> pane, click on the dropdown where it says <code class=\"language-plaintext highlighter-rouge\">fastq</code>.</li>\n    <li>Enter <code class=\"language-plaintext highlighter-rouge\">fastqsanger</code>, then click the <strong>Change datatype</strong> button in the upper right of the pane.</li>\n  </ol>\n</blockquote>\n\n<blockquote class=\"details\">\n  <details-title>Where do the FASTQ quality scores come from?</details-title>\n\n  <p>There is no easy way to assign a PHRED score to a consensus base derived from many duplex reads.</p>\n\n  <p>So Du Novo does not attempt to give a meaningful score. It assigns the same arbitrary score to all bases.</p>\n  <ul>\n    <li>It produces FASTQ for compatibility, but the output contains no more information than a FASTA file.</li>\n  </ul>\n\n  <p>You may have noticed the <i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>Output PHRED score</em> parameter in the <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Du Novo: Make consensus reads</strong> tool. This allows you to specify which score to assign to (all) the bases.</p>\n\n</blockquote>\n\n<h2 id=\"filtering-consensuses\">Filtering consensuses</h2>\n\n<p>You may have realized that when calling a “consensus” between two sequences, if the two disagree on a base, there’s no way to know which is correct. So in these situations, Du Novo uses the <a href=\"https://en.wikipedia.org/wiki/Nucleic_acid_notation\">IUPAC ambiguity letter</a> for the two different bases (e.g. <code class=\"language-plaintext highlighter-rouge\">W</code> = <code class=\"language-plaintext highlighter-rouge\">A</code> or <code class=\"language-plaintext highlighter-rouge\">T</code>). Also, when calling single-stranded consensus sequences, if there aren’t enough high-quality bases to call a position (in the <a href=\"#hands-on-making-consensus-sequences\">above hands-on</a>, we set this threshold to 70%), it gives an <code class=\"language-plaintext highlighter-rouge\">N</code>.</p>\n\n<p>This information could be useful for some analyses, but not for our variant calling. The tool <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Sequence Content Trimmer</strong> will help with filtering these out. With the settings below, it will move along the read, tracking the frequency of ambiguous (non-ACGT) bases in a 10bp window. If it sees more than 2 ambiguous bases in a window, it will remove the rest of the read, starting with the first offending base in the window. We’ll also tell it to remove entirely any read pair containing a read that got trimmed to less than 50bp.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Filtering the consensus sequences</hands-on-title>\n\n  <p>Run <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Sequence Content Trimmer</strong> with the following parameters:</p>\n  <ul>\n    <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>Paired reads?</em>: <code class=\"language-plaintext highlighter-rouge\">Paired</code></li>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>Input reads (mate 1)</em>: <code class=\"language-plaintext highlighter-rouge\">10: Du Novo: Make consensus reads on data 9 (mate 1)</code></li>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>Input reads (mate 2)</em>: <code class=\"language-plaintext highlighter-rouge\">11: Du Novo: Make consensus reads on data 9 (mate 2)</code></li>\n    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>Bases to filter on</em>: <code class=\"language-plaintext highlighter-rouge\">ACGT</code></li>\n    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>Frequency threshold</em>: <code class=\"language-plaintext highlighter-rouge\">0.2</code></li>\n    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>Size of the window</em>: <code class=\"language-plaintext highlighter-rouge\">10</code></li>\n    <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>Invert filter bases</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n    <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>Set a minimum read length</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code></li>\n    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>Minimum read length</em>: <code class=\"language-plaintext highlighter-rouge\">50</code></li>\n  </ul>\n\n  <p>Outputs:</p>\n  <ul>\n    <li><code class=\"language-plaintext highlighter-rouge\">14: Sequence Content Trimmer on data 10 and data 11</code></li>\n    <li><code class=\"language-plaintext highlighter-rouge\">15: Sequence Content Trimmer on data 10 and data 11</code></li>\n  </ul>\n</blockquote>\n\n<h1 id=\"calling-variants-with-duplex-consensus-sequences\">Calling variants with duplex consensus sequences</h1>\n\n<p>At this point we have trimmed DCSs. We can now proceed to call variants. This involves aligning the variants against the reference genome, then counting variants.</p>\n\n<p>We’re not specifically interested in the reference sequence, since all we care about is sequence content of the consensus reads. But we’ll be using the reference sequence to figure out where all the reads come from. This lets us stack them on top of each other, with equivalent bases lined up in columns. Then we can step through each column, count how many times we see each base, and and compile a list of variants.</p>\n\n<h2 id=\"mapping-the-reads\">Mapping the reads</h2>\n\n<h3 id=\"align-against-the-genome-with-bwa-mem\">Align against the genome with BWA-MEM</h3>\n\n<p>Here, we’ll use <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Map with BWA-MEM</strong> to map the DCS reads to the human reference genome.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Align with BWA-MEM</hands-on-title>\n\n  <p>Run <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Map with BWA-MEM</strong> with the following parameters:</p>\n  <ul>\n    <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>Using reference genome?</em>: <code class=\"language-plaintext highlighter-rouge\">Human (Homo sapiens) (b38): hg38</code></li>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>Select first set of reads</em>: <code class=\"language-plaintext highlighter-rouge\">14: Sequence Content Trimmer on data 10 and data 11</code></li>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>Select second set of reads</em>: <code class=\"language-plaintext highlighter-rouge\">15: Sequence Content Trimmer on data 10 and data 11</code></li>\n  </ul>\n\n  <p>Output: <code class=\"language-plaintext highlighter-rouge\">16: Map with BWA-MEM on data 15 and data 14 (mapped reads in BAM format)</code></p>\n</blockquote>\n\n<h3 id=\"left-aligning-indels\">Left Aligning indels</h3>\n\n<p>To normalize the positional distribution of indels we use the <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>BamLeftAlign</strong> utility from the <a href=\"https://github.com/ekg/freebayes#indels\">FreeBayes</a> package. You can find it in the <strong>NGS: Variant Analysis</strong> section. This is necessary to avoid erroneous polymorphisms flanking regions with indels (e.g., in low complexity loci):</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Left-align indels</hands-on-title>\n\n  <p>Run <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>BamLeftAlign</strong> with the following parameters:</p>\n  <ul>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>Select alignment file in BAM format</em>: <code class=\"language-plaintext highlighter-rouge\">16: Map with BWA-MEM on data 15 and data 14 (mapped reads in BAM format)</code></li>\n    <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>Using reference genome</em>: <code class=\"language-plaintext highlighter-rouge\">Human (Homo sapiens): hg38</code>\n      <ul>\n        <li>The same genome we aligned to.</li>\n      </ul>\n    </li>\n  </ul>\n\n  <p>Output: <code class=\"language-plaintext highlighter-rouge\">17: BamLeftAlign on data 16 (alignments)</code></p>\n</blockquote>\n\n<h2 id=\"calling-the-variants\">Calling the variants</h2>\n\n<p>Now we’ll use our aligned consensus reads to find variants.</p>\n\n<p>Normally, in a diploid resequencing experiment, you would call variants relative to the reference. So, you’d report sites which are different from the reference (and whether they’re hetero- or homozygous).</p>\n\n<p>In our case, we’re interested in <em>rare</em> variants. So what we’ll report is the sites where there is more than one allele, and what the frequency is of the less-common allele (the <strong>minor allele</strong>). This has the potential to include every small sequencing error (even though we’re using duplex, there still are errors). So to reduce the noise, we’ll set a lower threshold at 1% minor allele frequency (<strong>MAF</strong>).</p>\n\n<h3 id=\"finding-variants-in-the-alignment\">Finding variants in the alignment</h3>\n\n<p>To identify sites containing variants we use the <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Naive Variant Caller (NVC)</strong> tool from the <strong>NGS: Variant Analysis</strong> section. This reads the alignment and counts the number of bases of each type at each site.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Count the variants</hands-on-title>\n\n  <p>Run <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Naive Variant Caller (NVC)</strong> with the following parameters:</p>\n  <ul>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>BAM file</em>: <code class=\"language-plaintext highlighter-rouge\">17: BamLeftAlign on data 16 (alignments)</code></li>\n    <li><i class=\"fas fa-filter\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-select</span> <em>Using reference genome</em>: <code class=\"language-plaintext highlighter-rouge\">hg38</code>\n      <ul>\n        <li>The same genome we aligned to.</li>\n      </ul>\n    </li>\n    <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>Insert Restrict to regions</em>: Click to add a region.</li>\n    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>Chromosome</em>: <code class=\"language-plaintext highlighter-rouge\">chr9</code>\n      <ul>\n        <li><em>ABL1</em> is on chr9. Restricting it to this region saves some processing time.</li>\n      </ul>\n    </li>\n    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>Minimum base quality</em>: <code class=\"language-plaintext highlighter-rouge\">0</code>\n      <ul>\n        <li>In our case, base quality <a href=\"#details-where-do-the-fastq-quality-scores-come-from\">isn’t meaningful</a>, so we set the threshold to 0.</li>\n      </ul>\n    </li>\n    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>Minimum mapping quality</em>: <code class=\"language-plaintext highlighter-rouge\">20</code></li>\n    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>Ploidy</em>: <code class=\"language-plaintext highlighter-rouge\">1</code>\n      <ul>\n        <li>Ploidy is irrelevant here as it is a mixture of multiple genomes.</li>\n      </ul>\n    </li>\n  </ul>\n\n  <p>Output: <code class=\"language-plaintext highlighter-rouge\">18: Naive Variant Caller (NVC) on data 17</code></p>\n</blockquote>\n\n<p>The <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Naive Variant Caller (NVC)</strong> generates a <a href=\"https://en.wikipedia.org/wiki/Variant_Call_Format\">VCF</a> file that can be viewed at genome browsers such as <a href=\"https://www.broadinstitute.org/igv/\">IGV</a>. Yet one rarely finds variants by looking at genome browsers. We’ll want to use tools to search for variants that fit our criteria.</p>\n\n<h3 id=\"finding-minor-alleles\">Finding minor alleles</h3>\n\n<p>Now we’ll want to parse the VCF produced by the NVC, determine what the major and minor allele is at each site, and calculate their frequencies. The <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Variant Annotator</strong> from the <strong>NGS: Variant Analysis</strong> section can do this.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Read the variants file</hands-on-title>\n\n  <p>Run <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Variant Annotator</strong> with the following parameters:</p>\n  <ul>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>Input variants from Naive Variants Detector</em>: <code class=\"language-plaintext highlighter-rouge\">18: Naive Variant Caller (NVC) on data 17</code></li>\n    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>Minor allele frequency threshold</em>: <code class=\"language-plaintext highlighter-rouge\">0</code></li>\n    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>Coverage threshold</em>: <code class=\"language-plaintext highlighter-rouge\">10</code></li>\n    <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>Output stranded base counts</em>: <code class=\"language-plaintext highlighter-rouge\">Yes</code>\n      <ul>\n        <li>To be able to filter for strand bias.</li>\n      </ul>\n    </li>\n  </ul>\n\n  <p>Output: <code class=\"language-plaintext highlighter-rouge\">19: Variant Annotator on data 18</code></p>\n</blockquote>\n\n<h3 id=\"filtering-out-the-noise\">Filtering out the noise</h3>\n\n<p>Now we have a file containing the base counts for every site covered by at least 10 reads. We’d like to filter through this data to find sites with a reasonable chance of being a real variant, not sequencing error.</p>\n\n<p>The <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Variant Annotator</strong> produces a simple tab-delimited file, with one site per line. We can use the <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Filter</strong> tool from the <strong>Filter and Sort</strong> section to process this kind of file. We’ll use the filter <code class=\"language-plaintext highlighter-rouge\">c16 &gt;= 0.01</code> to remove lines where the value in column 16 is less than 0.01. Column 16 contains the minor allele frequency, so this will remove all sites with a MAF less than 1%.</p>\n\n<blockquote class=\"hands_on\">\n  <hands-on-title>Filter the raw variants list</hands-on-title>\n\n  <p>Run <i class=\"fas fa-wrench\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">tool</span> <strong>Filter</strong> with the following parameters:</p>\n  <ul>\n    <li><i class=\"far fa-file\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-file</span> <em>Filter</em>: <code class=\"language-plaintext highlighter-rouge\">19: Variant Annotator on data 18</code></li>\n    <li><i class=\"fas fa-pencil-alt\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-text</span> <em>With following condition</em>: <code class=\"language-plaintext highlighter-rouge\">c16 &gt;= 0.01</code></li>\n    <li><i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>Number of header lines to skip</em>: <code class=\"language-plaintext highlighter-rouge\">1</code></li>\n  </ul>\n\n  <p>Output: <code class=\"language-plaintext highlighter-rouge\">20: Filter on data 19</code></p>\n</blockquote>\n\n<h2 id=\"results\">Results</h2>\n\n<p>Now we’re down to just two sites:</p>\n\n<table>\n  <thead>\n    <tr>\n      <th style=\"text-align: left\">Position (chr9)</th>\n      <th style=\"text-align: center\">Major allele</th>\n      <th style=\"text-align: center\">Minor allele</th>\n      <th style=\"text-align: center\">MAF</th>\n    </tr>\n    <tr>\n      <th style=\"text-align: left\">Column 3</th>\n      <th style=\"text-align: center\">Column 14</th>\n      <th style=\"text-align: center\">Column 15</th>\n      <th style=\"text-align: center\">Column 16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td style=\"text-align: left\">130,872,141</td>\n      <td style=\"text-align: center\">G</td>\n      <td style=\"text-align: center\">A</td>\n      <td style=\"text-align: center\">0.01259</td>\n    </tr>\n    <tr>\n      <td style=\"text-align: left\">130,880,141</td>\n      <td style=\"text-align: center\">A</td>\n      <td style=\"text-align: center\">G</td>\n      <td style=\"text-align: center\">0.47764</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>The polymorphism we are interested in (and the one reported by <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4414912/\">Schmitt <em>et al.</em> 2015</a>) is at the position 130,872,141 and has a frequency of 1.3%. The other site (position 130,880,141) is a known common variant <a href=\"https://www.ncbi.nlm.nih.gov/SNP/snp_ref.cgi?type=rs&amp;rs=rs2227985\">rs2227985</a>, which is heterozygous in this sample.</p>\n\n<h1 id=\"calling-variants-with-single-strand-consensus-sequences\">Calling variants with single strand consensus sequences</h1>\n\n<p>Analysis of SSCS data follows the exact same trajectory:</p>\n\n<ul>\n  <li><a href=\"#filtering-consensuses\">Filtering consensuses</a></li>\n  <li><a href=\"#mapping-the-reads\">Mapping the reads</a>\n \t- <a href=\"#align-against-the-genome-with-bwa-mem\">Aligning against genome</a>\n \t- <a href=\"#left-aligning-indels\">Left aligning indels</a></li>\n  <li><a href=\"#calling-the-variants\">Calling the variants</a></li>\n</ul>\n\n<blockquote class=\"tip\">\n  <tip-title>Re-running with the same settings</tip-title>\n\n  <p>There’s a shortcut to avoid setting every parameter the second time you run a tool.</p>\n\n  <ol>\n    <li>In your history, click on an output of the first run to expand it.</li>\n    <li>Click on the button with the circular “re-run” arrows.</li>\n    <li>Now the parameters will all be the same as the last run. All you have to do is change the input file(s).</li>\n  </ol>\n</blockquote>\n\n<h2 id=\"re-running-analyses-with-workflows\">Re-running analyses with workflows</h2>\n\n<p>Instead of manually re-running all the tools in the variant calling section, you can use a <strong>workflow</strong> to automatically run the same tools, but on the SSCS reads. Workflows let you run a chain of tools on different input data with a single click of a button. You can find more information on using workflows in the <a href=\"../../../introduction/tutorials/galaxy-intro-101/tutorial.html#run-workflow-on-different-data\">Galaxy 101 introductory tutorial</a>.</p>\n\n<p>We’ve prepared two workflows which split the above analysis into two steps:</p>\n\n<ol>\n  <li><a href=\"https://usegalaxy.org/u/nstoler/w/du-novo-gtn-tutorial\">Using Du Novo</a> to create consensus sequences from raw reads.\n    <ul>\n      <li>This will generate trimmed DCS and SSCS files from raw sequencing data.</li>\n      <li>This does not include the FastQC step. You should always run FastQC on your raw reads first, to check the quality of your sequencing run before proceeding with the analysis.</li>\n    </ul>\n\n    <blockquote class=\"comment\">\n      <comment-title>Helping Du Novo</comment-title>\n      <p>The <i class=\"far fa-check-square\" aria-hidden=\"true\"></i><span class=\"visually-hidden\">param-check</span> <em>Send usage data</em> option is left off in the above workflow.\nThis is because we want to make sure you only share data knowingly.</p>\n\n      <p>But again, if you’d like to help improve Du Novo, consider turning it on.</p>\n    </blockquote>\n  </li>\n  <li><a href=\"https://usegalaxy.org/u/nstoler/w/copy-of-du-novo-gtn-tutorial\">Calling variants</a> from consensus sequences.\n    <ul>\n      <li>This takes a pair of FASTQ files and calls variants using them.</li>\n      <li>If you’d like variants from both DCS and SSCS, you’ll have to run this twice, once on each.</li>\n      <li><strong>N.B.</strong> Remember that this workflow is designed for the above <em>ABL1</em> analysis. If you want to use it for any other dataset, you’ll have to change the relevant options.</li>\n    </ul>\n  </li>\n</ol>\n\n<p>You can use the variant calling workflow to call variants using the SSCS instead of the DCS.</p>\n\n<figure id=\"figure-1\" style=\"max-width: 90%;\"><img src=\"../../images/workflow-dunovo.png\" alt=\"Du Novo workflow. \" width=\"1053\" height=\"438\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/workflow-dunovo.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 1</strong>:</span> Workflow 1: Making consensus sequences</figcaption></figure>\n\n<figure id=\"figure-2\" style=\"max-width: 90%;\"><img src=\"../../images/workflow-dunovo-variant-calling.png\" alt=\"Variant calling workflow. \" width=\"777\" height=\"360\" loading=\"lazy\" /><a target=\"_blank\" href=\"../../images/workflow-dunovo-variant-calling.png\" rel=\"noopener noreferrer\"><small>Open image in new tab</small></a><br /><br /><figcaption><span class=\"figcaption-prefix\"><strong>Figure 2</strong>:</span> Workflow 2: Variant calling</figcaption></figure>\n\n<h1 id=\"conclusion\">Conclusion</h1>\n\n<p>You should now understand duplex sequencing, rare variants, and be able to process the former to find the latter.</p>\n\n<h3 id=\"if-things-dont-work\">If things don’t work…</h3>\n<p>…you need to complain. Use <a href=\"https://help.galaxyproject.org/\">Galaxy’s Help Channel</a> to do this.</p>\n"],"ref_slides":[],"hands_on":true,"slides":false,"mod_date":"2023-11-03 14:30:27 +0000","pub_date":"2017-02-22 11:51:41 +0000","version":30,"workflows":[{"workflow":"dunovo.ga","tests":false,"url":"https://training.galaxyproject.org/training-material/topics/variant-analysis/tutorials/dunovo/workflows/dunovo.ga","path":"topics/variant-analysis/tutorials/dunovo/workflows/dunovo.ga","wfid":"variant-analysis-dunovo","wfname":"dunovo","trs_endpoint":"https://training.galaxyproject.org/training-material/api/ga4gh/trs/v2/tools/variant-analysis-dunovo/versions/dunovo","license":null,"creators":[],"name":"Du Novo GTN Tutorial - Make Consensus Sequences","title":"Du Novo GTN Tutorial - Make Consensus Sequences","test_results":null,"modified":"2024-06-14 10:06:51 +0000","mermaid":"flowchart TD\n  0[\"ℹ️ Input Dataset\\nSRR1799908_forward\"];\n  style 0 stroke:#2c3143,stroke-width:4px;\n  1[\"ℹ️ Input Dataset\\nSRR1799908_reverse\"];\n  style 1 stroke:#2c3143,stroke-width:4px;\n  2[\"Du Novo: Make families\"];\n  0 -->|output| 2;\n  1 -->|output| 2;\n  3[\"Du Novo: Correct barcodes\"];\n  2 -->|output| 3;\n  4[\"Du Novo: Align families\"];\n  3 -->|output| 4;\n  5[\"Du Novo: Make consensus reads\"];\n  4 -->|output| 5;\n  6[\"DCS: Sequence Content Trimmer\"];\n  5 -->|dcs1| 6;\n  5 -->|dcs2| 6;\n  7[\"SSCS: Sequence Content Trimmer\"];\n  5 -->|sscs1| 7;\n  5 -->|sscs2| 7;\n  75dfe52d-711e-4826-ba9b-b4feed30f5bf[\"Output\\n\"];\n  7 --> 75dfe52d-711e-4826-ba9b-b4feed30f5bf;\n  style 75dfe52d-711e-4826-ba9b-b4feed30f5bf stroke:#2c3143,stroke-width:4px;"},{"workflow":"variant-calling.ga","tests":false,"url":"https://training.galaxyproject.org/training-material/topics/variant-analysis/tutorials/dunovo/workflows/variant-calling.ga","path":"topics/variant-analysis/tutorials/dunovo/workflows/variant-calling.ga","wfid":"variant-analysis-dunovo","wfname":"variant-calling","trs_endpoint":"https://training.galaxyproject.org/training-material/api/ga4gh/trs/v2/tools/variant-analysis-dunovo/versions/variant-calling","license":null,"creators":[],"name":"Du Novo GTN Tutorial - Variant Calling","title":"Du Novo GTN Tutorial - Variant Calling","test_results":null,"modified":"2024-06-14 10:06:51 +0000","mermaid":"flowchart TD\n  0[\"ℹ️ Input Dataset\\nTrimmed reads mate 1\"];\n  style 0 stroke:#2c3143,stroke-width:4px;\n  1[\"ℹ️ Input Dataset\\nTrimmed reads mate 2\"];\n  style 1 stroke:#2c3143,stroke-width:4px;\n  2[\"Map with BWA-MEM\"];\n  0 -->|output| 2;\n  1 -->|output| 2;\n  3[\"BamLeftAlign\"];\n  2 -->|bam_output| 3;\n  4[\"Naive Variant Caller NVC\"];\n  3 -->|output_bam| 4;\n  5[\"Variant Annotator\"];\n  4 -->|output_vcf| 5;\n  6[\"Filter\"];\n  5 -->|output| 6;"}],"api":"https://training.galaxyproject.org/training-material/api/topics/variant-analysis/tutorials/dunovo/tutorial.json","tools":["Filter1","toolshed.g2.bx.psu.edu/repos/blankenberg/naive_variant_caller/naive_variant_caller/0.0.4","toolshed.g2.bx.psu.edu/repos/devteam/bwa/bwa_mem/0.7.17.1","toolshed.g2.bx.psu.edu/repos/devteam/freebayes/bamleftalign/1.1.0.46-0","toolshed.g2.bx.psu.edu/repos/nick/allele_counts/allele_counts_1/1.2","toolshed.g2.bx.psu.edu/repos/nick/dunovo/align_families/2.15","toolshed.g2.bx.psu.edu/repos/nick/dunovo/correct_barcodes/2.15","toolshed.g2.bx.psu.edu/repos/nick/dunovo/dunovo/2.15","toolshed.g2.bx.psu.edu/repos/nick/dunovo/make_families/2.15","toolshed.g2.bx.psu.edu/repos/nick/sequence_content_trimmer/sequence_content_trimmer/0.1"],"supported_servers":{"exact":[{"url":"https://usegalaxy.be/","name":"UseGalaxy.be","usegalaxy":false},{"url":"https://usegalaxy.org","name":"UseGalaxy.org (Main)","usegalaxy":true}],"inexact":[]},"topic_name_human":"Variant Analysis","admin_install":{"install_tool_dependencies":true,"install_repository_dependencies":true,"install_resolver_dependencies":true,"tools":[{"name":"naive_variant_caller","owner":"blankenberg","revisions":"6be51647d31a","tool_panel_section_label":"Variant Calling","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"bwa","owner":"devteam","revisions":"3fe632431b68","tool_panel_section_label":"Mapping","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"freebayes","owner":"devteam","revisions":"156b60c1530f","tool_panel_section_label":"Variant Calling","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"allele_counts","owner":"nick","revisions":"411adeff1eec","tool_panel_section_label":"Variant Calling","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"dunovo","owner":"nick","revisions":"9dc43bf7d1db","tool_panel_section_label":"Du Novo","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"dunovo","owner":"nick","revisions":"9dc43bf7d1db","tool_panel_section_label":"Du Novo","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"dunovo","owner":"nick","revisions":"9dc43bf7d1db","tool_panel_section_label":"Du Novo","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"dunovo","owner":"nick","revisions":"9dc43bf7d1db","tool_panel_section_label":"Du Novo","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"},{"name":"sequence_content_trimmer","owner":"nick","revisions":"7f170cb06e2e","tool_panel_section_label":"Du Novo","tool_shed_url":"https://toolshed.g2.bx.psu.edu/"}]},"admin_install_yaml":"---\ninstall_tool_dependencies: true\ninstall_repository_dependencies: true\ninstall_resolver_dependencies: true\ntools:\n- name: naive_variant_caller\n  owner: blankenberg\n  revisions: 6be51647d31a\n  tool_panel_section_label: Variant Calling\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: bwa\n  owner: devteam\n  revisions: 3fe632431b68\n  tool_panel_section_label: Mapping\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: freebayes\n  owner: devteam\n  revisions: 156b60c1530f\n  tool_panel_section_label: Variant Calling\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: allele_counts\n  owner: nick\n  revisions: 411adeff1eec\n  tool_panel_section_label: Variant Calling\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: dunovo\n  owner: nick\n  revisions: 9dc43bf7d1db\n  tool_panel_section_label: Du Novo\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: dunovo\n  owner: nick\n  revisions: 9dc43bf7d1db\n  tool_panel_section_label: Du Novo\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: dunovo\n  owner: nick\n  revisions: 9dc43bf7d1db\n  tool_panel_section_label: Du Novo\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: dunovo\n  owner: nick\n  revisions: 9dc43bf7d1db\n  tool_panel_section_label: Du Novo\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n- name: sequence_content_trimmer\n  owner: nick\n  revisions: 7f170cb06e2e\n  tool_panel_section_label: Du Novo\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n","tours":false,"video":false,"slides_recordings":false,"translations":{"tutorial":[],"slides":[],"video":false},"license":"CC-BY-4.0","type":"tutorial","tags":["work-in-progress"]}